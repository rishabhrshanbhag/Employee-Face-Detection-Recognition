{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imutils import face_utils\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_files(path):\n",
    "    return os.listdir(path)\n",
    "\n",
    "cascPath = \"/Users/abdulrehman/opt/anaconda3/envs/Face-Detection/lib/python3.6/site-packages/cv2/data/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "def return_bbx(image):\n",
    "    faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "    faces = faceCascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5, flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Abdullah_Gul</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Adrien_Brody</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Alejandro_Toledo</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Alvaro_Uribe</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Amelie_Mauresmo</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>Vicente_Fox</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>Vladimir_Putin</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5605</th>\n",
       "      <td>Wen_Jiabao</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5659</th>\n",
       "      <td>Winona_Ryder</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>Yoriko_Kawaguchi</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  images\n",
       "20        Abdullah_Gul      19\n",
       "52        Adrien_Brody      12\n",
       "127   Alejandro_Toledo      39\n",
       "210       Alvaro_Uribe      35\n",
       "223    Amelie_Mauresmo      21\n",
       "...                ...     ...\n",
       "5541       Vicente_Fox      32\n",
       "5569    Vladimir_Putin      49\n",
       "5605        Wen_Jiabao      13\n",
       "5659      Winona_Ryder      24\n",
       "5704  Yoriko_Kawaguchi      14\n",
       "\n",
       "[143 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_path = '/Users/abdulrehman/Desktop/SML Project/FacesInTheWild/'\n",
    "\n",
    "Celebs = pd.read_csv(Dataset_path+'lfw_allnames.csv')\n",
    "Celebs = Celebs[Celebs['images']>10]\n",
    "Celebs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list = []\n",
    "X = []\n",
    "Y = []\n",
    "y_label = 0\n",
    "\n",
    "for _, [name,__] in Celebs.iterrows():\n",
    "    celeb_path = Dataset_path+'lfw-deepfunneled/'+name+'/'\n",
    "    \n",
    "    images_paths = get_files(celeb_path)\n",
    "    temp = []\n",
    "    for image_path in images_paths:\n",
    "        image = cv2.imread(celeb_path+image_path,1)\n",
    "        faces = return_bbx(image)\n",
    "        if len(faces) == 1:\n",
    "            if len(temp)>=10:\n",
    "                break\n",
    "            temp.append(len(X))\n",
    "            (x,y,w,h) = faces[0]\n",
    "            cropped = image[x:x+w, y:y+h]\n",
    "            dim = (100, 100)\n",
    "            resized = cv2.resize(cropped, dim, interpolation = cv2.INTER_AREA)\n",
    "            image = np.array(resized).astype(\"float32\")\n",
    "            X.append(image)\n",
    "            Y.append(y_label)\n",
    "    y_label+=1\n",
    "    cat_list.append(temp)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1423, 100, 100, 3) (1423,)\n"
     ]
    }
   ],
   "source": [
    "X_data = np.asarray(X)/255\n",
    "Y_data = np.array(Y)\n",
    "cat_list = np.asarray(cat_list)\n",
    "\n",
    "print(X_data.shape, Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 10,\n",
       "         1: 10,\n",
       "         2: 10,\n",
       "         3: 10,\n",
       "         4: 10,\n",
       "         5: 10,\n",
       "         6: 10,\n",
       "         7: 10,\n",
       "         8: 10,\n",
       "         9: 10,\n",
       "         10: 10,\n",
       "         11: 10,\n",
       "         12: 10,\n",
       "         13: 10,\n",
       "         14: 10,\n",
       "         15: 10,\n",
       "         16: 10,\n",
       "         17: 10,\n",
       "         18: 10,\n",
       "         19: 10,\n",
       "         20: 10,\n",
       "         21: 10,\n",
       "         22: 10,\n",
       "         23: 10,\n",
       "         24: 10,\n",
       "         25: 10,\n",
       "         26: 10,\n",
       "         27: 10,\n",
       "         28: 10,\n",
       "         29: 10,\n",
       "         30: 10,\n",
       "         31: 10,\n",
       "         32: 10,\n",
       "         33: 10,\n",
       "         34: 10,\n",
       "         35: 10,\n",
       "         36: 10,\n",
       "         37: 9,\n",
       "         38: 10,\n",
       "         39: 10,\n",
       "         40: 10,\n",
       "         41: 10,\n",
       "         42: 10,\n",
       "         43: 10,\n",
       "         44: 10,\n",
       "         45: 10,\n",
       "         46: 10,\n",
       "         47: 10,\n",
       "         48: 10,\n",
       "         49: 10,\n",
       "         50: 10,\n",
       "         51: 10,\n",
       "         52: 10,\n",
       "         53: 10,\n",
       "         54: 10,\n",
       "         55: 10,\n",
       "         56: 10,\n",
       "         57: 10,\n",
       "         58: 10,\n",
       "         59: 10,\n",
       "         60: 10,\n",
       "         61: 10,\n",
       "         62: 10,\n",
       "         63: 10,\n",
       "         64: 10,\n",
       "         65: 10,\n",
       "         66: 10,\n",
       "         67: 10,\n",
       "         68: 10,\n",
       "         69: 10,\n",
       "         70: 10,\n",
       "         71: 10,\n",
       "         72: 10,\n",
       "         73: 10,\n",
       "         74: 10,\n",
       "         75: 10,\n",
       "         76: 10,\n",
       "         77: 10,\n",
       "         78: 10,\n",
       "         79: 10,\n",
       "         80: 10,\n",
       "         81: 10,\n",
       "         82: 10,\n",
       "         83: 10,\n",
       "         84: 10,\n",
       "         85: 10,\n",
       "         86: 10,\n",
       "         87: 10,\n",
       "         88: 10,\n",
       "         89: 10,\n",
       "         90: 10,\n",
       "         91: 10,\n",
       "         92: 10,\n",
       "         93: 10,\n",
       "         94: 10,\n",
       "         95: 10,\n",
       "         96: 10,\n",
       "         97: 10,\n",
       "         98: 10,\n",
       "         99: 10,\n",
       "         100: 10,\n",
       "         101: 10,\n",
       "         102: 10,\n",
       "         103: 8,\n",
       "         104: 10,\n",
       "         105: 10,\n",
       "         106: 10,\n",
       "         107: 9,\n",
       "         108: 10,\n",
       "         109: 10,\n",
       "         110: 10,\n",
       "         111: 10,\n",
       "         112: 10,\n",
       "         113: 10,\n",
       "         114: 10,\n",
       "         115: 8,\n",
       "         116: 10,\n",
       "         117: 10,\n",
       "         118: 10,\n",
       "         119: 10,\n",
       "         120: 10,\n",
       "         121: 10,\n",
       "         122: 10,\n",
       "         123: 10,\n",
       "         124: 9,\n",
       "         125: 10,\n",
       "         126: 10,\n",
       "         127: 10,\n",
       "         128: 10,\n",
       "         129: 10,\n",
       "         130: 10,\n",
       "         131: 10,\n",
       "         132: 10,\n",
       "         133: 10,\n",
       "         134: 10,\n",
       "         135: 10,\n",
       "         136: 10,\n",
       "         137: 10,\n",
       "         138: 10,\n",
       "         139: 10,\n",
       "         140: 10,\n",
       "         141: 10,\n",
       "         142: 10})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = Y_data\n",
    "n_classes = len(set(a))\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X&Y shape of training data : (1280, 100, 100, 3) and (1280,) (128,)\n",
      "X&Y shape of testing data : (143, 100, 100, 3) and (143,) (15,)\n"
     ]
    }
   ],
   "source": [
    "train_split = 0.9\n",
    "\n",
    "train_size = int(n_classes*train_split)\n",
    "test_size = n_classes-train_size\n",
    "\n",
    "train_files = train_size * 10\n",
    "\n",
    "X_train = X_data[:train_files]\n",
    "y_train = Y_data[:train_files]\n",
    "cat_train = cat_list[:train_size]\n",
    "\n",
    "#Validation Split\n",
    "X_test = X_data[train_files:]\n",
    "y_test = Y_data[train_files:]\n",
    "cat_test = cat_list[train_size:]\n",
    "\n",
    "print('X&Y shape of training data :',X_train.shape, 'and', y_train.shape, cat_train.shape)\n",
    "print('X&Y shape of testing data :' , X_test.shape, 'and', y_test.shape, cat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size=64):\n",
    "    \n",
    "    temp_x = X_train\n",
    "    temp_cat_list = cat_train\n",
    "    start=0\n",
    "    end=train_size\n",
    "    batch_x=[]\n",
    "        \n",
    "    batch_y = np.zeros(batch_size)\n",
    "    batch_y[int(batch_size/2):] = 1\n",
    "    np.random.shuffle(batch_y)\n",
    "    \n",
    "    class_list = np.random.randint(start, end, batch_size) \n",
    "    batch_x.append(np.zeros((batch_size, 100, 100, 3)))\n",
    "    batch_x.append(np.zeros((batch_size, 100, 100, 3)))\n",
    "\n",
    "    for i in range(0, batch_size):\n",
    "        batch_x[0][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]  \n",
    "        #If train_y has 0 pick from the same class, else pick from any other class\n",
    "        if batch_y[i]==0:\n",
    "            batch_x[1][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]\n",
    "\n",
    "        else:\n",
    "            temp_list = np.append(temp_cat_list[:class_list[i]].flatten(), temp_cat_list[class_list[i]+1:].flatten())\n",
    "            temp_list = np.random.choice(temp_list)\n",
    "            batch_x[1][i] = temp_x[np.random.choice(temp_list)]\n",
    "            \n",
    "            \n",
    "    return(batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "left_input_18 (InputLayer)      [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "right_input_19 (InputLayer)     [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "left_block1_conv1 (Conv2D)      (None, 100, 100, 64) 1792        left_input_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "right_block1_conv1 (Conv2D)     (None, 100, 100, 64) 1792        right_input_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "left_block1_conv2 (Conv2D)      (None, 100, 100, 64) 36928       left_block1_conv1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "right_block1_conv2 (Conv2D)     (None, 100, 100, 64) 36928       right_block1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "left_block1_pool (MaxPooling2D) (None, 50, 50, 64)   0           left_block1_conv2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "right_block1_pool (MaxPooling2D (None, 50, 50, 64)   0           right_block1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "left_block2_conv1 (Conv2D)      (None, 50, 50, 128)  73856       left_block1_pool[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "right_block2_conv1 (Conv2D)     (None, 50, 50, 128)  73856       right_block1_pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "left_block2_conv2 (Conv2D)      (None, 50, 50, 128)  147584      left_block2_conv1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "right_block2_conv2 (Conv2D)     (None, 50, 50, 128)  147584      right_block2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "left_block2_pool (MaxPooling2D) (None, 25, 25, 128)  0           left_block2_conv2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "right_block2_pool (MaxPooling2D (None, 25, 25, 128)  0           right_block2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "left_block3_conv1 (Conv2D)      (None, 25, 25, 256)  295168      left_block2_pool[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "right_block3_conv1 (Conv2D)     (None, 25, 25, 256)  295168      right_block2_pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "left_block3_conv2 (Conv2D)      (None, 25, 25, 256)  590080      left_block3_conv1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "right_block3_conv2 (Conv2D)     (None, 25, 25, 256)  590080      right_block3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "left_block3_conv3 (Conv2D)      (None, 25, 25, 256)  590080      left_block3_conv2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "right_block3_conv3 (Conv2D)     (None, 25, 25, 256)  590080      right_block3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "left_block3_pool (MaxPooling2D) (None, 12, 12, 256)  0           left_block3_conv3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "right_block3_pool (MaxPooling2D (None, 12, 12, 256)  0           right_block3_conv3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "left_block4_conv1 (Conv2D)      (None, 12, 12, 512)  1180160     left_block3_pool[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "right_block4_conv1 (Conv2D)     (None, 12, 12, 512)  1180160     right_block3_pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "left_block4_conv2 (Conv2D)      (None, 12, 12, 512)  2359808     left_block4_conv1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "right_block4_conv2 (Conv2D)     (None, 12, 12, 512)  2359808     right_block4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 73728)        0           left_block4_conv2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 73728)        0           right_block4_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 73728)        0           flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 73728)        0           flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 900)          66356100    dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 900)          66356100    dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 900)          3600        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 900)          3600        dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 900)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 900)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_5 (Subtract)           (None, 900)          0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            901         subtract_5[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 143,271,213\n",
      "Trainable params: 132,716,701\n",
      "Non-trainable params: 10,554,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Subtract, Input, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import plot_model\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "input_shape = (100,100,3)\n",
    "\n",
    "vgg_left = VGG16(weights = 'imagenet',include_top = False, input_shape = input_shape)\n",
    "\n",
    "for layer in vgg_left.layers:\n",
    "    layer.trainable = False\n",
    "    layer._name = 'left_'+layer.name\n",
    "    \n",
    "left = [layer.output for layer in vgg_left.layers][-7]\n",
    "\n",
    "left = Flatten()(left)\n",
    "left = Dropout(0.5)(left)\n",
    "left = Dense(900, kernel_regularizer=l2(1e-2))(left)\n",
    "left = BatchNormalization()(left)\n",
    "left = Activation('relu')(left)\n",
    "\n",
    "\n",
    "vgg_right = VGG16(weights = 'imagenet',include_top = False, input_shape = input_shape)\n",
    "\n",
    "for layer in vgg_right.layers:\n",
    "    layer.trainable = False\n",
    "    layer._name = 'right_'+layer.name\n",
    "\n",
    "right = [layer.output for layer in vgg_right.layers][-7]\n",
    "\n",
    "right = Flatten()(right)\n",
    "right = Dropout(0.5)(right)\n",
    "right = Dense(900, kernel_regularizer=l2(1e-2))(right)\n",
    "right = BatchNormalization()(right)\n",
    "right = Activation('relu')(right)\n",
    "\n",
    "\n",
    "subtracted = Subtract()([left,right])\n",
    "out = Dense(1, activation='sigmoid')(subtracted)\n",
    "\n",
    "model = Model(inputs = [vgg_left.input,vgg_right.input], outputs = out)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.0001), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_shot_learning(model, n_way, n_val):\n",
    "    \n",
    "    temp_x = X_test\n",
    "    temp_cat_list = cat_test\n",
    "    batch_x=[]\n",
    "    x_0_choice=[]\n",
    "    n_correct = 0\n",
    "   \n",
    "    class_list = np.random.randint(train_size+1, n_classes-1, n_val)\n",
    "\n",
    "    for i in class_list:  \n",
    "        j = np.random.choice(cat_list[i])\n",
    "        temp=[]\n",
    "        temp.append(np.zeros((n_way, 100, 100, 3)))\n",
    "        temp.append(np.zeros((n_way, 100, 100, 3)))\n",
    "        for k in range(0, n_way):\n",
    "            temp[0][k] = X_data[j]\n",
    "            \n",
    "            if k==0:\n",
    "                temp[1][k] = X_data[np.random.choice(cat_list[i])]\n",
    "            else:\n",
    "                temp_list = np.append(cat_list[:i].flatten(), cat_list[i+1:].flatten())\n",
    "                temp_list = np.random.choice(temp_list)\n",
    "                temp[1][k] = X_data[np.random.choice(temp_list)]\n",
    "\n",
    "        result = model.predict(temp)\n",
    "        result = result.flatten().tolist()\n",
    "        result_index = result.index(min(result))\n",
    "        if result_index == 0:\n",
    "            n_correct = n_correct + 1\n",
    "    print(n_correct, \"correctly classified among\", n_val)\n",
    "    accuracy = (n_correct*100)/n_val\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Loss: [36.413150787353516, 0.5]\n",
      "Epoch: 2 , Loss: [36.19757843017578, 0.53125]\n",
      "Epoch: 3 , Loss: [35.958553314208984, 0.59375]\n",
      "Epoch: 4 , Loss: [35.629783630371094, 0.46875]\n",
      "Epoch: 5 , Loss: [35.264427185058594, 0.46875]\n",
      "Epoch: 6 , Loss: [34.9962158203125, 0.484375]\n",
      "Epoch: 7 , Loss: [34.607017517089844, 0.484375]\n",
      "Epoch: 8 , Loss: [34.0762939453125, 0.484375]\n",
      "Epoch: 9 , Loss: [33.96660614013672, 0.46875]\n",
      "Epoch: 10 , Loss: [33.522891998291016, 0.453125]\n",
      "Epoch: 11 , Loss: [33.204803466796875, 0.5]\n",
      "Epoch: 12 , Loss: [32.95225524902344, 0.453125]\n",
      "Epoch: 13 , Loss: [32.328521728515625, 0.59375]\n",
      "Epoch: 14 , Loss: [32.29762268066406, 0.53125]\n",
      "Epoch: 15 , Loss: [32.1262092590332, 0.46875]\n",
      "Epoch: 16 , Loss: [31.531391143798828, 0.484375]\n",
      "Epoch: 17 , Loss: [31.467618942260742, 0.53125]\n",
      "Epoch: 18 , Loss: [31.27994155883789, 0.515625]\n",
      "Epoch: 19 , Loss: [31.004077911376953, 0.546875]\n",
      "Epoch: 20 , Loss: [30.675342559814453, 0.453125]\n",
      "Epoch: 21 , Loss: [30.415199279785156, 0.578125]\n",
      "Epoch: 22 , Loss: [30.164323806762695, 0.515625]\n",
      "Epoch: 23 , Loss: [30.069438934326172, 0.46875]\n",
      "Epoch: 24 , Loss: [29.333484649658203, 0.59375]\n",
      "Epoch: 25 , Loss: [29.462610244750977, 0.515625]\n",
      "Epoch: 26 , Loss: [29.16908836364746, 0.515625]\n",
      "Epoch: 27 , Loss: [28.74136734008789, 0.5]\n",
      "Epoch: 28 , Loss: [28.928730010986328, 0.484375]\n",
      "Epoch: 29 , Loss: [28.97991943359375, 0.40625]\n",
      "Epoch: 30 , Loss: [28.34385108947754, 0.421875]\n",
      "Epoch: 31 , Loss: [27.887495040893555, 0.453125]\n",
      "Epoch: 32 , Loss: [27.689117431640625, 0.546875]\n",
      "Epoch: 33 , Loss: [27.869522094726562, 0.46875]\n",
      "Epoch: 34 , Loss: [27.39365005493164, 0.484375]\n",
      "Epoch: 35 , Loss: [26.984560012817383, 0.546875]\n",
      "Epoch: 36 , Loss: [27.319164276123047, 0.46875]\n",
      "Epoch: 37 , Loss: [26.57485580444336, 0.515625]\n",
      "Epoch: 38 , Loss: [26.6322021484375, 0.515625]\n",
      "Epoch: 39 , Loss: [26.318620681762695, 0.53125]\n",
      "Epoch: 40 , Loss: [26.303817749023438, 0.453125]\n",
      "Epoch: 41 , Loss: [26.032302856445312, 0.5625]\n",
      "Epoch: 42 , Loss: [26.061744689941406, 0.421875]\n",
      "Epoch: 43 , Loss: [25.827625274658203, 0.4375]\n",
      "Epoch: 44 , Loss: [24.789196014404297, 0.640625]\n",
      "Epoch: 45 , Loss: [25.025131225585938, 0.59375]\n",
      "Epoch: 46 , Loss: [25.072721481323242, 0.53125]\n",
      "Epoch: 47 , Loss: [25.11685562133789, 0.4375]\n",
      "Epoch: 48 , Loss: [24.880191802978516, 0.5]\n",
      "Epoch: 49 , Loss: [24.861942291259766, 0.515625]\n",
      "Epoch: 50 , Loss: [24.13701629638672, 0.59375]\n",
      "Epoch: 51 , Loss: [24.4191951751709, 0.515625]\n",
      "Epoch: 52 , Loss: [24.679889678955078, 0.421875]\n",
      "Epoch: 53 , Loss: [23.736045837402344, 0.515625]\n",
      "Epoch: 54 , Loss: [23.8660831451416, 0.4375]\n",
      "Epoch: 55 , Loss: [23.90555191040039, 0.484375]\n",
      "Epoch: 56 , Loss: [23.665382385253906, 0.453125]\n",
      "Epoch: 57 , Loss: [23.271892547607422, 0.5625]\n",
      "Epoch: 58 , Loss: [22.86322593688965, 0.5625]\n",
      "Epoch: 59 , Loss: [22.968429565429688, 0.578125]\n",
      "Epoch: 60 , Loss: [22.79177474975586, 0.515625]\n",
      "Epoch: 61 , Loss: [22.573413848876953, 0.53125]\n",
      "Epoch: 62 , Loss: [22.988880157470703, 0.4375]\n",
      "Epoch: 63 , Loss: [22.068222045898438, 0.53125]\n",
      "Epoch: 64 , Loss: [22.3798885345459, 0.453125]\n",
      "Epoch: 65 , Loss: [22.296470642089844, 0.453125]\n",
      "Epoch: 66 , Loss: [22.416095733642578, 0.390625]\n",
      "Epoch: 67 , Loss: [21.952146530151367, 0.53125]\n",
      "Epoch: 68 , Loss: [21.749271392822266, 0.5]\n",
      "Epoch: 69 , Loss: [21.40092658996582, 0.5625]\n",
      "Epoch: 70 , Loss: [21.547510147094727, 0.46875]\n",
      "Epoch: 71 , Loss: [21.485790252685547, 0.421875]\n",
      "Epoch: 72 , Loss: [21.103302001953125, 0.53125]\n",
      "Epoch: 73 , Loss: [21.42060089111328, 0.4375]\n",
      "Epoch: 74 , Loss: [20.98106575012207, 0.390625]\n",
      "Epoch: 75 , Loss: [20.9766845703125, 0.515625]\n",
      "Epoch: 76 , Loss: [20.702247619628906, 0.5625]\n",
      "Epoch: 77 , Loss: [20.66120147705078, 0.515625]\n",
      "Epoch: 78 , Loss: [20.612558364868164, 0.5]\n",
      "Epoch: 79 , Loss: [20.26209259033203, 0.59375]\n",
      "Epoch: 80 , Loss: [20.544158935546875, 0.5]\n",
      "Epoch: 81 , Loss: [20.598529815673828, 0.46875]\n",
      "Epoch: 82 , Loss: [20.262676239013672, 0.5625]\n",
      "Epoch: 83 , Loss: [20.008159637451172, 0.515625]\n",
      "Epoch: 84 , Loss: [19.718624114990234, 0.578125]\n",
      "Epoch: 85 , Loss: [20.280746459960938, 0.484375]\n",
      "Epoch: 86 , Loss: [19.715187072753906, 0.5]\n",
      "Epoch: 87 , Loss: [19.643476486206055, 0.484375]\n",
      "Epoch: 88 , Loss: [19.694377899169922, 0.453125]\n",
      "Epoch: 89 , Loss: [19.59027099609375, 0.5]\n",
      "Epoch: 90 , Loss: [19.13189697265625, 0.5625]\n",
      "Epoch: 91 , Loss: [19.74291229248047, 0.375]\n",
      "Epoch: 92 , Loss: [18.912220001220703, 0.578125]\n",
      "Epoch: 93 , Loss: [19.403696060180664, 0.484375]\n",
      "Epoch: 94 , Loss: [19.05487823486328, 0.5]\n",
      "Epoch: 95 , Loss: [18.80465316772461, 0.515625]\n",
      "Epoch: 96 , Loss: [18.622358322143555, 0.53125]\n",
      "Epoch: 97 , Loss: [18.494544982910156, 0.515625]\n",
      "Epoch: 98 , Loss: [18.557058334350586, 0.484375]\n",
      "Epoch: 99 , Loss: [18.86984634399414, 0.421875]\n",
      "Epoch: 100 , Loss: [19.3450984954834, 0.375]\n",
      "Epoch: 101 , Loss: [18.337209701538086, 0.546875]\n",
      "Epoch: 102 , Loss: [18.490442276000977, 0.484375]\n",
      "Epoch: 103 , Loss: [18.166645050048828, 0.421875]\n",
      "Epoch: 104 , Loss: [18.212244033813477, 0.46875]\n",
      "Epoch: 105 , Loss: [17.77307891845703, 0.515625]\n",
      "Epoch: 106 , Loss: [17.95151138305664, 0.5]\n",
      "Epoch: 107 , Loss: [18.073253631591797, 0.453125]\n",
      "Epoch: 108 , Loss: [17.68403434753418, 0.546875]\n",
      "Epoch: 109 , Loss: [17.42801284790039, 0.625]\n",
      "Epoch: 110 , Loss: [18.163612365722656, 0.390625]\n",
      "Epoch: 111 , Loss: [17.637950897216797, 0.40625]\n",
      "Epoch: 112 , Loss: [17.234214782714844, 0.5625]\n",
      "Epoch: 113 , Loss: [17.11519432067871, 0.609375]\n",
      "Epoch: 114 , Loss: [17.474000930786133, 0.53125]\n",
      "Epoch: 115 , Loss: [17.068805694580078, 0.546875]\n",
      "Epoch: 116 , Loss: [17.133974075317383, 0.484375]\n",
      "Epoch: 117 , Loss: [17.018817901611328, 0.578125]\n",
      "Epoch: 118 , Loss: [17.128646850585938, 0.453125]\n",
      "Epoch: 119 , Loss: [16.86220932006836, 0.484375]\n",
      "Epoch: 120 , Loss: [17.00336265563965, 0.421875]\n",
      "Epoch: 121 , Loss: [16.760852813720703, 0.53125]\n",
      "Epoch: 122 , Loss: [16.560848236083984, 0.5625]\n",
      "Epoch: 123 , Loss: [16.36186981201172, 0.59375]\n",
      "Epoch: 124 , Loss: [16.421667098999023, 0.515625]\n",
      "Epoch: 125 , Loss: [16.57917594909668, 0.5]\n",
      "Epoch: 126 , Loss: [16.525672912597656, 0.4375]\n",
      "Epoch: 127 , Loss: [16.308984756469727, 0.5]\n",
      "Epoch: 128 , Loss: [15.998187065124512, 0.546875]\n",
      "Epoch: 129 , Loss: [16.415102005004883, 0.421875]\n",
      "Epoch: 130 , Loss: [16.014543533325195, 0.53125]\n",
      "Epoch: 131 , Loss: [15.976351737976074, 0.546875]\n",
      "Epoch: 132 , Loss: [16.297571182250977, 0.40625]\n",
      "Epoch: 133 , Loss: [15.891000747680664, 0.5625]\n",
      "Epoch: 134 , Loss: [15.857852935791016, 0.546875]\n",
      "Epoch: 135 , Loss: [15.96971321105957, 0.4375]\n",
      "Epoch: 136 , Loss: [15.730087280273438, 0.5]\n",
      "Epoch: 137 , Loss: [15.775656700134277, 0.484375]\n",
      "Epoch: 138 , Loss: [15.533516883850098, 0.4375]\n",
      "Epoch: 139 , Loss: [15.49394416809082, 0.53125]\n",
      "Epoch: 140 , Loss: [15.35252857208252, 0.5625]\n",
      "Epoch: 141 , Loss: [15.196247100830078, 0.546875]\n",
      "Epoch: 142 , Loss: [15.14869213104248, 0.546875]\n",
      "Epoch: 143 , Loss: [15.351631164550781, 0.359375]\n",
      "Epoch: 144 , Loss: [14.929315567016602, 0.484375]\n",
      "Epoch: 145 , Loss: [14.796808242797852, 0.625]\n",
      "Epoch: 146 , Loss: [14.872220039367676, 0.53125]\n",
      "Epoch: 147 , Loss: [14.9046630859375, 0.4375]\n",
      "Epoch: 148 , Loss: [15.207806587219238, 0.34375]\n",
      "Epoch: 149 , Loss: [14.973907470703125, 0.359375]\n",
      "Epoch: 150 , Loss: [14.59467887878418, 0.484375]\n",
      "Epoch: 151 , Loss: [14.47271728515625, 0.578125]\n",
      "Epoch: 152 , Loss: [14.579915046691895, 0.546875]\n",
      "Epoch: 153 , Loss: [14.442611694335938, 0.546875]\n",
      "Epoch: 154 , Loss: [14.244661331176758, 0.625]\n",
      "Epoch: 155 , Loss: [14.54328727722168, 0.53125]\n",
      "Epoch: 156 , Loss: [14.250162124633789, 0.578125]\n",
      "Epoch: 157 , Loss: [14.300941467285156, 0.546875]\n",
      "Epoch: 158 , Loss: [14.357972145080566, 0.484375]\n",
      "Epoch: 159 , Loss: [14.282198905944824, 0.484375]\n",
      "Epoch: 160 , Loss: [14.319859504699707, 0.53125]\n",
      "Epoch: 161 , Loss: [14.230504989624023, 0.515625]\n",
      "Epoch: 162 , Loss: [14.404756546020508, 0.484375]\n",
      "Epoch: 163 , Loss: [14.4067964553833, 0.359375]\n",
      "Epoch: 164 , Loss: [13.85897445678711, 0.5]\n",
      "Epoch: 165 , Loss: [13.75914192199707, 0.546875]\n",
      "Epoch: 166 , Loss: [13.768766403198242, 0.484375]\n",
      "Epoch: 167 , Loss: [13.786138534545898, 0.4375]\n",
      "Epoch: 168 , Loss: [13.730119705200195, 0.46875]\n",
      "Epoch: 169 , Loss: [13.651098251342773, 0.484375]\n",
      "Epoch: 170 , Loss: [13.416576385498047, 0.53125]\n",
      "Epoch: 171 , Loss: [13.68002986907959, 0.46875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 172 , Loss: [13.570953369140625, 0.453125]\n",
      "Epoch: 173 , Loss: [13.2342529296875, 0.515625]\n",
      "Epoch: 174 , Loss: [13.668811798095703, 0.34375]\n",
      "Epoch: 175 , Loss: [13.416696548461914, 0.4375]\n",
      "Epoch: 176 , Loss: [13.083231925964355, 0.59375]\n",
      "Epoch: 177 , Loss: [13.134989738464355, 0.546875]\n",
      "Epoch: 178 , Loss: [13.085309982299805, 0.484375]\n",
      "Epoch: 179 , Loss: [13.01218032836914, 0.59375]\n",
      "Epoch: 180 , Loss: [13.3836030960083, 0.421875]\n",
      "Epoch: 181 , Loss: [12.926779747009277, 0.515625]\n",
      "Epoch: 182 , Loss: [12.900328636169434, 0.59375]\n",
      "Epoch: 183 , Loss: [13.002784729003906, 0.5]\n",
      "Epoch: 184 , Loss: [12.774658203125, 0.546875]\n",
      "Epoch: 185 , Loss: [12.826277732849121, 0.484375]\n",
      "Epoch: 186 , Loss: [12.756367683410645, 0.53125]\n",
      "Epoch: 187 , Loss: [12.50297737121582, 0.578125]\n",
      "Epoch: 188 , Loss: [12.543216705322266, 0.5625]\n",
      "Epoch: 189 , Loss: [12.639472961425781, 0.5]\n",
      "Epoch: 190 , Loss: [12.692861557006836, 0.46875]\n",
      "Epoch: 191 , Loss: [12.660715103149414, 0.5]\n",
      "Epoch: 192 , Loss: [12.349323272705078, 0.515625]\n",
      "Epoch: 193 , Loss: [12.32773208618164, 0.578125]\n",
      "Epoch: 194 , Loss: [12.131085395812988, 0.578125]\n",
      "Epoch: 195 , Loss: [12.29559326171875, 0.53125]\n",
      "Epoch: 196 , Loss: [12.218029975891113, 0.46875]\n",
      "Epoch: 197 , Loss: [12.129732131958008, 0.578125]\n",
      "Epoch: 198 , Loss: [12.109579086303711, 0.53125]\n",
      "Epoch: 199 , Loss: [12.223615646362305, 0.453125]\n",
      "Epoch: 200 , Loss: [12.165800094604492, 0.4375]\n",
      "Epoch: 201 , Loss: [11.886336326599121, 0.578125]\n",
      "Epoch: 202 , Loss: [12.061347007751465, 0.46875]\n",
      "Epoch: 203 , Loss: [12.146531105041504, 0.484375]\n",
      "Epoch: 204 , Loss: [11.878019332885742, 0.5]\n",
      "Epoch: 205 , Loss: [12.276165008544922, 0.328125]\n",
      "Epoch: 206 , Loss: [11.783235549926758, 0.484375]\n",
      "Epoch: 207 , Loss: [11.661405563354492, 0.5]\n",
      "Epoch: 208 , Loss: [11.67326545715332, 0.53125]\n",
      "Epoch: 209 , Loss: [11.564977645874023, 0.5625]\n",
      "Epoch: 210 , Loss: [11.739883422851562, 0.515625]\n",
      "Epoch: 211 , Loss: [11.497374534606934, 0.484375]\n",
      "Epoch: 212 , Loss: [11.754331588745117, 0.453125]\n",
      "Epoch: 213 , Loss: [11.474344253540039, 0.5625]\n",
      "Epoch: 214 , Loss: [11.703627586364746, 0.421875]\n",
      "Epoch: 215 , Loss: [11.345338821411133, 0.5625]\n",
      "Epoch: 216 , Loss: [11.527090072631836, 0.46875]\n",
      "Epoch: 217 , Loss: [11.527975082397461, 0.40625]\n",
      "Epoch: 218 , Loss: [11.294988632202148, 0.453125]\n",
      "Epoch: 219 , Loss: [11.404424667358398, 0.53125]\n",
      "Epoch: 220 , Loss: [11.182302474975586, 0.4375]\n",
      "Epoch: 221 , Loss: [11.11011791229248, 0.59375]\n",
      "Epoch: 222 , Loss: [11.216772079467773, 0.375]\n",
      "Epoch: 223 , Loss: [11.171684265136719, 0.53125]\n",
      "Epoch: 224 , Loss: [11.255477905273438, 0.46875]\n",
      "Epoch: 225 , Loss: [11.068987846374512, 0.46875]\n",
      "Epoch: 226 , Loss: [10.816580772399902, 0.515625]\n",
      "Epoch: 227 , Loss: [10.905158042907715, 0.5625]\n",
      "Epoch: 228 , Loss: [11.172735214233398, 0.34375]\n",
      "Epoch: 229 , Loss: [10.822036743164062, 0.484375]\n",
      "Epoch: 230 , Loss: [10.815916061401367, 0.4375]\n",
      "Epoch: 231 , Loss: [10.7465238571167, 0.53125]\n",
      "Epoch: 232 , Loss: [10.84669017791748, 0.484375]\n",
      "Epoch: 233 , Loss: [10.67795467376709, 0.484375]\n",
      "Epoch: 234 , Loss: [10.692768096923828, 0.515625]\n",
      "Epoch: 235 , Loss: [10.677473068237305, 0.484375]\n",
      "Epoch: 236 , Loss: [10.477096557617188, 0.578125]\n",
      "Epoch: 237 , Loss: [10.598870277404785, 0.46875]\n",
      "Epoch: 238 , Loss: [10.440131187438965, 0.46875]\n",
      "Epoch: 239 , Loss: [10.779897689819336, 0.375]\n",
      "Epoch: 240 , Loss: [10.52622127532959, 0.46875]\n",
      "Epoch: 241 , Loss: [10.45326042175293, 0.5]\n",
      "Epoch: 242 , Loss: [10.429886817932129, 0.546875]\n",
      "Epoch: 243 , Loss: [10.274675369262695, 0.515625]\n",
      "Epoch: 244 , Loss: [10.312524795532227, 0.5]\n",
      "Epoch: 245 , Loss: [10.33586311340332, 0.46875]\n",
      "Epoch: 246 , Loss: [10.381269454956055, 0.5]\n",
      "Epoch: 247 , Loss: [10.344892501831055, 0.5]\n",
      "Epoch: 248 , Loss: [10.275677680969238, 0.453125]\n",
      "Epoch: 249 , Loss: [9.980207443237305, 0.59375]\n",
      "Epoch: 250 , Loss: [10.101240158081055, 0.53125]\n",
      "=============================================\n",
      "2 correctly classified among 64\n",
      "Accuracy as of 250 epochs: 3.125\n",
      "=============================================\n",
      "Epoch: 251 , Loss: [10.080650329589844, 0.40625]\n",
      "Epoch: 252 , Loss: [9.825119972229004, 0.625]\n",
      "Epoch: 253 , Loss: [10.151679992675781, 0.4375]\n",
      "Epoch: 254 , Loss: [10.013577461242676, 0.5]\n",
      "Epoch: 255 , Loss: [10.028200149536133, 0.4375]\n",
      "Epoch: 256 , Loss: [9.909208297729492, 0.53125]\n",
      "Epoch: 257 , Loss: [9.678253173828125, 0.53125]\n",
      "Epoch: 258 , Loss: [9.881470680236816, 0.46875]\n",
      "Epoch: 259 , Loss: [9.735771179199219, 0.546875]\n",
      "Epoch: 260 , Loss: [9.745874404907227, 0.46875]\n",
      "Epoch: 261 , Loss: [9.614594459533691, 0.578125]\n",
      "Epoch: 262 , Loss: [9.581491470336914, 0.5625]\n",
      "Epoch: 263 , Loss: [9.651811599731445, 0.421875]\n",
      "Epoch: 264 , Loss: [9.478656768798828, 0.46875]\n",
      "Epoch: 265 , Loss: [9.56471061706543, 0.515625]\n",
      "Epoch: 266 , Loss: [9.536630630493164, 0.5]\n",
      "Epoch: 267 , Loss: [9.658230781555176, 0.53125]\n",
      "Epoch: 268 , Loss: [9.560335159301758, 0.546875]\n",
      "Epoch: 269 , Loss: [9.58673095703125, 0.515625]\n",
      "Epoch: 270 , Loss: [9.444082260131836, 0.40625]\n",
      "Epoch: 271 , Loss: [9.31230354309082, 0.546875]\n",
      "Epoch: 272 , Loss: [9.396759986877441, 0.4375]\n",
      "Epoch: 273 , Loss: [9.36504077911377, 0.484375]\n",
      "Epoch: 274 , Loss: [9.330330848693848, 0.375]\n",
      "Epoch: 275 , Loss: [9.3353853225708, 0.578125]\n",
      "Epoch: 276 , Loss: [9.241491317749023, 0.4375]\n",
      "Epoch: 277 , Loss: [9.26038646697998, 0.46875]\n",
      "Epoch: 278 , Loss: [9.495718955993652, 0.453125]\n",
      "Epoch: 279 , Loss: [8.92861270904541, 0.625]\n",
      "Epoch: 280 , Loss: [9.1055269241333, 0.515625]\n",
      "Epoch: 281 , Loss: [9.281244277954102, 0.453125]\n",
      "Epoch: 282 , Loss: [9.122209548950195, 0.5]\n",
      "Epoch: 283 , Loss: [9.17803955078125, 0.4375]\n",
      "Epoch: 284 , Loss: [9.087728500366211, 0.46875]\n",
      "Epoch: 285 , Loss: [9.098459243774414, 0.375]\n",
      "Epoch: 286 , Loss: [8.922335624694824, 0.46875]\n",
      "Epoch: 287 , Loss: [9.177125930786133, 0.328125]\n",
      "Epoch: 288 , Loss: [8.798096656799316, 0.546875]\n",
      "Epoch: 289 , Loss: [8.82738208770752, 0.5]\n",
      "Epoch: 290 , Loss: [8.659102439880371, 0.59375]\n",
      "Epoch: 291 , Loss: [8.73221492767334, 0.53125]\n",
      "Epoch: 292 , Loss: [8.71062183380127, 0.484375]\n",
      "Epoch: 293 , Loss: [8.63320541381836, 0.546875]\n",
      "Epoch: 294 , Loss: [8.669655799865723, 0.390625]\n",
      "Epoch: 295 , Loss: [8.871818542480469, 0.390625]\n",
      "Epoch: 296 , Loss: [8.723395347595215, 0.515625]\n",
      "Epoch: 297 , Loss: [8.539915084838867, 0.59375]\n",
      "Epoch: 298 , Loss: [8.48238754272461, 0.453125]\n",
      "Epoch: 299 , Loss: [8.27773666381836, 0.671875]\n",
      "Epoch: 300 , Loss: [8.584946632385254, 0.484375]\n",
      "Epoch: 301 , Loss: [8.339899063110352, 0.5625]\n",
      "Epoch: 302 , Loss: [8.652721405029297, 0.4375]\n",
      "Epoch: 303 , Loss: [8.563220024108887, 0.46875]\n",
      "Epoch: 304 , Loss: [8.402871131896973, 0.53125]\n",
      "Epoch: 305 , Loss: [8.518339157104492, 0.46875]\n",
      "Epoch: 306 , Loss: [8.3197021484375, 0.515625]\n",
      "Epoch: 307 , Loss: [8.470942497253418, 0.421875]\n",
      "Epoch: 308 , Loss: [8.571417808532715, 0.375]\n",
      "Epoch: 309 , Loss: [8.43101692199707, 0.453125]\n",
      "Epoch: 310 , Loss: [8.24450969696045, 0.515625]\n",
      "Epoch: 311 , Loss: [8.364278793334961, 0.34375]\n",
      "Epoch: 312 , Loss: [8.120984077453613, 0.515625]\n",
      "Epoch: 313 , Loss: [8.165544509887695, 0.484375]\n",
      "Epoch: 314 , Loss: [8.108893394470215, 0.4375]\n",
      "Epoch: 315 , Loss: [8.170762062072754, 0.4375]\n",
      "Epoch: 316 , Loss: [8.320791244506836, 0.375]\n",
      "Epoch: 317 , Loss: [7.927586555480957, 0.546875]\n",
      "Epoch: 318 , Loss: [7.91135835647583, 0.5625]\n",
      "Epoch: 319 , Loss: [8.052955627441406, 0.46875]\n",
      "Epoch: 320 , Loss: [8.189969062805176, 0.453125]\n",
      "Epoch: 321 , Loss: [7.894748687744141, 0.5]\n",
      "Epoch: 322 , Loss: [8.047307014465332, 0.359375]\n",
      "Epoch: 323 , Loss: [8.048604965209961, 0.53125]\n",
      "Epoch: 324 , Loss: [7.812536239624023, 0.5]\n",
      "Epoch: 325 , Loss: [7.813568115234375, 0.5]\n",
      "Epoch: 326 , Loss: [7.8565673828125, 0.46875]\n",
      "Epoch: 327 , Loss: [7.617244243621826, 0.625]\n",
      "Epoch: 328 , Loss: [7.945103645324707, 0.359375]\n",
      "Epoch: 329 , Loss: [7.708719253540039, 0.5625]\n",
      "Epoch: 330 , Loss: [7.809358596801758, 0.5]\n",
      "Epoch: 331 , Loss: [7.614232063293457, 0.5625]\n",
      "Epoch: 332 , Loss: [7.8721723556518555, 0.484375]\n",
      "Epoch: 333 , Loss: [7.544654369354248, 0.546875]\n",
      "Epoch: 334 , Loss: [7.670001983642578, 0.4375]\n",
      "Epoch: 335 , Loss: [7.7287702560424805, 0.40625]\n",
      "Epoch: 336 , Loss: [7.478946685791016, 0.515625]\n",
      "Epoch: 337 , Loss: [7.546962738037109, 0.5]\n",
      "Epoch: 338 , Loss: [7.50313138961792, 0.5]\n",
      "Epoch: 339 , Loss: [7.607393741607666, 0.34375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340 , Loss: [7.50798225402832, 0.4375]\n",
      "Epoch: 341 , Loss: [7.413730621337891, 0.59375]\n",
      "Epoch: 342 , Loss: [7.435927867889404, 0.484375]\n",
      "Epoch: 343 , Loss: [7.542851448059082, 0.484375]\n",
      "Epoch: 344 , Loss: [7.238460540771484, 0.609375]\n",
      "Epoch: 345 , Loss: [7.355165958404541, 0.484375]\n",
      "Epoch: 346 , Loss: [7.221383094787598, 0.5]\n",
      "Epoch: 347 , Loss: [7.164600372314453, 0.59375]\n",
      "Epoch: 348 , Loss: [7.392096519470215, 0.421875]\n",
      "Epoch: 349 , Loss: [7.224465370178223, 0.53125]\n",
      "Epoch: 350 , Loss: [7.164438724517822, 0.546875]\n",
      "Epoch: 351 , Loss: [7.323452949523926, 0.46875]\n",
      "Epoch: 352 , Loss: [7.151773929595947, 0.53125]\n",
      "Epoch: 353 , Loss: [6.99727725982666, 0.625]\n",
      "Epoch: 354 , Loss: [7.200167179107666, 0.4375]\n",
      "Epoch: 355 , Loss: [7.2054033279418945, 0.421875]\n",
      "Epoch: 356 , Loss: [7.109163284301758, 0.5]\n",
      "Epoch: 357 , Loss: [7.06820011138916, 0.484375]\n",
      "Epoch: 358 , Loss: [7.200517654418945, 0.453125]\n",
      "Epoch: 359 , Loss: [6.960214614868164, 0.546875]\n",
      "Epoch: 360 , Loss: [7.207374572753906, 0.375]\n",
      "Epoch: 361 , Loss: [7.112139701843262, 0.5]\n",
      "Epoch: 362 , Loss: [7.113156318664551, 0.46875]\n",
      "Epoch: 363 , Loss: [7.105223178863525, 0.53125]\n",
      "Epoch: 364 , Loss: [6.845703125, 0.5]\n",
      "Epoch: 365 , Loss: [6.812587261199951, 0.546875]\n",
      "Epoch: 366 , Loss: [6.8523173332214355, 0.5]\n",
      "Epoch: 367 , Loss: [6.863746166229248, 0.4375]\n",
      "Epoch: 368 , Loss: [6.77752685546875, 0.484375]\n",
      "Epoch: 369 , Loss: [6.923457145690918, 0.484375]\n",
      "Epoch: 370 , Loss: [6.731329441070557, 0.515625]\n",
      "Epoch: 371 , Loss: [6.639995574951172, 0.546875]\n",
      "Epoch: 372 , Loss: [6.748208045959473, 0.5]\n",
      "Epoch: 373 , Loss: [6.899118423461914, 0.390625]\n",
      "Epoch: 374 , Loss: [6.7713942527771, 0.53125]\n",
      "Epoch: 375 , Loss: [6.6123762130737305, 0.5]\n",
      "Epoch: 376 , Loss: [6.699699878692627, 0.34375]\n",
      "Epoch: 377 , Loss: [6.649750232696533, 0.484375]\n",
      "Epoch: 378 , Loss: [6.788906574249268, 0.421875]\n",
      "Epoch: 379 , Loss: [6.60087251663208, 0.53125]\n",
      "Epoch: 380 , Loss: [6.593136787414551, 0.609375]\n",
      "Epoch: 381 , Loss: [6.539849758148193, 0.5625]\n",
      "Epoch: 382 , Loss: [6.413768291473389, 0.59375]\n",
      "Epoch: 383 , Loss: [6.707324981689453, 0.40625]\n",
      "Epoch: 384 , Loss: [6.490610122680664, 0.5]\n",
      "Epoch: 385 , Loss: [6.4920244216918945, 0.5]\n",
      "Epoch: 386 , Loss: [6.492130279541016, 0.4375]\n",
      "Epoch: 387 , Loss: [6.219320297241211, 0.71875]\n",
      "Epoch: 388 , Loss: [6.456223011016846, 0.546875]\n",
      "Epoch: 389 , Loss: [6.498476028442383, 0.546875]\n",
      "Epoch: 390 , Loss: [6.500153064727783, 0.484375]\n",
      "Epoch: 391 , Loss: [6.428525447845459, 0.421875]\n",
      "Epoch: 392 , Loss: [6.22678279876709, 0.5625]\n",
      "Epoch: 393 , Loss: [6.340048789978027, 0.546875]\n",
      "Epoch: 394 , Loss: [6.35982084274292, 0.53125]\n",
      "Epoch: 395 , Loss: [6.444108009338379, 0.421875]\n",
      "Epoch: 396 , Loss: [6.383275032043457, 0.4375]\n",
      "Epoch: 397 , Loss: [6.368043422698975, 0.515625]\n",
      "Epoch: 398 , Loss: [6.1644086837768555, 0.59375]\n",
      "Epoch: 399 , Loss: [6.525158882141113, 0.375]\n",
      "Epoch: 400 , Loss: [6.048999786376953, 0.640625]\n",
      "Epoch: 401 , Loss: [6.191038608551025, 0.484375]\n",
      "Epoch: 402 , Loss: [6.1662516593933105, 0.5]\n",
      "Epoch: 403 , Loss: [6.1978278160095215, 0.453125]\n",
      "Epoch: 404 , Loss: [6.137042999267578, 0.421875]\n",
      "Epoch: 405 , Loss: [6.00383996963501, 0.5625]\n",
      "Epoch: 406 , Loss: [6.140671730041504, 0.453125]\n",
      "Epoch: 407 , Loss: [6.153236389160156, 0.53125]\n",
      "Epoch: 408 , Loss: [5.953061580657959, 0.546875]\n",
      "Epoch: 409 , Loss: [6.117978096008301, 0.515625]\n",
      "Epoch: 410 , Loss: [5.9666852951049805, 0.546875]\n",
      "Epoch: 411 , Loss: [5.924345016479492, 0.53125]\n",
      "Epoch: 412 , Loss: [5.984581470489502, 0.5]\n",
      "Epoch: 413 , Loss: [5.870334625244141, 0.578125]\n",
      "Epoch: 414 , Loss: [5.89245080947876, 0.546875]\n",
      "Epoch: 415 , Loss: [5.846983432769775, 0.5625]\n",
      "Epoch: 416 , Loss: [5.958818435668945, 0.515625]\n",
      "Epoch: 417 , Loss: [5.909225940704346, 0.5]\n",
      "Epoch: 418 , Loss: [5.701220512390137, 0.6875]\n",
      "Epoch: 419 , Loss: [5.8338727951049805, 0.53125]\n",
      "Epoch: 420 , Loss: [5.7893900871276855, 0.515625]\n",
      "Epoch: 421 , Loss: [5.768300533294678, 0.546875]\n",
      "Epoch: 422 , Loss: [5.75678825378418, 0.609375]\n",
      "Epoch: 423 , Loss: [5.796866416931152, 0.5625]\n",
      "Epoch: 424 , Loss: [5.813300609588623, 0.546875]\n",
      "Epoch: 425 , Loss: [5.7716064453125, 0.515625]\n",
      "Epoch: 426 , Loss: [5.810220718383789, 0.46875]\n",
      "Epoch: 427 , Loss: [5.881996154785156, 0.4375]\n",
      "Epoch: 428 , Loss: [5.558557033538818, 0.59375]\n",
      "Epoch: 429 , Loss: [5.642749786376953, 0.578125]\n",
      "Epoch: 430 , Loss: [5.829179763793945, 0.40625]\n",
      "Epoch: 431 , Loss: [5.593897819519043, 0.546875]\n",
      "Epoch: 432 , Loss: [5.603448867797852, 0.546875]\n",
      "Epoch: 433 , Loss: [5.521219253540039, 0.578125]\n",
      "Epoch: 434 , Loss: [5.599804878234863, 0.515625]\n",
      "Epoch: 435 , Loss: [5.749387741088867, 0.5]\n",
      "Epoch: 436 , Loss: [5.524083137512207, 0.578125]\n",
      "Epoch: 437 , Loss: [5.658960819244385, 0.4375]\n",
      "Epoch: 438 , Loss: [5.7080183029174805, 0.390625]\n",
      "Epoch: 439 , Loss: [5.640570163726807, 0.46875]\n",
      "Epoch: 440 , Loss: [5.569614410400391, 0.5]\n",
      "Epoch: 441 , Loss: [5.677493572235107, 0.421875]\n",
      "Epoch: 442 , Loss: [5.43122673034668, 0.578125]\n",
      "Epoch: 443 , Loss: [5.56362247467041, 0.46875]\n",
      "Epoch: 444 , Loss: [5.469878196716309, 0.46875]\n",
      "Epoch: 445 , Loss: [5.496153354644775, 0.546875]\n",
      "Epoch: 446 , Loss: [5.55674409866333, 0.484375]\n",
      "Epoch: 447 , Loss: [5.265811920166016, 0.546875]\n",
      "Epoch: 448 , Loss: [5.315505504608154, 0.515625]\n",
      "Epoch: 449 , Loss: [5.349011421203613, 0.578125]\n",
      "Epoch: 450 , Loss: [5.299241065979004, 0.484375]\n",
      "Epoch: 451 , Loss: [5.455904960632324, 0.484375]\n",
      "Epoch: 452 , Loss: [5.441165924072266, 0.515625]\n",
      "Epoch: 453 , Loss: [5.359908103942871, 0.4375]\n",
      "Epoch: 454 , Loss: [5.468951225280762, 0.359375]\n",
      "Epoch: 455 , Loss: [5.304660797119141, 0.53125]\n",
      "Epoch: 456 , Loss: [5.301135063171387, 0.515625]\n",
      "Epoch: 457 , Loss: [5.448057651519775, 0.5]\n",
      "Epoch: 458 , Loss: [5.383239269256592, 0.46875]\n",
      "Epoch: 459 , Loss: [5.405676364898682, 0.4375]\n",
      "Epoch: 460 , Loss: [5.335681915283203, 0.453125]\n",
      "Epoch: 461 , Loss: [5.266100883483887, 0.5]\n",
      "Epoch: 462 , Loss: [5.181229591369629, 0.46875]\n",
      "Epoch: 463 , Loss: [5.25227165222168, 0.53125]\n",
      "Epoch: 464 , Loss: [5.34305477142334, 0.46875]\n",
      "Epoch: 465 , Loss: [5.155894756317139, 0.484375]\n",
      "Epoch: 466 , Loss: [5.131031513214111, 0.5]\n",
      "Epoch: 467 , Loss: [5.271516799926758, 0.4375]\n",
      "Epoch: 468 , Loss: [5.215792655944824, 0.4375]\n",
      "Epoch: 469 , Loss: [5.252612113952637, 0.4375]\n",
      "Epoch: 470 , Loss: [5.0930304527282715, 0.484375]\n",
      "Epoch: 471 , Loss: [5.223660469055176, 0.421875]\n",
      "Epoch: 472 , Loss: [5.1931610107421875, 0.375]\n",
      "Epoch: 473 , Loss: [5.0010881423950195, 0.53125]\n",
      "Epoch: 474 , Loss: [5.116281032562256, 0.484375]\n",
      "Epoch: 475 , Loss: [5.203404903411865, 0.359375]\n",
      "Epoch: 476 , Loss: [5.013275623321533, 0.4375]\n",
      "Epoch: 477 , Loss: [5.077789306640625, 0.453125]\n",
      "Epoch: 478 , Loss: [5.005677700042725, 0.53125]\n",
      "Epoch: 479 , Loss: [5.160605430603027, 0.453125]\n",
      "Epoch: 480 , Loss: [5.139349937438965, 0.4375]\n",
      "Epoch: 481 , Loss: [4.915421009063721, 0.484375]\n",
      "Epoch: 482 , Loss: [4.866366386413574, 0.546875]\n",
      "Epoch: 483 , Loss: [4.8059515953063965, 0.609375]\n",
      "Epoch: 484 , Loss: [4.839752197265625, 0.578125]\n",
      "Epoch: 485 , Loss: [4.881958484649658, 0.53125]\n",
      "Epoch: 486 , Loss: [4.850801467895508, 0.5]\n",
      "Epoch: 487 , Loss: [4.878747940063477, 0.53125]\n",
      "Epoch: 488 , Loss: [5.034931182861328, 0.46875]\n",
      "Epoch: 489 , Loss: [4.841756820678711, 0.546875]\n",
      "Epoch: 490 , Loss: [4.808586120605469, 0.515625]\n",
      "Epoch: 491 , Loss: [5.004153728485107, 0.453125]\n",
      "Epoch: 492 , Loss: [5.032771110534668, 0.40625]\n",
      "Epoch: 493 , Loss: [4.792916774749756, 0.46875]\n",
      "Epoch: 494 , Loss: [4.71624755859375, 0.515625]\n",
      "Epoch: 495 , Loss: [4.701381206512451, 0.515625]\n",
      "Epoch: 496 , Loss: [4.751999378204346, 0.5]\n",
      "Epoch: 497 , Loss: [4.7935404777526855, 0.53125]\n",
      "Epoch: 498 , Loss: [4.706305980682373, 0.53125]\n",
      "Epoch: 499 , Loss: [4.75623893737793, 0.53125]\n",
      "Epoch: 500 , Loss: [4.831667423248291, 0.515625]\n",
      "=============================================\n",
      "3 correctly classified among 64\n",
      "Accuracy as of 500 epochs: 4.6875\n",
      "=============================================\n",
      "Epoch: 501 , Loss: [4.56287145614624, 0.609375]\n",
      "Epoch: 502 , Loss: [4.828205108642578, 0.390625]\n",
      "Epoch: 503 , Loss: [4.599979400634766, 0.59375]\n",
      "Epoch: 504 , Loss: [4.6878342628479, 0.5]\n",
      "Epoch: 505 , Loss: [4.650066375732422, 0.5]\n",
      "Epoch: 506 , Loss: [4.883203029632568, 0.375]\n",
      "Epoch: 507 , Loss: [4.753236770629883, 0.4375]\n",
      "Epoch: 508 , Loss: [4.652621269226074, 0.421875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 509 , Loss: [4.7200822830200195, 0.46875]\n",
      "Epoch: 510 , Loss: [4.690189838409424, 0.40625]\n",
      "Epoch: 511 , Loss: [4.42103385925293, 0.609375]\n",
      "Epoch: 512 , Loss: [4.739438533782959, 0.421875]\n",
      "Epoch: 513 , Loss: [4.512754440307617, 0.546875]\n",
      "Epoch: 514 , Loss: [4.641388416290283, 0.421875]\n",
      "Epoch: 515 , Loss: [4.682775020599365, 0.390625]\n",
      "Epoch: 516 , Loss: [4.467435836791992, 0.546875]\n",
      "Epoch: 517 , Loss: [4.563045978546143, 0.40625]\n",
      "Epoch: 518 , Loss: [4.648697853088379, 0.453125]\n",
      "Epoch: 519 , Loss: [4.487810134887695, 0.5625]\n",
      "Epoch: 520 , Loss: [4.411172389984131, 0.546875]\n",
      "Epoch: 521 , Loss: [4.425206184387207, 0.59375]\n",
      "Epoch: 522 , Loss: [4.527921199798584, 0.421875]\n",
      "Epoch: 523 , Loss: [4.524209976196289, 0.484375]\n",
      "Epoch: 524 , Loss: [4.462250232696533, 0.46875]\n",
      "Epoch: 525 , Loss: [4.359433650970459, 0.53125]\n",
      "Epoch: 526 , Loss: [4.5386962890625, 0.40625]\n",
      "Epoch: 527 , Loss: [4.516570568084717, 0.421875]\n",
      "Epoch: 528 , Loss: [4.319839000701904, 0.515625]\n",
      "Epoch: 529 , Loss: [4.374917030334473, 0.546875]\n",
      "Epoch: 530 , Loss: [4.376183986663818, 0.484375]\n",
      "Epoch: 531 , Loss: [4.378860950469971, 0.515625]\n",
      "Epoch: 532 , Loss: [4.337961673736572, 0.515625]\n",
      "Epoch: 533 , Loss: [4.34108304977417, 0.59375]\n",
      "Epoch: 534 , Loss: [4.298328876495361, 0.515625]\n",
      "Epoch: 535 , Loss: [4.243372440338135, 0.53125]\n",
      "Epoch: 536 , Loss: [4.288642883300781, 0.5625]\n",
      "Epoch: 537 , Loss: [4.357497692108154, 0.484375]\n",
      "Epoch: 538 , Loss: [4.369531154632568, 0.46875]\n",
      "Epoch: 539 , Loss: [4.332149982452393, 0.453125]\n",
      "Epoch: 540 , Loss: [4.203024387359619, 0.625]\n",
      "Epoch: 541 , Loss: [4.443014144897461, 0.40625]\n",
      "Epoch: 542 , Loss: [4.214160919189453, 0.578125]\n",
      "Epoch: 543 , Loss: [4.325026512145996, 0.546875]\n",
      "Epoch: 544 , Loss: [4.207170486450195, 0.484375]\n",
      "Epoch: 545 , Loss: [4.192615509033203, 0.5625]\n",
      "Epoch: 546 , Loss: [4.209583759307861, 0.578125]\n",
      "Epoch: 547 , Loss: [4.234466552734375, 0.53125]\n",
      "Epoch: 548 , Loss: [4.206679821014404, 0.46875]\n",
      "Epoch: 549 , Loss: [4.1215434074401855, 0.609375]\n",
      "Epoch: 550 , Loss: [4.148550987243652, 0.515625]\n",
      "Epoch: 551 , Loss: [4.255692481994629, 0.46875]\n",
      "Epoch: 552 , Loss: [4.14487886428833, 0.5]\n",
      "Epoch: 553 , Loss: [4.220945358276367, 0.484375]\n",
      "Epoch: 554 , Loss: [4.21672248840332, 0.46875]\n",
      "Epoch: 555 , Loss: [4.187731742858887, 0.5]\n",
      "Epoch: 556 , Loss: [4.053463935852051, 0.609375]\n",
      "Epoch: 557 , Loss: [4.2057271003723145, 0.515625]\n",
      "Epoch: 558 , Loss: [4.082244396209717, 0.46875]\n",
      "Epoch: 559 , Loss: [4.084600448608398, 0.46875]\n",
      "Epoch: 560 , Loss: [4.208398342132568, 0.46875]\n",
      "Epoch: 561 , Loss: [4.10418701171875, 0.453125]\n",
      "Epoch: 562 , Loss: [4.083982467651367, 0.546875]\n",
      "Epoch: 563 , Loss: [3.99021577835083, 0.453125]\n",
      "Epoch: 564 , Loss: [4.107424736022949, 0.53125]\n",
      "Epoch: 565 , Loss: [4.157341003417969, 0.4375]\n",
      "Epoch: 566 , Loss: [4.094627380371094, 0.46875]\n",
      "Epoch: 567 , Loss: [4.046410083770752, 0.484375]\n",
      "Epoch: 568 , Loss: [4.11004638671875, 0.453125]\n",
      "Epoch: 569 , Loss: [4.023070812225342, 0.5625]\n",
      "Epoch: 570 , Loss: [4.084109783172607, 0.5]\n",
      "Epoch: 571 , Loss: [3.9290688037872314, 0.53125]\n",
      "Epoch: 572 , Loss: [4.096126079559326, 0.4375]\n",
      "Epoch: 573 , Loss: [3.7522220611572266, 0.5625]\n",
      "Epoch: 574 , Loss: [3.809175968170166, 0.5625]\n",
      "Epoch: 575 , Loss: [4.044142723083496, 0.4375]\n",
      "Epoch: 576 , Loss: [3.929816246032715, 0.5]\n",
      "Epoch: 577 , Loss: [3.825084686279297, 0.5625]\n",
      "Epoch: 578 , Loss: [3.749195098876953, 0.625]\n",
      "Epoch: 579 , Loss: [3.964735746383667, 0.40625]\n",
      "Epoch: 580 , Loss: [3.9851551055908203, 0.5625]\n",
      "Epoch: 581 , Loss: [4.011872291564941, 0.484375]\n",
      "Epoch: 582 , Loss: [3.9731171131134033, 0.5]\n",
      "Epoch: 583 , Loss: [3.856203079223633, 0.515625]\n",
      "Epoch: 584 , Loss: [3.710860252380371, 0.609375]\n",
      "Epoch: 585 , Loss: [3.7879180908203125, 0.515625]\n",
      "Epoch: 586 , Loss: [3.855180025100708, 0.546875]\n",
      "Epoch: 587 , Loss: [3.785512924194336, 0.5625]\n",
      "Epoch: 588 , Loss: [3.785252571105957, 0.5]\n",
      "Epoch: 589 , Loss: [3.7376787662506104, 0.53125]\n",
      "Epoch: 590 , Loss: [3.8162217140197754, 0.484375]\n",
      "Epoch: 591 , Loss: [3.8470592498779297, 0.40625]\n",
      "Epoch: 592 , Loss: [3.7030656337738037, 0.53125]\n",
      "Epoch: 593 , Loss: [3.964951276779175, 0.40625]\n",
      "Epoch: 594 , Loss: [3.82462215423584, 0.46875]\n",
      "Epoch: 595 , Loss: [3.7696533203125, 0.484375]\n",
      "Epoch: 596 , Loss: [3.8249459266662598, 0.5]\n",
      "Epoch: 597 , Loss: [3.7342190742492676, 0.453125]\n",
      "Epoch: 598 , Loss: [3.690505027770996, 0.5]\n",
      "Epoch: 599 , Loss: [3.7560644149780273, 0.5]\n",
      "Epoch: 600 , Loss: [3.6679325103759766, 0.484375]\n",
      "Epoch: 601 , Loss: [3.720458507537842, 0.515625]\n",
      "Epoch: 602 , Loss: [3.7472410202026367, 0.484375]\n",
      "Epoch: 603 , Loss: [3.7612361907958984, 0.453125]\n",
      "Epoch: 604 , Loss: [3.668459415435791, 0.453125]\n",
      "Epoch: 605 , Loss: [3.629160165786743, 0.53125]\n",
      "Epoch: 606 , Loss: [3.5832667350769043, 0.46875]\n",
      "Epoch: 607 , Loss: [3.797943115234375, 0.390625]\n",
      "Epoch: 608 , Loss: [3.6806564331054688, 0.515625]\n",
      "Epoch: 609 , Loss: [3.520972967147827, 0.59375]\n",
      "Epoch: 610 , Loss: [3.618746042251587, 0.53125]\n",
      "Epoch: 611 , Loss: [3.700748920440674, 0.46875]\n",
      "Epoch: 612 , Loss: [3.5649871826171875, 0.53125]\n",
      "Epoch: 613 , Loss: [3.473440408706665, 0.5625]\n",
      "Epoch: 614 , Loss: [3.499979019165039, 0.59375]\n",
      "Epoch: 615 , Loss: [3.607614755630493, 0.46875]\n",
      "Epoch: 616 , Loss: [3.6879289150238037, 0.421875]\n",
      "Epoch: 617 , Loss: [3.5463294982910156, 0.546875]\n",
      "Epoch: 618 , Loss: [3.6821162700653076, 0.5]\n",
      "Epoch: 619 , Loss: [3.4965643882751465, 0.546875]\n",
      "Epoch: 620 , Loss: [3.7295379638671875, 0.453125]\n",
      "Epoch: 621 , Loss: [3.6921603679656982, 0.453125]\n",
      "Epoch: 622 , Loss: [3.7971420288085938, 0.375]\n",
      "Epoch: 623 , Loss: [3.6465742588043213, 0.4375]\n",
      "Epoch: 624 , Loss: [3.4304704666137695, 0.59375]\n",
      "Epoch: 625 , Loss: [3.422854423522949, 0.53125]\n",
      "Epoch: 626 , Loss: [3.476905345916748, 0.515625]\n",
      "Epoch: 627 , Loss: [3.501593828201294, 0.5625]\n",
      "Epoch: 628 , Loss: [3.6078922748565674, 0.4375]\n",
      "Epoch: 629 , Loss: [3.3990132808685303, 0.53125]\n",
      "Epoch: 630 , Loss: [3.4619429111480713, 0.5]\n",
      "Epoch: 631 , Loss: [3.4358701705932617, 0.515625]\n",
      "Epoch: 632 , Loss: [3.4643826484680176, 0.484375]\n",
      "Epoch: 633 , Loss: [3.488468647003174, 0.515625]\n",
      "Epoch: 634 , Loss: [3.5171468257904053, 0.484375]\n",
      "Epoch: 635 , Loss: [3.389031171798706, 0.515625]\n",
      "Epoch: 636 , Loss: [3.3698337078094482, 0.5]\n",
      "Epoch: 637 , Loss: [3.3488564491271973, 0.484375]\n",
      "Epoch: 638 , Loss: [3.396198272705078, 0.5]\n",
      "Epoch: 639 , Loss: [3.541358709335327, 0.390625]\n",
      "Epoch: 640 , Loss: [3.5686941146850586, 0.40625]\n",
      "Epoch: 641 , Loss: [3.361659288406372, 0.46875]\n",
      "Epoch: 642 , Loss: [3.5027222633361816, 0.4375]\n",
      "Epoch: 643 , Loss: [3.4061620235443115, 0.5]\n",
      "Epoch: 644 , Loss: [3.3579061031341553, 0.515625]\n",
      "Epoch: 645 , Loss: [3.395873546600342, 0.46875]\n",
      "Epoch: 646 , Loss: [3.2567696571350098, 0.53125]\n",
      "Epoch: 647 , Loss: [3.4266366958618164, 0.40625]\n",
      "Epoch: 648 , Loss: [3.384871006011963, 0.46875]\n",
      "Epoch: 649 , Loss: [3.399090051651001, 0.46875]\n",
      "Epoch: 650 , Loss: [3.188896656036377, 0.65625]\n",
      "Epoch: 651 , Loss: [3.343186855316162, 0.5625]\n",
      "Epoch: 652 , Loss: [3.188298463821411, 0.625]\n",
      "Epoch: 653 , Loss: [3.155411720275879, 0.703125]\n",
      "Epoch: 654 , Loss: [3.3151869773864746, 0.5]\n",
      "Epoch: 655 , Loss: [3.290161371231079, 0.484375]\n",
      "Epoch: 656 , Loss: [3.4021224975585938, 0.421875]\n",
      "Epoch: 657 , Loss: [3.230027675628662, 0.5625]\n",
      "Epoch: 658 , Loss: [3.310835599899292, 0.4375]\n",
      "Epoch: 659 , Loss: [3.364231824874878, 0.46875]\n",
      "Epoch: 660 , Loss: [3.4416184425354004, 0.4375]\n",
      "Epoch: 661 , Loss: [3.319228172302246, 0.40625]\n",
      "Epoch: 662 , Loss: [3.3081305027008057, 0.515625]\n",
      "Epoch: 663 , Loss: [3.146197557449341, 0.515625]\n",
      "Epoch: 664 , Loss: [3.105480432510376, 0.578125]\n",
      "Epoch: 665 , Loss: [3.357788324356079, 0.484375]\n",
      "Epoch: 666 , Loss: [3.223284959793091, 0.53125]\n",
      "Epoch: 667 , Loss: [3.1499409675598145, 0.515625]\n",
      "Epoch: 668 , Loss: [3.222918748855591, 0.453125]\n",
      "Epoch: 669 , Loss: [3.2159271240234375, 0.53125]\n",
      "Epoch: 670 , Loss: [3.1199402809143066, 0.5625]\n",
      "Epoch: 671 , Loss: [3.070422410964966, 0.59375]\n",
      "Epoch: 672 , Loss: [3.3079347610473633, 0.4375]\n",
      "Epoch: 673 , Loss: [3.273773193359375, 0.375]\n",
      "Epoch: 674 , Loss: [3.116549015045166, 0.5625]\n",
      "Epoch: 675 , Loss: [3.0801987648010254, 0.515625]\n",
      "Epoch: 676 , Loss: [3.1246871948242188, 0.453125]\n",
      "Epoch: 677 , Loss: [3.2353029251098633, 0.5]\n",
      "Epoch: 678 , Loss: [3.2033467292785645, 0.421875]\n",
      "Epoch: 679 , Loss: [3.1399521827697754, 0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 680 , Loss: [3.214555263519287, 0.375]\n",
      "Epoch: 681 , Loss: [3.218021869659424, 0.40625]\n",
      "Epoch: 682 , Loss: [3.1216390132904053, 0.484375]\n",
      "Epoch: 683 , Loss: [3.185838222503662, 0.375]\n",
      "Epoch: 684 , Loss: [3.1630334854125977, 0.5]\n",
      "Epoch: 685 , Loss: [2.952378273010254, 0.5625]\n",
      "Epoch: 686 , Loss: [3.1790051460266113, 0.484375]\n",
      "Epoch: 687 , Loss: [3.159846782684326, 0.421875]\n",
      "Epoch: 688 , Loss: [3.0692853927612305, 0.484375]\n",
      "Epoch: 689 , Loss: [3.002450466156006, 0.578125]\n",
      "Epoch: 690 , Loss: [2.950991153717041, 0.578125]\n",
      "Epoch: 691 , Loss: [3.1939291954040527, 0.484375]\n",
      "Epoch: 692 , Loss: [3.1499037742614746, 0.421875]\n",
      "Epoch: 693 , Loss: [3.159487247467041, 0.453125]\n",
      "Epoch: 694 , Loss: [2.9845614433288574, 0.5625]\n",
      "Epoch: 695 , Loss: [3.049259901046753, 0.5]\n",
      "Epoch: 696 , Loss: [3.0962376594543457, 0.4375]\n",
      "Epoch: 697 , Loss: [3.245858669281006, 0.4375]\n",
      "Epoch: 698 , Loss: [3.1056504249572754, 0.421875]\n",
      "Epoch: 699 , Loss: [2.950580596923828, 0.609375]\n",
      "Epoch: 700 , Loss: [2.9986605644226074, 0.4375]\n",
      "Epoch: 701 , Loss: [2.9311652183532715, 0.46875]\n",
      "Epoch: 702 , Loss: [3.0021958351135254, 0.5]\n",
      "Epoch: 703 , Loss: [2.9590587615966797, 0.578125]\n",
      "Epoch: 704 , Loss: [2.8763186931610107, 0.59375]\n",
      "Epoch: 705 , Loss: [2.913412094116211, 0.578125]\n",
      "Epoch: 706 , Loss: [3.0938620567321777, 0.375]\n",
      "Epoch: 707 , Loss: [2.969343900680542, 0.484375]\n",
      "Epoch: 708 , Loss: [2.9186348915100098, 0.53125]\n",
      "Epoch: 709 , Loss: [2.8864941596984863, 0.453125]\n",
      "Epoch: 710 , Loss: [2.9159092903137207, 0.46875]\n",
      "Epoch: 711 , Loss: [2.9113564491271973, 0.546875]\n",
      "Epoch: 712 , Loss: [3.1067371368408203, 0.4375]\n",
      "Epoch: 713 , Loss: [2.995058536529541, 0.4375]\n",
      "Epoch: 714 , Loss: [3.0122838020324707, 0.4375]\n",
      "Epoch: 715 , Loss: [2.8898208141326904, 0.515625]\n",
      "Epoch: 716 , Loss: [2.8662021160125732, 0.5]\n",
      "Epoch: 717 , Loss: [2.884218692779541, 0.453125]\n",
      "Epoch: 718 , Loss: [2.9764599800109863, 0.4375]\n",
      "Epoch: 719 , Loss: [2.8337247371673584, 0.5]\n",
      "Epoch: 720 , Loss: [2.7736082077026367, 0.578125]\n",
      "Epoch: 721 , Loss: [2.931316614151001, 0.453125]\n",
      "Epoch: 722 , Loss: [2.9027223587036133, 0.5]\n",
      "Epoch: 723 , Loss: [2.8919548988342285, 0.5]\n",
      "Epoch: 724 , Loss: [2.836334705352783, 0.390625]\n",
      "Epoch: 725 , Loss: [2.9223029613494873, 0.4375]\n",
      "Epoch: 726 , Loss: [2.973698616027832, 0.484375]\n",
      "Epoch: 727 , Loss: [2.8560924530029297, 0.546875]\n",
      "Epoch: 728 , Loss: [2.866023540496826, 0.53125]\n",
      "Epoch: 729 , Loss: [2.794827461242676, 0.59375]\n",
      "Epoch: 730 , Loss: [2.7898664474487305, 0.53125]\n",
      "Epoch: 731 , Loss: [2.7526378631591797, 0.484375]\n",
      "Epoch: 732 , Loss: [2.8423659801483154, 0.5]\n",
      "Epoch: 733 , Loss: [2.745520830154419, 0.53125]\n",
      "Epoch: 734 , Loss: [2.7546820640563965, 0.578125]\n",
      "Epoch: 735 , Loss: [2.910722494125366, 0.4375]\n",
      "Epoch: 736 , Loss: [2.9231224060058594, 0.390625]\n",
      "Epoch: 737 , Loss: [2.7591798305511475, 0.53125]\n",
      "Epoch: 738 , Loss: [2.8396921157836914, 0.453125]\n",
      "Epoch: 739 , Loss: [2.8599867820739746, 0.578125]\n",
      "Epoch: 740 , Loss: [2.6691372394561768, 0.609375]\n",
      "Epoch: 741 , Loss: [2.680081844329834, 0.640625]\n",
      "Epoch: 742 , Loss: [2.8186042308807373, 0.46875]\n",
      "Epoch: 743 , Loss: [2.8420486450195312, 0.453125]\n",
      "Epoch: 744 , Loss: [2.679880380630493, 0.609375]\n",
      "Epoch: 745 , Loss: [2.7878928184509277, 0.515625]\n",
      "Epoch: 746 , Loss: [2.8210015296936035, 0.421875]\n",
      "Epoch: 747 , Loss: [2.694915294647217, 0.46875]\n",
      "Epoch: 748 , Loss: [2.7921183109283447, 0.546875]\n",
      "Epoch: 749 , Loss: [2.9166319370269775, 0.40625]\n",
      "Epoch: 750 , Loss: [2.638509511947632, 0.53125]\n",
      "=============================================\n",
      "0 correctly classified among 64\n",
      "Accuracy as of 750 epochs: 0.0\n",
      "=============================================\n",
      "Epoch: 751 , Loss: [2.62914776802063, 0.59375]\n",
      "Epoch: 752 , Loss: [2.716567277908325, 0.546875]\n",
      "Epoch: 753 , Loss: [2.6835508346557617, 0.53125]\n",
      "Epoch: 754 , Loss: [2.6518964767456055, 0.5]\n",
      "Epoch: 755 , Loss: [2.812192916870117, 0.4375]\n",
      "Epoch: 756 , Loss: [2.6689906120300293, 0.484375]\n",
      "Epoch: 757 , Loss: [2.5999112129211426, 0.515625]\n",
      "Epoch: 758 , Loss: [2.6639504432678223, 0.5]\n",
      "Epoch: 759 , Loss: [2.704498291015625, 0.515625]\n",
      "Epoch: 760 , Loss: [2.6113805770874023, 0.5]\n",
      "Epoch: 761 , Loss: [2.776237964630127, 0.46875]\n",
      "Epoch: 762 , Loss: [2.644636631011963, 0.46875]\n",
      "Epoch: 763 , Loss: [2.6026148796081543, 0.546875]\n",
      "Epoch: 764 , Loss: [2.545846700668335, 0.578125]\n",
      "Epoch: 765 , Loss: [2.531879425048828, 0.609375]\n",
      "Epoch: 766 , Loss: [2.528218984603882, 0.53125]\n",
      "Epoch: 767 , Loss: [2.695366621017456, 0.4375]\n",
      "Epoch: 768 , Loss: [2.601510524749756, 0.5625]\n",
      "Epoch: 769 , Loss: [2.6636111736297607, 0.4375]\n",
      "Epoch: 770 , Loss: [2.667752981185913, 0.421875]\n",
      "Epoch: 771 , Loss: [2.53037428855896, 0.5625]\n",
      "Epoch: 772 , Loss: [2.779463291168213, 0.328125]\n",
      "Epoch: 773 , Loss: [2.6528284549713135, 0.46875]\n",
      "Epoch: 774 , Loss: [2.639172077178955, 0.390625]\n",
      "Epoch: 775 , Loss: [2.5684690475463867, 0.5625]\n",
      "Epoch: 776 , Loss: [2.5261764526367188, 0.53125]\n",
      "Epoch: 777 , Loss: [2.5196614265441895, 0.578125]\n",
      "Epoch: 778 , Loss: [2.578563690185547, 0.53125]\n",
      "Epoch: 779 , Loss: [2.5838329792022705, 0.546875]\n",
      "Epoch: 780 , Loss: [2.581373929977417, 0.5625]\n",
      "Epoch: 781 , Loss: [2.601041793823242, 0.59375]\n",
      "Epoch: 782 , Loss: [2.5914533138275146, 0.53125]\n",
      "Epoch: 783 , Loss: [2.6044583320617676, 0.4375]\n",
      "Epoch: 784 , Loss: [2.5630083084106445, 0.546875]\n",
      "Epoch: 785 , Loss: [2.6345627307891846, 0.4375]\n",
      "Epoch: 786 , Loss: [2.371354341506958, 0.59375]\n",
      "Epoch: 787 , Loss: [2.6402206420898438, 0.484375]\n",
      "Epoch: 788 , Loss: [2.5925097465515137, 0.46875]\n",
      "Epoch: 789 , Loss: [2.474825382232666, 0.609375]\n",
      "Epoch: 790 , Loss: [2.544854164123535, 0.484375]\n",
      "Epoch: 791 , Loss: [2.562715530395508, 0.53125]\n",
      "Epoch: 792 , Loss: [2.491335868835449, 0.453125]\n",
      "Epoch: 793 , Loss: [2.541090965270996, 0.53125]\n",
      "Epoch: 794 , Loss: [2.4033634662628174, 0.5625]\n",
      "Epoch: 795 , Loss: [2.5861644744873047, 0.421875]\n",
      "Epoch: 796 , Loss: [2.51765775680542, 0.53125]\n",
      "Epoch: 797 , Loss: [2.4315733909606934, 0.609375]\n",
      "Epoch: 798 , Loss: [2.4849636554718018, 0.546875]\n",
      "Epoch: 799 , Loss: [2.479766368865967, 0.515625]\n",
      "Epoch: 800 , Loss: [2.515592098236084, 0.515625]\n",
      "Epoch: 801 , Loss: [2.391630172729492, 0.59375]\n",
      "Epoch: 802 , Loss: [2.528898239135742, 0.453125]\n",
      "Epoch: 803 , Loss: [2.4505465030670166, 0.5625]\n",
      "Epoch: 804 , Loss: [2.4032437801361084, 0.59375]\n",
      "Epoch: 805 , Loss: [2.499983787536621, 0.5]\n",
      "Epoch: 806 , Loss: [2.3931832313537598, 0.546875]\n",
      "Epoch: 807 , Loss: [2.5253424644470215, 0.40625]\n",
      "Epoch: 808 , Loss: [2.477741241455078, 0.546875]\n",
      "Epoch: 809 , Loss: [2.3726892471313477, 0.578125]\n",
      "Epoch: 810 , Loss: [2.516523599624634, 0.484375]\n",
      "Epoch: 811 , Loss: [2.542308807373047, 0.390625]\n",
      "Epoch: 812 , Loss: [2.36116886138916, 0.53125]\n",
      "Epoch: 813 , Loss: [2.4514999389648438, 0.546875]\n",
      "Epoch: 814 , Loss: [2.423494815826416, 0.484375]\n",
      "Epoch: 815 , Loss: [2.3460323810577393, 0.609375]\n",
      "Epoch: 816 , Loss: [2.3119702339172363, 0.5625]\n",
      "Epoch: 817 , Loss: [2.296994209289551, 0.640625]\n",
      "Epoch: 818 , Loss: [2.51778507232666, 0.46875]\n",
      "Epoch: 819 , Loss: [2.468020439147949, 0.53125]\n",
      "Epoch: 820 , Loss: [2.383030891418457, 0.484375]\n",
      "Epoch: 821 , Loss: [2.489802837371826, 0.46875]\n",
      "Epoch: 822 , Loss: [2.3741092681884766, 0.5625]\n",
      "Epoch: 823 , Loss: [2.355968952178955, 0.59375]\n",
      "Epoch: 824 , Loss: [2.551600933074951, 0.4375]\n",
      "Epoch: 825 , Loss: [2.3547310829162598, 0.53125]\n",
      "Epoch: 826 , Loss: [2.3395352363586426, 0.5625]\n",
      "Epoch: 827 , Loss: [2.3752686977386475, 0.484375]\n",
      "Epoch: 828 , Loss: [2.3931307792663574, 0.5]\n",
      "Epoch: 829 , Loss: [2.3505735397338867, 0.46875]\n",
      "Epoch: 830 , Loss: [2.2245872020721436, 0.671875]\n",
      "Epoch: 831 , Loss: [2.378244400024414, 0.390625]\n",
      "Epoch: 832 , Loss: [2.366687297821045, 0.5]\n",
      "Epoch: 833 , Loss: [2.428375244140625, 0.484375]\n",
      "Epoch: 834 , Loss: [2.477416515350342, 0.34375]\n",
      "Epoch: 835 , Loss: [2.329615592956543, 0.46875]\n",
      "Epoch: 836 , Loss: [2.316781997680664, 0.515625]\n",
      "Epoch: 837 , Loss: [2.287651300430298, 0.53125]\n",
      "Epoch: 838 , Loss: [2.386915683746338, 0.515625]\n",
      "Epoch: 839 , Loss: [2.3701541423797607, 0.46875]\n",
      "Epoch: 840 , Loss: [2.342175006866455, 0.484375]\n",
      "Epoch: 841 , Loss: [2.5368940830230713, 0.484375]\n",
      "Epoch: 842 , Loss: [2.3480064868927, 0.53125]\n",
      "Epoch: 843 , Loss: [2.3945229053497314, 0.46875]\n",
      "Epoch: 844 , Loss: [2.3614606857299805, 0.515625]\n",
      "Epoch: 845 , Loss: [2.3359358310699463, 0.53125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 846 , Loss: [2.3178765773773193, 0.5]\n",
      "Epoch: 847 , Loss: [2.3542261123657227, 0.40625]\n",
      "Epoch: 848 , Loss: [2.4611496925354004, 0.390625]\n",
      "Epoch: 849 , Loss: [2.304509162902832, 0.5625]\n",
      "Epoch: 850 , Loss: [2.2951104640960693, 0.515625]\n",
      "Epoch: 851 , Loss: [2.262343406677246, 0.515625]\n",
      "Epoch: 852 , Loss: [2.3848633766174316, 0.484375]\n",
      "Epoch: 853 , Loss: [2.2543203830718994, 0.53125]\n",
      "Epoch: 854 , Loss: [2.2469024658203125, 0.5625]\n",
      "Epoch: 855 , Loss: [2.2727551460266113, 0.46875]\n",
      "Epoch: 856 , Loss: [2.3005881309509277, 0.53125]\n",
      "Epoch: 857 , Loss: [2.287271499633789, 0.515625]\n",
      "Epoch: 858 , Loss: [2.1276841163635254, 0.546875]\n",
      "Epoch: 859 , Loss: [2.1457345485687256, 0.546875]\n",
      "Epoch: 860 , Loss: [2.3924546241760254, 0.4375]\n",
      "Epoch: 861 , Loss: [2.2561583518981934, 0.5]\n",
      "Epoch: 862 , Loss: [2.3837156295776367, 0.390625]\n",
      "Epoch: 863 , Loss: [2.192628860473633, 0.546875]\n",
      "Epoch: 864 , Loss: [2.1907200813293457, 0.53125]\n",
      "Epoch: 865 , Loss: [2.284897804260254, 0.4375]\n",
      "Epoch: 866 , Loss: [2.2817606925964355, 0.515625]\n",
      "Epoch: 867 , Loss: [2.325403928756714, 0.359375]\n",
      "Epoch: 868 , Loss: [2.268089532852173, 0.53125]\n",
      "Epoch: 869 , Loss: [2.2819018363952637, 0.421875]\n",
      "Epoch: 870 , Loss: [2.2108263969421387, 0.484375]\n",
      "Epoch: 871 , Loss: [2.2131905555725098, 0.5]\n",
      "Epoch: 872 , Loss: [2.047715902328491, 0.671875]\n",
      "Epoch: 873 , Loss: [2.231853485107422, 0.5]\n",
      "Epoch: 874 , Loss: [2.303967237472534, 0.375]\n",
      "Epoch: 875 , Loss: [2.1487183570861816, 0.53125]\n",
      "Epoch: 876 , Loss: [2.1312618255615234, 0.609375]\n",
      "Epoch: 877 , Loss: [2.1194615364074707, 0.5625]\n",
      "Epoch: 878 , Loss: [2.253023862838745, 0.53125]\n",
      "Epoch: 879 , Loss: [2.111764669418335, 0.515625]\n",
      "Epoch: 880 , Loss: [2.2200100421905518, 0.515625]\n",
      "Epoch: 881 , Loss: [2.2362937927246094, 0.453125]\n",
      "Epoch: 882 , Loss: [2.1612801551818848, 0.484375]\n",
      "Epoch: 883 , Loss: [2.1966726779937744, 0.53125]\n",
      "Epoch: 884 , Loss: [2.1812891960144043, 0.5625]\n",
      "Epoch: 885 , Loss: [2.253369092941284, 0.46875]\n",
      "Epoch: 886 , Loss: [2.289935350418091, 0.40625]\n",
      "Epoch: 887 , Loss: [2.156641721725464, 0.453125]\n",
      "Epoch: 888 , Loss: [2.210132598876953, 0.515625]\n",
      "Epoch: 889 , Loss: [2.090947389602661, 0.546875]\n",
      "Epoch: 890 , Loss: [2.3124306201934814, 0.421875]\n",
      "Epoch: 891 , Loss: [2.110318183898926, 0.453125]\n",
      "Epoch: 892 , Loss: [2.152743101119995, 0.484375]\n",
      "Epoch: 893 , Loss: [2.1673080921173096, 0.484375]\n",
      "Epoch: 894 , Loss: [1.9865376949310303, 0.5625]\n",
      "Epoch: 895 , Loss: [2.088124990463257, 0.484375]\n",
      "Epoch: 896 , Loss: [2.1025891304016113, 0.515625]\n",
      "Epoch: 897 , Loss: [2.094283103942871, 0.46875]\n",
      "Epoch: 898 , Loss: [2.260002613067627, 0.46875]\n",
      "Epoch: 899 , Loss: [2.2085635662078857, 0.375]\n",
      "Epoch: 900 , Loss: [2.0762381553649902, 0.53125]\n",
      "Epoch: 901 , Loss: [2.1238853931427, 0.5625]\n",
      "Epoch: 902 , Loss: [2.2496871948242188, 0.4375]\n",
      "Epoch: 903 , Loss: [2.0770461559295654, 0.546875]\n",
      "Epoch: 904 , Loss: [2.024212598800659, 0.578125]\n",
      "Epoch: 905 , Loss: [2.1156387329101562, 0.5]\n",
      "Epoch: 906 , Loss: [2.112758159637451, 0.5625]\n",
      "Epoch: 907 , Loss: [2.166489601135254, 0.421875]\n",
      "Epoch: 908 , Loss: [2.1145076751708984, 0.453125]\n",
      "Epoch: 909 , Loss: [2.0308783054351807, 0.609375]\n",
      "Epoch: 910 , Loss: [2.1341605186462402, 0.4375]\n",
      "Epoch: 911 , Loss: [2.093757390975952, 0.46875]\n",
      "Epoch: 912 , Loss: [2.163233518600464, 0.4375]\n",
      "Epoch: 913 , Loss: [2.1124391555786133, 0.4375]\n",
      "Epoch: 914 , Loss: [2.1132373809814453, 0.46875]\n",
      "Epoch: 915 , Loss: [2.082883834838867, 0.5]\n",
      "Epoch: 916 , Loss: [2.013421058654785, 0.578125]\n",
      "Epoch: 917 , Loss: [1.9763720035552979, 0.5625]\n",
      "Epoch: 918 , Loss: [2.083749294281006, 0.53125]\n",
      "Epoch: 919 , Loss: [2.1054890155792236, 0.484375]\n",
      "Epoch: 920 , Loss: [2.07062029838562, 0.5]\n",
      "Epoch: 921 , Loss: [2.0105104446411133, 0.5]\n",
      "Epoch: 922 , Loss: [2.056213140487671, 0.4375]\n",
      "Epoch: 923 , Loss: [2.0721919536590576, 0.546875]\n",
      "Epoch: 924 , Loss: [1.9411110877990723, 0.59375]\n",
      "Epoch: 925 , Loss: [2.049520492553711, 0.53125]\n",
      "Epoch: 926 , Loss: [2.0901241302490234, 0.515625]\n",
      "Epoch: 927 , Loss: [1.8915653228759766, 0.625]\n",
      "Epoch: 928 , Loss: [1.9973747730255127, 0.515625]\n",
      "Epoch: 929 , Loss: [2.145380973815918, 0.453125]\n",
      "Epoch: 930 , Loss: [1.9880344867706299, 0.484375]\n",
      "Epoch: 931 , Loss: [2.009925127029419, 0.46875]\n",
      "Epoch: 932 , Loss: [2.0445446968078613, 0.4375]\n",
      "Epoch: 933 , Loss: [2.01163911819458, 0.5]\n",
      "Epoch: 934 , Loss: [2.096832275390625, 0.40625]\n",
      "Epoch: 935 , Loss: [1.8947458267211914, 0.640625]\n",
      "Epoch: 936 , Loss: [2.070737838745117, 0.453125]\n",
      "Epoch: 937 , Loss: [1.9335438013076782, 0.546875]\n",
      "Epoch: 938 , Loss: [2.209665060043335, 0.359375]\n",
      "Epoch: 939 , Loss: [1.9723429679870605, 0.484375]\n",
      "Epoch: 940 , Loss: [1.9917045831680298, 0.5]\n",
      "Epoch: 941 , Loss: [1.9856220483779907, 0.5]\n",
      "Epoch: 942 , Loss: [1.9822852611541748, 0.5625]\n",
      "Epoch: 943 , Loss: [1.8726623058319092, 0.65625]\n",
      "Epoch: 944 , Loss: [1.9517675638198853, 0.515625]\n",
      "Epoch: 945 , Loss: [1.9538989067077637, 0.484375]\n",
      "Epoch: 946 , Loss: [1.9782791137695312, 0.5]\n",
      "Epoch: 947 , Loss: [2.098615884780884, 0.421875]\n",
      "Epoch: 948 , Loss: [1.9280009269714355, 0.5]\n",
      "Epoch: 949 , Loss: [1.8186166286468506, 0.734375]\n",
      "Epoch: 950 , Loss: [2.0765905380249023, 0.390625]\n",
      "Epoch: 951 , Loss: [1.9777052402496338, 0.5]\n",
      "Epoch: 952 , Loss: [1.8299615383148193, 0.59375]\n",
      "Epoch: 953 , Loss: [1.9081485271453857, 0.53125]\n",
      "Epoch: 954 , Loss: [2.0159993171691895, 0.4375]\n",
      "Epoch: 955 , Loss: [1.9699374437332153, 0.4375]\n",
      "Epoch: 956 , Loss: [1.9337316751480103, 0.53125]\n",
      "Epoch: 957 , Loss: [2.004884958267212, 0.453125]\n",
      "Epoch: 958 , Loss: [1.9041671752929688, 0.5]\n",
      "Epoch: 959 , Loss: [1.9380178451538086, 0.5]\n",
      "Epoch: 960 , Loss: [1.9263066053390503, 0.515625]\n",
      "Epoch: 961 , Loss: [1.8726229667663574, 0.5]\n",
      "Epoch: 962 , Loss: [2.071765661239624, 0.390625]\n",
      "Epoch: 963 , Loss: [1.9212327003479004, 0.5]\n",
      "Epoch: 964 , Loss: [1.8612192869186401, 0.65625]\n",
      "Epoch: 965 , Loss: [1.8862073421478271, 0.515625]\n",
      "Epoch: 966 , Loss: [1.992166519165039, 0.484375]\n",
      "Epoch: 967 , Loss: [1.8831779956817627, 0.578125]\n",
      "Epoch: 968 , Loss: [1.840597152709961, 0.609375]\n",
      "Epoch: 969 , Loss: [1.8874340057373047, 0.53125]\n",
      "Epoch: 970 , Loss: [1.8261430263519287, 0.640625]\n",
      "Epoch: 971 , Loss: [1.9474259614944458, 0.515625]\n",
      "Epoch: 972 , Loss: [2.016315460205078, 0.453125]\n",
      "Epoch: 973 , Loss: [2.095275402069092, 0.390625]\n",
      "Epoch: 974 , Loss: [1.8513085842132568, 0.578125]\n",
      "Epoch: 975 , Loss: [2.071075677871704, 0.421875]\n",
      "Epoch: 976 , Loss: [1.9022338390350342, 0.5625]\n",
      "Epoch: 977 , Loss: [1.9357320070266724, 0.375]\n",
      "Epoch: 978 , Loss: [1.9923150539398193, 0.46875]\n",
      "Epoch: 979 , Loss: [1.8629429340362549, 0.484375]\n",
      "Epoch: 980 , Loss: [1.9053415060043335, 0.453125]\n",
      "Epoch: 981 , Loss: [1.8715877532958984, 0.53125]\n",
      "Epoch: 982 , Loss: [1.9303855895996094, 0.484375]\n",
      "Epoch: 983 , Loss: [1.8158780336380005, 0.59375]\n",
      "Epoch: 984 , Loss: [1.8085474967956543, 0.546875]\n",
      "Epoch: 985 , Loss: [1.8499009609222412, 0.53125]\n",
      "Epoch: 986 , Loss: [1.9163061380386353, 0.53125]\n",
      "Epoch: 987 , Loss: [1.8819941282272339, 0.5]\n",
      "Epoch: 988 , Loss: [1.9427752494812012, 0.46875]\n",
      "Epoch: 989 , Loss: [1.8774785995483398, 0.5625]\n",
      "Epoch: 990 , Loss: [1.940998911857605, 0.421875]\n",
      "Epoch: 991 , Loss: [1.9088037014007568, 0.484375]\n",
      "Epoch: 992 , Loss: [1.8295282125473022, 0.46875]\n",
      "Epoch: 993 , Loss: [1.853453278541565, 0.421875]\n",
      "Epoch: 994 , Loss: [1.8979113101959229, 0.4375]\n",
      "Epoch: 995 , Loss: [1.9082212448120117, 0.484375]\n",
      "Epoch: 996 , Loss: [1.88406240940094, 0.453125]\n",
      "Epoch: 997 , Loss: [1.8289989233016968, 0.515625]\n",
      "Epoch: 998 , Loss: [1.7859764099121094, 0.578125]\n",
      "Epoch: 999 , Loss: [1.7910475730895996, 0.5]\n",
      "Epoch: 1000 , Loss: [1.8309499025344849, 0.5]\n",
      "=============================================\n",
      "3 correctly classified among 64\n",
      "Accuracy as of 1000 epochs: 4.6875\n",
      "=============================================\n",
      "Epoch: 1001 , Loss: [1.7749980688095093, 0.5625]\n",
      "Epoch: 1002 , Loss: [1.8638283014297485, 0.484375]\n",
      "Epoch: 1003 , Loss: [1.8072714805603027, 0.5]\n",
      "Epoch: 1004 , Loss: [1.951174259185791, 0.296875]\n",
      "Epoch: 1005 , Loss: [1.8183400630950928, 0.515625]\n",
      "Epoch: 1006 , Loss: [1.8230342864990234, 0.484375]\n",
      "Epoch: 1007 , Loss: [1.7681033611297607, 0.515625]\n",
      "Epoch: 1008 , Loss: [1.8618755340576172, 0.53125]\n",
      "Epoch: 1009 , Loss: [1.8267850875854492, 0.484375]\n",
      "Epoch: 1010 , Loss: [1.9640130996704102, 0.421875]\n",
      "Epoch: 1011 , Loss: [1.8965502977371216, 0.515625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1012 , Loss: [1.7753105163574219, 0.53125]\n",
      "Epoch: 1013 , Loss: [1.8104523420333862, 0.53125]\n",
      "Epoch: 1014 , Loss: [1.7452532052993774, 0.453125]\n",
      "Epoch: 1015 , Loss: [1.6911001205444336, 0.65625]\n",
      "Epoch: 1016 , Loss: [1.7919909954071045, 0.5]\n",
      "Epoch: 1017 , Loss: [1.70449697971344, 0.53125]\n",
      "Epoch: 1018 , Loss: [1.7672621011734009, 0.484375]\n",
      "Epoch: 1019 , Loss: [1.757267951965332, 0.515625]\n",
      "Epoch: 1020 , Loss: [1.8602745532989502, 0.53125]\n",
      "Epoch: 1021 , Loss: [1.8095473051071167, 0.515625]\n",
      "Epoch: 1022 , Loss: [1.7953990697860718, 0.421875]\n",
      "Epoch: 1023 , Loss: [1.7801591157913208, 0.484375]\n",
      "Epoch: 1024 , Loss: [1.7022693157196045, 0.578125]\n",
      "Epoch: 1025 , Loss: [1.8070948123931885, 0.46875]\n",
      "Epoch: 1026 , Loss: [1.7203624248504639, 0.515625]\n",
      "Epoch: 1027 , Loss: [1.780429720878601, 0.5]\n",
      "Epoch: 1028 , Loss: [1.9212065935134888, 0.390625]\n",
      "Epoch: 1029 , Loss: [1.7922592163085938, 0.4375]\n",
      "Epoch: 1030 , Loss: [1.7292697429656982, 0.46875]\n",
      "Epoch: 1031 , Loss: [1.72084641456604, 0.53125]\n",
      "Epoch: 1032 , Loss: [1.8708250522613525, 0.453125]\n",
      "Epoch: 1033 , Loss: [1.7142243385314941, 0.59375]\n",
      "Epoch: 1034 , Loss: [1.8006277084350586, 0.4375]\n",
      "Epoch: 1035 , Loss: [1.708125114440918, 0.5625]\n",
      "Epoch: 1036 , Loss: [1.7577459812164307, 0.515625]\n",
      "Epoch: 1037 , Loss: [1.8331340551376343, 0.5]\n",
      "Epoch: 1038 , Loss: [1.758617639541626, 0.5]\n",
      "Epoch: 1039 , Loss: [1.7706363201141357, 0.484375]\n",
      "Epoch: 1040 , Loss: [1.7253475189208984, 0.484375]\n",
      "Epoch: 1041 , Loss: [1.6699342727661133, 0.515625]\n",
      "Epoch: 1042 , Loss: [1.7612223625183105, 0.53125]\n",
      "Epoch: 1043 , Loss: [1.6582434177398682, 0.515625]\n",
      "Epoch: 1044 , Loss: [1.671454906463623, 0.578125]\n",
      "Epoch: 1045 , Loss: [1.7657437324523926, 0.53125]\n",
      "Epoch: 1046 , Loss: [1.7157150506973267, 0.390625]\n",
      "Epoch: 1047 , Loss: [1.6599750518798828, 0.59375]\n",
      "Epoch: 1048 , Loss: [1.8044565916061401, 0.453125]\n",
      "Epoch: 1049 , Loss: [1.8392918109893799, 0.453125]\n",
      "Epoch: 1050 , Loss: [1.6862030029296875, 0.578125]\n",
      "Epoch: 1051 , Loss: [1.6561028957366943, 0.53125]\n",
      "Epoch: 1052 , Loss: [1.721494197845459, 0.515625]\n",
      "Epoch: 1053 , Loss: [1.7329094409942627, 0.59375]\n",
      "Epoch: 1054 , Loss: [1.7490644454956055, 0.484375]\n",
      "Epoch: 1055 , Loss: [1.7868403196334839, 0.421875]\n",
      "Epoch: 1056 , Loss: [1.755008339881897, 0.453125]\n",
      "Epoch: 1057 , Loss: [1.7773268222808838, 0.4375]\n",
      "Epoch: 1058 , Loss: [1.6758174896240234, 0.609375]\n",
      "Epoch: 1059 , Loss: [1.6775603294372559, 0.546875]\n",
      "Epoch: 1060 , Loss: [1.6723527908325195, 0.515625]\n",
      "Epoch: 1061 , Loss: [1.7661991119384766, 0.4375]\n",
      "Epoch: 1062 , Loss: [1.7577253580093384, 0.484375]\n",
      "Epoch: 1063 , Loss: [1.7778337001800537, 0.484375]\n",
      "Epoch: 1064 , Loss: [1.7930426597595215, 0.453125]\n",
      "Epoch: 1065 , Loss: [1.8390390872955322, 0.390625]\n",
      "Epoch: 1066 , Loss: [1.681417465209961, 0.515625]\n",
      "Epoch: 1067 , Loss: [1.713210105895996, 0.546875]\n",
      "Epoch: 1068 , Loss: [1.785248875617981, 0.359375]\n",
      "Epoch: 1069 , Loss: [1.6787039041519165, 0.4375]\n",
      "Epoch: 1070 , Loss: [1.6462345123291016, 0.5]\n",
      "Epoch: 1071 , Loss: [1.8209675550460815, 0.375]\n",
      "Epoch: 1072 , Loss: [1.6478092670440674, 0.59375]\n",
      "Epoch: 1073 , Loss: [1.712092638015747, 0.53125]\n",
      "Epoch: 1074 , Loss: [1.8175346851348877, 0.4375]\n",
      "Epoch: 1075 , Loss: [1.7644366025924683, 0.390625]\n",
      "Epoch: 1076 , Loss: [1.6664543151855469, 0.5625]\n",
      "Epoch: 1077 , Loss: [1.7183685302734375, 0.53125]\n",
      "Epoch: 1078 , Loss: [1.7138137817382812, 0.53125]\n",
      "Epoch: 1079 , Loss: [1.7129838466644287, 0.421875]\n",
      "Epoch: 1080 , Loss: [1.5698540210723877, 0.578125]\n",
      "Epoch: 1081 , Loss: [1.6318602561950684, 0.5625]\n",
      "Epoch: 1082 , Loss: [1.6448347568511963, 0.46875]\n",
      "Epoch: 1083 , Loss: [1.6878582239151, 0.5]\n",
      "Epoch: 1084 , Loss: [1.5864570140838623, 0.546875]\n",
      "Epoch: 1085 , Loss: [1.7956949472427368, 0.4375]\n",
      "Epoch: 1086 , Loss: [1.6978759765625, 0.53125]\n",
      "Epoch: 1087 , Loss: [1.747751235961914, 0.421875]\n",
      "Epoch: 1088 , Loss: [1.6856741905212402, 0.53125]\n",
      "Epoch: 1089 , Loss: [1.6792396306991577, 0.53125]\n",
      "Epoch: 1090 , Loss: [1.7813111543655396, 0.40625]\n",
      "Epoch: 1091 , Loss: [1.6629220247268677, 0.578125]\n",
      "Epoch: 1092 , Loss: [1.66097092628479, 0.46875]\n",
      "Epoch: 1093 , Loss: [1.5328997373580933, 0.609375]\n",
      "Epoch: 1094 , Loss: [1.6578930616378784, 0.46875]\n",
      "Epoch: 1095 , Loss: [1.7288663387298584, 0.375]\n",
      "Epoch: 1096 , Loss: [1.8103578090667725, 0.421875]\n",
      "Epoch: 1097 , Loss: [1.6749565601348877, 0.546875]\n",
      "Epoch: 1098 , Loss: [1.5050897598266602, 0.625]\n",
      "Epoch: 1099 , Loss: [1.638622522354126, 0.46875]\n",
      "Epoch: 1100 , Loss: [1.6118865013122559, 0.515625]\n",
      "Epoch: 1101 , Loss: [1.6246848106384277, 0.484375]\n",
      "Epoch: 1102 , Loss: [1.602252721786499, 0.546875]\n",
      "Epoch: 1103 , Loss: [1.7251935005187988, 0.421875]\n",
      "Epoch: 1104 , Loss: [1.616685152053833, 0.53125]\n",
      "Epoch: 1105 , Loss: [1.5568475723266602, 0.59375]\n",
      "Epoch: 1106 , Loss: [1.766469120979309, 0.453125]\n",
      "Epoch: 1107 , Loss: [1.6255916357040405, 0.515625]\n",
      "Epoch: 1108 , Loss: [1.6622954607009888, 0.453125]\n",
      "Epoch: 1109 , Loss: [1.6910321712493896, 0.5]\n",
      "Epoch: 1110 , Loss: [1.604203701019287, 0.515625]\n",
      "Epoch: 1111 , Loss: [1.5833384990692139, 0.515625]\n",
      "Epoch: 1112 , Loss: [1.5712839365005493, 0.578125]\n",
      "Epoch: 1113 , Loss: [1.5740933418273926, 0.53125]\n",
      "Epoch: 1114 , Loss: [1.6243897676467896, 0.484375]\n",
      "Epoch: 1115 , Loss: [1.6333575248718262, 0.46875]\n",
      "Epoch: 1116 , Loss: [1.7081027030944824, 0.5]\n",
      "Epoch: 1117 , Loss: [1.602241039276123, 0.5625]\n",
      "Epoch: 1118 , Loss: [1.590465784072876, 0.53125]\n",
      "Epoch: 1119 , Loss: [1.6657359600067139, 0.390625]\n",
      "Epoch: 1120 , Loss: [1.5982069969177246, 0.546875]\n",
      "Epoch: 1121 , Loss: [1.482513666152954, 0.640625]\n",
      "Epoch: 1122 , Loss: [1.682849407196045, 0.46875]\n",
      "Epoch: 1123 , Loss: [1.6845399141311646, 0.5]\n",
      "Epoch: 1124 , Loss: [1.5340464115142822, 0.578125]\n",
      "Epoch: 1125 , Loss: [1.6593492031097412, 0.453125]\n",
      "Epoch: 1126 , Loss: [1.6500798463821411, 0.5]\n",
      "Epoch: 1127 , Loss: [1.6515038013458252, 0.5625]\n",
      "Epoch: 1128 , Loss: [1.6393113136291504, 0.421875]\n",
      "Epoch: 1129 , Loss: [1.618605375289917, 0.5]\n",
      "Epoch: 1130 , Loss: [1.589026689529419, 0.5]\n",
      "Epoch: 1131 , Loss: [1.6352434158325195, 0.515625]\n",
      "Epoch: 1132 , Loss: [1.5635119676589966, 0.59375]\n",
      "Epoch: 1133 , Loss: [1.5361452102661133, 0.59375]\n",
      "Epoch: 1134 , Loss: [1.509176254272461, 0.59375]\n",
      "Epoch: 1135 , Loss: [1.6797661781311035, 0.40625]\n",
      "Epoch: 1136 , Loss: [1.5375778675079346, 0.546875]\n",
      "Epoch: 1137 , Loss: [1.50751531124115, 0.609375]\n",
      "Epoch: 1138 , Loss: [1.6677560806274414, 0.484375]\n",
      "Epoch: 1139 , Loss: [1.7299742698669434, 0.390625]\n",
      "Epoch: 1140 , Loss: [1.7306103706359863, 0.359375]\n",
      "Epoch: 1141 , Loss: [1.643509864807129, 0.4375]\n",
      "Epoch: 1142 , Loss: [1.6580090522766113, 0.4375]\n",
      "Epoch: 1143 , Loss: [1.4836640357971191, 0.515625]\n",
      "Epoch: 1144 , Loss: [1.5182877779006958, 0.5625]\n",
      "Epoch: 1145 , Loss: [1.6394753456115723, 0.4375]\n",
      "Epoch: 1146 , Loss: [1.598610520362854, 0.4375]\n",
      "Epoch: 1147 , Loss: [1.5196559429168701, 0.53125]\n",
      "Epoch: 1148 , Loss: [1.4887008666992188, 0.625]\n",
      "Epoch: 1149 , Loss: [1.642317295074463, 0.421875]\n",
      "Epoch: 1150 , Loss: [1.5574541091918945, 0.59375]\n",
      "Epoch: 1151 , Loss: [1.538367509841919, 0.484375]\n",
      "Epoch: 1152 , Loss: [1.5810223817825317, 0.484375]\n",
      "Epoch: 1153 , Loss: [1.5590275526046753, 0.546875]\n",
      "Epoch: 1154 , Loss: [1.658966064453125, 0.375]\n",
      "Epoch: 1155 , Loss: [1.5581063032150269, 0.515625]\n",
      "Epoch: 1156 , Loss: [1.5465351343154907, 0.5]\n",
      "Epoch: 1157 , Loss: [1.57171630859375, 0.515625]\n",
      "Epoch: 1158 , Loss: [1.5619072914123535, 0.5]\n",
      "Epoch: 1159 , Loss: [1.5192971229553223, 0.5]\n",
      "Epoch: 1160 , Loss: [1.508812427520752, 0.515625]\n",
      "Epoch: 1161 , Loss: [1.5417276620864868, 0.40625]\n",
      "Epoch: 1162 , Loss: [1.5427258014678955, 0.546875]\n",
      "Epoch: 1163 , Loss: [1.6013388633728027, 0.5]\n",
      "Epoch: 1164 , Loss: [1.543548345565796, 0.453125]\n",
      "Epoch: 1165 , Loss: [1.4953984022140503, 0.546875]\n",
      "Epoch: 1166 , Loss: [1.6358320713043213, 0.5]\n",
      "Epoch: 1167 , Loss: [1.5696791410446167, 0.5625]\n",
      "Epoch: 1168 , Loss: [1.5527961254119873, 0.484375]\n",
      "Epoch: 1169 , Loss: [1.561525821685791, 0.484375]\n",
      "Epoch: 1170 , Loss: [1.6560033559799194, 0.46875]\n",
      "Epoch: 1171 , Loss: [1.552958607673645, 0.421875]\n",
      "Epoch: 1172 , Loss: [1.601783275604248, 0.453125]\n",
      "Epoch: 1173 , Loss: [1.614237904548645, 0.390625]\n",
      "Epoch: 1174 , Loss: [1.5883252620697021, 0.453125]\n",
      "Epoch: 1175 , Loss: [1.558611273765564, 0.390625]\n",
      "Epoch: 1176 , Loss: [1.6359893083572388, 0.359375]\n",
      "Epoch: 1177 , Loss: [1.5050849914550781, 0.5625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1178 , Loss: [1.5258162021636963, 0.53125]\n",
      "Epoch: 1179 , Loss: [1.5463018417358398, 0.421875]\n",
      "Epoch: 1180 , Loss: [1.514196515083313, 0.515625]\n",
      "Epoch: 1181 , Loss: [1.4786546230316162, 0.515625]\n",
      "Epoch: 1182 , Loss: [1.5085948705673218, 0.46875]\n",
      "Epoch: 1183 , Loss: [1.4959728717803955, 0.59375]\n",
      "Epoch: 1184 , Loss: [1.5256729125976562, 0.53125]\n",
      "Epoch: 1185 , Loss: [1.5438156127929688, 0.4375]\n",
      "Epoch: 1186 , Loss: [1.4947140216827393, 0.53125]\n",
      "Epoch: 1187 , Loss: [1.4734293222427368, 0.5625]\n",
      "Epoch: 1188 , Loss: [1.4925073385238647, 0.484375]\n",
      "Epoch: 1189 , Loss: [1.5536917448043823, 0.40625]\n",
      "Epoch: 1190 , Loss: [1.5196759700775146, 0.53125]\n",
      "Epoch: 1191 , Loss: [1.603562355041504, 0.484375]\n",
      "Epoch: 1192 , Loss: [1.466005802154541, 0.5625]\n",
      "Epoch: 1193 , Loss: [1.5329205989837646, 0.484375]\n",
      "Epoch: 1194 , Loss: [1.5644997358322144, 0.46875]\n",
      "Epoch: 1195 , Loss: [1.4813575744628906, 0.46875]\n",
      "Epoch: 1196 , Loss: [1.404341459274292, 0.578125]\n",
      "Epoch: 1197 , Loss: [1.5977778434753418, 0.390625]\n",
      "Epoch: 1198 , Loss: [1.6417911052703857, 0.390625]\n",
      "Epoch: 1199 , Loss: [1.5056841373443604, 0.46875]\n",
      "Epoch: 1200 , Loss: [1.4265111684799194, 0.5]\n",
      "Epoch: 1201 , Loss: [1.550723910331726, 0.421875]\n",
      "Epoch: 1202 , Loss: [1.389988660812378, 0.5625]\n",
      "Epoch: 1203 , Loss: [1.427844524383545, 0.484375]\n",
      "Epoch: 1204 , Loss: [1.5930554866790771, 0.390625]\n",
      "Epoch: 1205 , Loss: [1.4889779090881348, 0.4375]\n",
      "Epoch: 1206 , Loss: [1.402919054031372, 0.640625]\n",
      "Epoch: 1207 , Loss: [1.5455492734909058, 0.515625]\n",
      "Epoch: 1208 , Loss: [1.4692296981811523, 0.515625]\n",
      "Epoch: 1209 , Loss: [1.3830108642578125, 0.625]\n",
      "Epoch: 1210 , Loss: [1.4520729780197144, 0.53125]\n",
      "Epoch: 1211 , Loss: [1.4413998126983643, 0.515625]\n",
      "Epoch: 1212 , Loss: [1.4612045288085938, 0.5]\n",
      "Epoch: 1213 , Loss: [1.4984546899795532, 0.515625]\n",
      "Epoch: 1214 , Loss: [1.4290612936019897, 0.640625]\n",
      "Epoch: 1215 , Loss: [1.6431474685668945, 0.375]\n",
      "Epoch: 1216 , Loss: [1.5291602611541748, 0.46875]\n",
      "Epoch: 1217 , Loss: [1.4349466562271118, 0.53125]\n",
      "Epoch: 1218 , Loss: [1.4084298610687256, 0.53125]\n",
      "Epoch: 1219 , Loss: [1.4259129762649536, 0.515625]\n",
      "Epoch: 1220 , Loss: [1.4486162662506104, 0.484375]\n",
      "Epoch: 1221 , Loss: [1.5220509767532349, 0.453125]\n",
      "Epoch: 1222 , Loss: [1.438697338104248, 0.46875]\n",
      "Epoch: 1223 , Loss: [1.4819411039352417, 0.4375]\n",
      "Epoch: 1224 , Loss: [1.5415072441101074, 0.46875]\n",
      "Epoch: 1225 , Loss: [1.4795191287994385, 0.453125]\n",
      "Epoch: 1226 , Loss: [1.4919136762619019, 0.515625]\n",
      "Epoch: 1227 , Loss: [1.5362375974655151, 0.40625]\n",
      "Epoch: 1228 , Loss: [1.5232067108154297, 0.421875]\n",
      "Epoch: 1229 , Loss: [1.4828492403030396, 0.421875]\n",
      "Epoch: 1230 , Loss: [1.3892171382904053, 0.546875]\n",
      "Epoch: 1231 , Loss: [1.4752073287963867, 0.5]\n",
      "Epoch: 1232 , Loss: [1.4669467210769653, 0.46875]\n",
      "Epoch: 1233 , Loss: [1.4295940399169922, 0.515625]\n",
      "Epoch: 1234 , Loss: [1.551943063735962, 0.390625]\n",
      "Epoch: 1235 , Loss: [1.3993184566497803, 0.515625]\n",
      "Epoch: 1236 , Loss: [1.5162582397460938, 0.46875]\n",
      "Epoch: 1237 , Loss: [1.4456260204315186, 0.515625]\n",
      "Epoch: 1238 , Loss: [1.548312783241272, 0.53125]\n",
      "Epoch: 1239 , Loss: [1.4283145666122437, 0.5]\n",
      "Epoch: 1240 , Loss: [1.4816502332687378, 0.421875]\n",
      "Epoch: 1241 , Loss: [1.458828330039978, 0.453125]\n",
      "Epoch: 1242 , Loss: [1.5276089906692505, 0.359375]\n",
      "Epoch: 1243 , Loss: [1.3739681243896484, 0.546875]\n",
      "Epoch: 1244 , Loss: [1.4224436283111572, 0.53125]\n",
      "Epoch: 1245 , Loss: [1.4456114768981934, 0.46875]\n",
      "Epoch: 1246 , Loss: [1.4296069145202637, 0.46875]\n",
      "Epoch: 1247 , Loss: [1.4509530067443848, 0.484375]\n",
      "Epoch: 1248 , Loss: [1.40176522731781, 0.515625]\n",
      "Epoch: 1249 , Loss: [1.382851004600525, 0.546875]\n",
      "Epoch: 1250 , Loss: [1.464954137802124, 0.46875]\n",
      "=============================================\n",
      "5 correctly classified among 64\n",
      "Accuracy as of 1250 epochs: 7.8125\n",
      "=============================================\n",
      "Epoch: 1251 , Loss: [1.2777026891708374, 0.65625]\n",
      "Epoch: 1252 , Loss: [1.4756113290786743, 0.453125]\n",
      "Epoch: 1253 , Loss: [1.3955326080322266, 0.609375]\n",
      "Epoch: 1254 , Loss: [1.4102354049682617, 0.5]\n",
      "Epoch: 1255 , Loss: [1.4683573246002197, 0.484375]\n",
      "Epoch: 1256 , Loss: [1.3571783304214478, 0.484375]\n",
      "Epoch: 1257 , Loss: [1.4760510921478271, 0.453125]\n",
      "Epoch: 1258 , Loss: [1.3599936962127686, 0.546875]\n",
      "Epoch: 1259 , Loss: [1.4916936159133911, 0.453125]\n",
      "Epoch: 1260 , Loss: [1.3859307765960693, 0.5]\n",
      "Epoch: 1261 , Loss: [1.4507274627685547, 0.484375]\n",
      "Epoch: 1262 , Loss: [1.336534023284912, 0.59375]\n",
      "Epoch: 1263 , Loss: [1.3774189949035645, 0.546875]\n",
      "Epoch: 1264 , Loss: [1.4090553522109985, 0.515625]\n",
      "Epoch: 1265 , Loss: [1.3979178667068481, 0.484375]\n",
      "Epoch: 1266 , Loss: [1.3782813549041748, 0.5]\n",
      "Epoch: 1267 , Loss: [1.450937271118164, 0.390625]\n",
      "Epoch: 1268 , Loss: [1.3684310913085938, 0.59375]\n",
      "Epoch: 1269 , Loss: [1.3821592330932617, 0.5]\n",
      "Epoch: 1270 , Loss: [1.3809926509857178, 0.546875]\n",
      "Epoch: 1271 , Loss: [1.4654574394226074, 0.46875]\n",
      "Epoch: 1272 , Loss: [1.4524528980255127, 0.46875]\n",
      "Epoch: 1273 , Loss: [1.3788518905639648, 0.515625]\n",
      "Epoch: 1274 , Loss: [1.4502520561218262, 0.46875]\n",
      "Epoch: 1275 , Loss: [1.3864768743515015, 0.453125]\n",
      "Epoch: 1276 , Loss: [1.4021919965744019, 0.5]\n",
      "Epoch: 1277 , Loss: [1.2855844497680664, 0.640625]\n",
      "Epoch: 1278 , Loss: [1.3152406215667725, 0.578125]\n",
      "Epoch: 1279 , Loss: [1.4588249921798706, 0.453125]\n",
      "Epoch: 1280 , Loss: [1.4022321701049805, 0.59375]\n",
      "Epoch: 1281 , Loss: [1.4536305665969849, 0.40625]\n",
      "Epoch: 1282 , Loss: [1.465545415878296, 0.40625]\n",
      "Epoch: 1283 , Loss: [1.500146508216858, 0.375]\n",
      "Epoch: 1284 , Loss: [1.3893004655838013, 0.53125]\n",
      "Epoch: 1285 , Loss: [1.423069953918457, 0.4375]\n",
      "Epoch: 1286 , Loss: [1.272235631942749, 0.578125]\n",
      "Epoch: 1287 , Loss: [1.348770260810852, 0.5625]\n",
      "Epoch: 1288 , Loss: [1.4093917608261108, 0.40625]\n",
      "Epoch: 1289 , Loss: [1.362595796585083, 0.5]\n",
      "Epoch: 1290 , Loss: [1.3214881420135498, 0.625]\n",
      "Epoch: 1291 , Loss: [1.3985652923583984, 0.5]\n",
      "Epoch: 1292 , Loss: [1.3599663972854614, 0.5]\n",
      "Epoch: 1293 , Loss: [1.3577308654785156, 0.609375]\n",
      "Epoch: 1294 , Loss: [1.3233081102371216, 0.5]\n",
      "Epoch: 1295 , Loss: [1.4342970848083496, 0.546875]\n",
      "Epoch: 1296 , Loss: [1.4073035717010498, 0.484375]\n",
      "Epoch: 1297 , Loss: [1.3790619373321533, 0.453125]\n",
      "Epoch: 1298 , Loss: [1.4349799156188965, 0.453125]\n",
      "Epoch: 1299 , Loss: [1.3932236433029175, 0.515625]\n",
      "Epoch: 1300 , Loss: [1.367253303527832, 0.515625]\n",
      "Epoch: 1301 , Loss: [1.3555471897125244, 0.53125]\n",
      "Epoch: 1302 , Loss: [1.346846342086792, 0.546875]\n",
      "Epoch: 1303 , Loss: [1.332231044769287, 0.5]\n",
      "Epoch: 1304 , Loss: [1.3738070726394653, 0.5]\n",
      "Epoch: 1305 , Loss: [1.3681780099868774, 0.46875]\n",
      "Epoch: 1306 , Loss: [1.3608176708221436, 0.40625]\n",
      "Epoch: 1307 , Loss: [1.399735927581787, 0.421875]\n",
      "Epoch: 1308 , Loss: [1.3570351600646973, 0.484375]\n",
      "Epoch: 1309 , Loss: [1.2764060497283936, 0.53125]\n",
      "Epoch: 1310 , Loss: [1.3433353900909424, 0.515625]\n",
      "Epoch: 1311 , Loss: [1.3909306526184082, 0.484375]\n",
      "Epoch: 1312 , Loss: [1.3303823471069336, 0.546875]\n",
      "Epoch: 1313 , Loss: [1.4500306844711304, 0.359375]\n",
      "Epoch: 1314 , Loss: [1.3778749704360962, 0.484375]\n",
      "Epoch: 1315 , Loss: [1.3480395078659058, 0.53125]\n",
      "Epoch: 1316 , Loss: [1.3228602409362793, 0.5625]\n",
      "Epoch: 1317 , Loss: [1.322190284729004, 0.53125]\n",
      "Epoch: 1318 , Loss: [1.5675036907196045, 0.34375]\n",
      "Epoch: 1319 , Loss: [1.327383041381836, 0.578125]\n",
      "Epoch: 1320 , Loss: [1.4108996391296387, 0.34375]\n",
      "Epoch: 1321 , Loss: [1.258789300918579, 0.59375]\n",
      "Epoch: 1322 , Loss: [1.32169508934021, 0.5]\n",
      "Epoch: 1323 , Loss: [1.390622615814209, 0.453125]\n",
      "Epoch: 1324 , Loss: [1.3864927291870117, 0.4375]\n",
      "Epoch: 1325 , Loss: [1.3647786378860474, 0.453125]\n",
      "Epoch: 1326 , Loss: [1.4011820554733276, 0.5]\n",
      "Epoch: 1327 , Loss: [1.3424205780029297, 0.53125]\n",
      "Epoch: 1328 , Loss: [1.2593199014663696, 0.5625]\n",
      "Epoch: 1329 , Loss: [1.3085027933120728, 0.609375]\n",
      "Epoch: 1330 , Loss: [1.416622281074524, 0.40625]\n",
      "Epoch: 1331 , Loss: [1.3622777462005615, 0.5]\n",
      "Epoch: 1332 , Loss: [1.3883655071258545, 0.484375]\n",
      "Epoch: 1333 , Loss: [1.2909284830093384, 0.53125]\n",
      "Epoch: 1334 , Loss: [1.2309422492980957, 0.53125]\n",
      "Epoch: 1335 , Loss: [1.33613920211792, 0.515625]\n",
      "Epoch: 1336 , Loss: [1.3802216053009033, 0.421875]\n",
      "Epoch: 1337 , Loss: [1.3395483493804932, 0.484375]\n",
      "Epoch: 1338 , Loss: [1.4225540161132812, 0.421875]\n",
      "Epoch: 1339 , Loss: [1.3473083972930908, 0.46875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1340 , Loss: [1.3879239559173584, 0.484375]\n",
      "Epoch: 1341 , Loss: [1.267524242401123, 0.578125]\n",
      "Epoch: 1342 , Loss: [1.289618730545044, 0.546875]\n",
      "Epoch: 1343 , Loss: [1.2789045572280884, 0.546875]\n",
      "Epoch: 1344 , Loss: [1.3260729312896729, 0.5]\n",
      "Epoch: 1345 , Loss: [1.2711772918701172, 0.5625]\n",
      "Epoch: 1346 , Loss: [1.2610976696014404, 0.5625]\n",
      "Epoch: 1347 , Loss: [1.3448363542556763, 0.5]\n",
      "Epoch: 1348 , Loss: [1.3660181760787964, 0.546875]\n",
      "Epoch: 1349 , Loss: [1.307822585105896, 0.5]\n",
      "Epoch: 1350 , Loss: [1.2752774953842163, 0.484375]\n",
      "Epoch: 1351 , Loss: [1.3653751611709595, 0.453125]\n",
      "Epoch: 1352 , Loss: [1.3857868909835815, 0.421875]\n",
      "Epoch: 1353 , Loss: [1.2883338928222656, 0.5625]\n",
      "Epoch: 1354 , Loss: [1.3729865550994873, 0.4375]\n",
      "Epoch: 1355 , Loss: [1.3797022104263306, 0.453125]\n",
      "Epoch: 1356 , Loss: [1.351146936416626, 0.515625]\n",
      "Epoch: 1357 , Loss: [1.4228023290634155, 0.46875]\n",
      "Epoch: 1358 , Loss: [1.3178179264068604, 0.515625]\n",
      "Epoch: 1359 , Loss: [1.3778963088989258, 0.4375]\n",
      "Epoch: 1360 , Loss: [1.2897346019744873, 0.515625]\n",
      "Epoch: 1361 , Loss: [1.3118513822555542, 0.5]\n",
      "Epoch: 1362 , Loss: [1.3382269144058228, 0.46875]\n",
      "Epoch: 1363 , Loss: [1.3817723989486694, 0.421875]\n",
      "Epoch: 1364 , Loss: [1.3243821859359741, 0.5]\n",
      "Epoch: 1365 , Loss: [1.1838284730911255, 0.59375]\n",
      "Epoch: 1366 , Loss: [1.1774451732635498, 0.578125]\n",
      "Epoch: 1367 , Loss: [1.3421669006347656, 0.4375]\n",
      "Epoch: 1368 , Loss: [1.4588533639907837, 0.390625]\n",
      "Epoch: 1369 , Loss: [1.2886322736740112, 0.53125]\n",
      "Epoch: 1370 , Loss: [1.2929413318634033, 0.46875]\n",
      "Epoch: 1371 , Loss: [1.3493410348892212, 0.4375]\n",
      "Epoch: 1372 , Loss: [1.3470728397369385, 0.4375]\n",
      "Epoch: 1373 , Loss: [1.403480887413025, 0.453125]\n",
      "Epoch: 1374 , Loss: [1.194462537765503, 0.578125]\n",
      "Epoch: 1375 , Loss: [1.2735320329666138, 0.46875]\n",
      "Epoch: 1376 , Loss: [1.4078090190887451, 0.40625]\n",
      "Epoch: 1377 , Loss: [1.2959656715393066, 0.515625]\n",
      "Epoch: 1378 , Loss: [1.2108490467071533, 0.59375]\n",
      "Epoch: 1379 , Loss: [1.2471721172332764, 0.5625]\n",
      "Epoch: 1380 , Loss: [1.4022092819213867, 0.375]\n",
      "Epoch: 1381 , Loss: [1.16023850440979, 0.609375]\n",
      "Epoch: 1382 , Loss: [1.3332178592681885, 0.421875]\n",
      "Epoch: 1383 , Loss: [1.2673149108886719, 0.515625]\n",
      "Epoch: 1384 , Loss: [1.3028643131256104, 0.453125]\n",
      "Epoch: 1385 , Loss: [1.2676165103912354, 0.578125]\n",
      "Epoch: 1386 , Loss: [1.3865597248077393, 0.40625]\n",
      "Epoch: 1387 , Loss: [1.2919822931289673, 0.53125]\n",
      "Epoch: 1388 , Loss: [1.2180390357971191, 0.59375]\n",
      "Epoch: 1389 , Loss: [1.3147461414337158, 0.484375]\n",
      "Epoch: 1390 , Loss: [1.1534911394119263, 0.640625]\n",
      "Epoch: 1391 , Loss: [1.3281011581420898, 0.5]\n",
      "Epoch: 1392 , Loss: [1.3372478485107422, 0.390625]\n",
      "Epoch: 1393 , Loss: [1.3125967979431152, 0.40625]\n",
      "Epoch: 1394 , Loss: [1.24247145652771, 0.546875]\n",
      "Epoch: 1395 , Loss: [1.1931207180023193, 0.5625]\n",
      "Epoch: 1396 , Loss: [1.221035361289978, 0.609375]\n",
      "Epoch: 1397 , Loss: [1.3416608572006226, 0.4375]\n",
      "Epoch: 1398 , Loss: [1.2745548486709595, 0.53125]\n",
      "Epoch: 1399 , Loss: [1.2297072410583496, 0.546875]\n",
      "Epoch: 1400 , Loss: [1.206495761871338, 0.5625]\n",
      "Epoch: 1401 , Loss: [1.342353105545044, 0.453125]\n",
      "Epoch: 1402 , Loss: [1.2133734226226807, 0.5625]\n",
      "Epoch: 1403 , Loss: [1.3327901363372803, 0.515625]\n",
      "Epoch: 1404 , Loss: [1.239038109779358, 0.515625]\n",
      "Epoch: 1405 , Loss: [1.2396646738052368, 0.46875]\n",
      "Epoch: 1406 , Loss: [1.2835421562194824, 0.515625]\n",
      "Epoch: 1407 , Loss: [1.230729341506958, 0.484375]\n",
      "Epoch: 1408 , Loss: [1.2574291229248047, 0.53125]\n",
      "Epoch: 1409 , Loss: [1.251743197441101, 0.546875]\n",
      "Epoch: 1410 , Loss: [1.2586545944213867, 0.46875]\n",
      "Epoch: 1411 , Loss: [1.1775949001312256, 0.609375]\n",
      "Epoch: 1412 , Loss: [1.2245185375213623, 0.53125]\n",
      "Epoch: 1413 , Loss: [1.2577438354492188, 0.46875]\n",
      "Epoch: 1414 , Loss: [1.2939194440841675, 0.515625]\n",
      "Epoch: 1415 , Loss: [1.236950397491455, 0.5]\n",
      "Epoch: 1416 , Loss: [1.2544937133789062, 0.5625]\n",
      "Epoch: 1417 , Loss: [1.2161189317703247, 0.625]\n",
      "Epoch: 1418 , Loss: [1.262762427330017, 0.515625]\n",
      "Epoch: 1419 , Loss: [1.1778775453567505, 0.609375]\n",
      "Epoch: 1420 , Loss: [1.3107738494873047, 0.484375]\n",
      "Epoch: 1421 , Loss: [1.2561795711517334, 0.515625]\n",
      "Epoch: 1422 , Loss: [1.3199043273925781, 0.421875]\n",
      "Epoch: 1423 , Loss: [1.2849109172821045, 0.453125]\n",
      "Epoch: 1424 , Loss: [1.3166810274124146, 0.390625]\n",
      "Epoch: 1425 , Loss: [1.24382746219635, 0.5]\n",
      "Epoch: 1426 , Loss: [1.2797757387161255, 0.4375]\n",
      "Epoch: 1427 , Loss: [1.3729304075241089, 0.484375]\n",
      "Epoch: 1428 , Loss: [1.2427092790603638, 0.515625]\n",
      "Epoch: 1429 , Loss: [1.1994048357009888, 0.515625]\n",
      "Epoch: 1430 , Loss: [1.2524703741073608, 0.484375]\n",
      "Epoch: 1431 , Loss: [1.4044020175933838, 0.46875]\n",
      "Epoch: 1432 , Loss: [1.235987663269043, 0.53125]\n",
      "Epoch: 1433 , Loss: [1.185546875, 0.546875]\n",
      "Epoch: 1434 , Loss: [1.159591555595398, 0.578125]\n",
      "Epoch: 1435 , Loss: [1.2151474952697754, 0.46875]\n",
      "Epoch: 1436 , Loss: [1.3219635486602783, 0.4375]\n",
      "Epoch: 1437 , Loss: [1.2079267501831055, 0.484375]\n",
      "Epoch: 1438 , Loss: [1.2628440856933594, 0.453125]\n",
      "Epoch: 1439 , Loss: [1.1616981029510498, 0.59375]\n",
      "Epoch: 1440 , Loss: [1.21794593334198, 0.5625]\n",
      "Epoch: 1441 , Loss: [1.216352105140686, 0.53125]\n",
      "Epoch: 1442 , Loss: [1.2623720169067383, 0.484375]\n",
      "Epoch: 1443 , Loss: [1.353722095489502, 0.328125]\n",
      "Epoch: 1444 , Loss: [1.2354621887207031, 0.4375]\n",
      "Epoch: 1445 , Loss: [1.1459254026412964, 0.609375]\n",
      "Epoch: 1446 , Loss: [1.2307417392730713, 0.53125]\n",
      "Epoch: 1447 , Loss: [1.3132641315460205, 0.484375]\n",
      "Epoch: 1448 , Loss: [1.281104564666748, 0.421875]\n",
      "Epoch: 1449 , Loss: [1.230039119720459, 0.515625]\n",
      "Epoch: 1450 , Loss: [1.2201069593429565, 0.53125]\n",
      "Epoch: 1451 , Loss: [1.2516247034072876, 0.53125]\n",
      "Epoch: 1452 , Loss: [1.215329885482788, 0.546875]\n",
      "Epoch: 1453 , Loss: [1.2684903144836426, 0.453125]\n",
      "Epoch: 1454 , Loss: [1.2136039733886719, 0.484375]\n",
      "Epoch: 1455 , Loss: [1.2617199420928955, 0.40625]\n",
      "Epoch: 1456 , Loss: [1.2995694875717163, 0.421875]\n",
      "Epoch: 1457 , Loss: [1.2130202054977417, 0.5625]\n",
      "Epoch: 1458 , Loss: [1.2616814374923706, 0.546875]\n",
      "Epoch: 1459 , Loss: [1.1418358087539673, 0.65625]\n",
      "Epoch: 1460 , Loss: [1.2658884525299072, 0.46875]\n",
      "Epoch: 1461 , Loss: [1.1539177894592285, 0.546875]\n",
      "Epoch: 1462 , Loss: [1.1874432563781738, 0.578125]\n",
      "Epoch: 1463 , Loss: [1.2579917907714844, 0.421875]\n",
      "Epoch: 1464 , Loss: [1.1681976318359375, 0.515625]\n",
      "Epoch: 1465 , Loss: [1.206361174583435, 0.46875]\n",
      "Epoch: 1466 , Loss: [1.1772730350494385, 0.59375]\n",
      "Epoch: 1467 , Loss: [1.2309527397155762, 0.4375]\n",
      "Epoch: 1468 , Loss: [1.2495391368865967, 0.484375]\n",
      "Epoch: 1469 , Loss: [1.1471786499023438, 0.5625]\n",
      "Epoch: 1470 , Loss: [1.2048436403274536, 0.609375]\n",
      "Epoch: 1471 , Loss: [1.1125617027282715, 0.578125]\n",
      "Epoch: 1472 , Loss: [1.2485086917877197, 0.46875]\n",
      "Epoch: 1473 , Loss: [1.2726653814315796, 0.421875]\n",
      "Epoch: 1474 , Loss: [1.2281615734100342, 0.546875]\n",
      "Epoch: 1475 , Loss: [1.2119790315628052, 0.53125]\n",
      "Epoch: 1476 , Loss: [1.321049451828003, 0.453125]\n",
      "Epoch: 1477 , Loss: [1.181455135345459, 0.546875]\n",
      "Epoch: 1478 , Loss: [1.2861924171447754, 0.421875]\n",
      "Epoch: 1479 , Loss: [1.3258605003356934, 0.46875]\n",
      "Epoch: 1480 , Loss: [1.237101674079895, 0.5]\n",
      "Epoch: 1481 , Loss: [1.2235205173492432, 0.46875]\n",
      "Epoch: 1482 , Loss: [1.1851119995117188, 0.546875]\n",
      "Epoch: 1483 , Loss: [1.1921346187591553, 0.453125]\n",
      "Epoch: 1484 , Loss: [1.2597724199295044, 0.484375]\n",
      "Epoch: 1485 , Loss: [1.2503409385681152, 0.453125]\n",
      "Epoch: 1486 , Loss: [1.3193260431289673, 0.40625]\n",
      "Epoch: 1487 , Loss: [1.242552399635315, 0.5]\n",
      "Epoch: 1488 , Loss: [1.1812418699264526, 0.625]\n",
      "Epoch: 1489 , Loss: [1.1137924194335938, 0.640625]\n",
      "Epoch: 1490 , Loss: [1.2056598663330078, 0.5625]\n",
      "Epoch: 1491 , Loss: [1.3254261016845703, 0.34375]\n",
      "Epoch: 1492 , Loss: [1.176558017730713, 0.53125]\n",
      "Epoch: 1493 , Loss: [1.1345083713531494, 0.609375]\n",
      "Epoch: 1494 , Loss: [1.1337475776672363, 0.5625]\n",
      "Epoch: 1495 , Loss: [1.1854649782180786, 0.5625]\n",
      "Epoch: 1496 , Loss: [1.1643470525741577, 0.5625]\n",
      "Epoch: 1497 , Loss: [1.2666866779327393, 0.53125]\n",
      "Epoch: 1498 , Loss: [1.2493830919265747, 0.484375]\n",
      "Epoch: 1499 , Loss: [1.1683077812194824, 0.546875]\n",
      "Epoch: 1500 , Loss: [1.1893366575241089, 0.515625]\n",
      "=============================================\n",
      "2 correctly classified among 64\n",
      "Accuracy as of 1500 epochs: 3.125\n",
      "=============================================\n",
      "Epoch: 1501 , Loss: [1.1189162731170654, 0.59375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1502 , Loss: [1.202765941619873, 0.5625]\n",
      "Epoch: 1503 , Loss: [1.196677803993225, 0.515625]\n",
      "Epoch: 1504 , Loss: [1.182450771331787, 0.578125]\n",
      "Epoch: 1505 , Loss: [1.1346676349639893, 0.59375]\n",
      "Epoch: 1506 , Loss: [1.2414138317108154, 0.484375]\n",
      "Epoch: 1507 , Loss: [1.1556267738342285, 0.640625]\n",
      "Epoch: 1508 , Loss: [1.2398402690887451, 0.515625]\n",
      "Epoch: 1509 , Loss: [1.2152326107025146, 0.40625]\n",
      "Epoch: 1510 , Loss: [1.2112326622009277, 0.484375]\n",
      "Epoch: 1511 , Loss: [1.1367526054382324, 0.5625]\n",
      "Epoch: 1512 , Loss: [1.2786469459533691, 0.40625]\n",
      "Epoch: 1513 , Loss: [1.0779893398284912, 0.65625]\n",
      "Epoch: 1514 , Loss: [1.2983856201171875, 0.34375]\n",
      "Epoch: 1515 , Loss: [1.1963920593261719, 0.53125]\n",
      "Epoch: 1516 , Loss: [1.29599130153656, 0.5]\n",
      "Epoch: 1517 , Loss: [1.2596789598464966, 0.484375]\n",
      "Epoch: 1518 , Loss: [1.1843864917755127, 0.484375]\n",
      "Epoch: 1519 , Loss: [1.2511053085327148, 0.4375]\n",
      "Epoch: 1520 , Loss: [1.1206927299499512, 0.53125]\n",
      "Epoch: 1521 , Loss: [1.1533831357955933, 0.5625]\n",
      "Epoch: 1522 , Loss: [1.2513258457183838, 0.421875]\n",
      "Epoch: 1523 , Loss: [1.188441276550293, 0.453125]\n",
      "Epoch: 1524 , Loss: [1.1938763856887817, 0.46875]\n",
      "Epoch: 1525 , Loss: [1.2470667362213135, 0.40625]\n",
      "Epoch: 1526 , Loss: [1.1473759412765503, 0.484375]\n",
      "Epoch: 1527 , Loss: [1.257219910621643, 0.4375]\n",
      "Epoch: 1528 , Loss: [1.184045672416687, 0.5]\n",
      "Epoch: 1529 , Loss: [1.2960262298583984, 0.359375]\n",
      "Epoch: 1530 , Loss: [1.1566518545150757, 0.53125]\n",
      "Epoch: 1531 , Loss: [1.1770169734954834, 0.484375]\n",
      "Epoch: 1532 , Loss: [1.1546475887298584, 0.625]\n",
      "Epoch: 1533 , Loss: [1.1379139423370361, 0.5625]\n",
      "Epoch: 1534 , Loss: [1.1396139860153198, 0.546875]\n",
      "Epoch: 1535 , Loss: [1.2198665142059326, 0.46875]\n",
      "Epoch: 1536 , Loss: [1.2540180683135986, 0.4375]\n",
      "Epoch: 1537 , Loss: [1.1336979866027832, 0.609375]\n",
      "Epoch: 1538 , Loss: [1.2356348037719727, 0.46875]\n",
      "Epoch: 1539 , Loss: [1.3835009336471558, 0.265625]\n",
      "Epoch: 1540 , Loss: [1.2589004039764404, 0.46875]\n",
      "Epoch: 1541 , Loss: [1.1827967166900635, 0.53125]\n",
      "Epoch: 1542 , Loss: [1.2062345743179321, 0.53125]\n",
      "Epoch: 1543 , Loss: [1.0997896194458008, 0.59375]\n",
      "Epoch: 1544 , Loss: [1.1608233451843262, 0.546875]\n",
      "Epoch: 1545 , Loss: [1.1378841400146484, 0.578125]\n",
      "Epoch: 1546 , Loss: [1.1715844869613647, 0.46875]\n",
      "Epoch: 1547 , Loss: [1.251786231994629, 0.421875]\n",
      "Epoch: 1548 , Loss: [1.1385515928268433, 0.53125]\n",
      "Epoch: 1549 , Loss: [1.212812900543213, 0.4375]\n",
      "Epoch: 1550 , Loss: [1.1376709938049316, 0.515625]\n",
      "Epoch: 1551 , Loss: [1.1376408338546753, 0.609375]\n",
      "Epoch: 1552 , Loss: [1.1652418375015259, 0.546875]\n",
      "Epoch: 1553 , Loss: [1.2100616693496704, 0.515625]\n",
      "Epoch: 1554 , Loss: [1.1729321479797363, 0.546875]\n",
      "Epoch: 1555 , Loss: [1.1459622383117676, 0.53125]\n",
      "Epoch: 1556 , Loss: [1.1939386129379272, 0.5]\n",
      "Epoch: 1557 , Loss: [1.183504581451416, 0.421875]\n",
      "Epoch: 1558 , Loss: [1.157991886138916, 0.5]\n",
      "Epoch: 1559 , Loss: [1.1715948581695557, 0.5]\n",
      "Epoch: 1560 , Loss: [1.1714816093444824, 0.4375]\n",
      "Epoch: 1561 , Loss: [1.1829806566238403, 0.484375]\n",
      "Epoch: 1562 , Loss: [1.1473973989486694, 0.578125]\n",
      "Epoch: 1563 , Loss: [1.1541558504104614, 0.609375]\n",
      "Epoch: 1564 , Loss: [1.3093924522399902, 0.453125]\n",
      "Epoch: 1565 , Loss: [1.2032983303070068, 0.46875]\n",
      "Epoch: 1566 , Loss: [1.1858503818511963, 0.5]\n",
      "Epoch: 1567 , Loss: [1.1631274223327637, 0.53125]\n",
      "Epoch: 1568 , Loss: [1.1809431314468384, 0.53125]\n",
      "Epoch: 1569 , Loss: [1.1344932317733765, 0.53125]\n",
      "Epoch: 1570 , Loss: [1.228928565979004, 0.5]\n",
      "Epoch: 1571 , Loss: [1.1348741054534912, 0.578125]\n",
      "Epoch: 1572 , Loss: [1.208936333656311, 0.390625]\n",
      "Epoch: 1573 , Loss: [1.169386863708496, 0.5]\n",
      "Epoch: 1574 , Loss: [1.2143399715423584, 0.5]\n",
      "Epoch: 1575 , Loss: [1.2800594568252563, 0.390625]\n",
      "Epoch: 1576 , Loss: [1.1606194972991943, 0.4375]\n",
      "Epoch: 1577 , Loss: [1.1908655166625977, 0.546875]\n",
      "Epoch: 1578 , Loss: [1.144556999206543, 0.5625]\n",
      "Epoch: 1579 , Loss: [1.1570281982421875, 0.578125]\n",
      "Epoch: 1580 , Loss: [1.1117186546325684, 0.59375]\n",
      "Epoch: 1581 , Loss: [1.0767295360565186, 0.578125]\n",
      "Epoch: 1582 , Loss: [1.2337751388549805, 0.46875]\n",
      "Epoch: 1583 , Loss: [1.1595669984817505, 0.515625]\n",
      "Epoch: 1584 , Loss: [1.1058993339538574, 0.578125]\n",
      "Epoch: 1585 , Loss: [1.1720565557479858, 0.546875]\n",
      "Epoch: 1586 , Loss: [1.15326726436615, 0.515625]\n",
      "Epoch: 1587 , Loss: [1.2028652429580688, 0.484375]\n",
      "Epoch: 1588 , Loss: [1.2166688442230225, 0.421875]\n",
      "Epoch: 1589 , Loss: [1.1793807744979858, 0.46875]\n",
      "Epoch: 1590 , Loss: [1.1753439903259277, 0.421875]\n",
      "Epoch: 1591 , Loss: [1.1641411781311035, 0.578125]\n",
      "Epoch: 1592 , Loss: [1.1609165668487549, 0.5]\n",
      "Epoch: 1593 , Loss: [1.166254997253418, 0.5]\n",
      "Epoch: 1594 , Loss: [1.1228492259979248, 0.515625]\n",
      "Epoch: 1595 , Loss: [1.2901235818862915, 0.40625]\n",
      "Epoch: 1596 , Loss: [1.0863652229309082, 0.546875]\n",
      "Epoch: 1597 , Loss: [1.1100084781646729, 0.515625]\n",
      "Epoch: 1598 , Loss: [1.2078354358673096, 0.46875]\n",
      "Epoch: 1599 , Loss: [1.215104579925537, 0.453125]\n",
      "Epoch: 1600 , Loss: [1.1420361995697021, 0.453125]\n",
      "Epoch: 1601 , Loss: [1.16653573513031, 0.5]\n",
      "Epoch: 1602 , Loss: [1.135751724243164, 0.515625]\n",
      "Epoch: 1603 , Loss: [1.1648674011230469, 0.5]\n",
      "Epoch: 1604 , Loss: [1.146376609802246, 0.46875]\n",
      "Epoch: 1605 , Loss: [1.1347496509552002, 0.578125]\n",
      "Epoch: 1606 , Loss: [1.1436914205551147, 0.546875]\n",
      "Epoch: 1607 , Loss: [1.1618947982788086, 0.453125]\n",
      "Epoch: 1608 , Loss: [1.2008581161499023, 0.5]\n",
      "Epoch: 1609 , Loss: [1.0531504154205322, 0.578125]\n",
      "Epoch: 1610 , Loss: [1.1343843936920166, 0.53125]\n",
      "Epoch: 1611 , Loss: [1.1361851692199707, 0.546875]\n",
      "Epoch: 1612 , Loss: [1.0952088832855225, 0.578125]\n",
      "Epoch: 1613 , Loss: [1.1610445976257324, 0.453125]\n",
      "Epoch: 1614 , Loss: [1.1805691719055176, 0.5]\n",
      "Epoch: 1615 , Loss: [1.0811090469360352, 0.484375]\n",
      "Epoch: 1616 , Loss: [1.1460063457489014, 0.515625]\n",
      "Epoch: 1617 , Loss: [1.1087250709533691, 0.578125]\n",
      "Epoch: 1618 , Loss: [1.1859278678894043, 0.40625]\n",
      "Epoch: 1619 , Loss: [1.1484100818634033, 0.4375]\n",
      "Epoch: 1620 , Loss: [1.1940827369689941, 0.4375]\n",
      "Epoch: 1621 , Loss: [1.0990073680877686, 0.5]\n",
      "Epoch: 1622 , Loss: [1.164712905883789, 0.453125]\n",
      "Epoch: 1623 , Loss: [1.0982823371887207, 0.546875]\n",
      "Epoch: 1624 , Loss: [1.1198627948760986, 0.53125]\n",
      "Epoch: 1625 , Loss: [1.1542284488677979, 0.53125]\n",
      "Epoch: 1626 , Loss: [1.1140525341033936, 0.484375]\n",
      "Epoch: 1627 , Loss: [1.1708457469940186, 0.421875]\n",
      "Epoch: 1628 , Loss: [1.1269102096557617, 0.4375]\n",
      "Epoch: 1629 , Loss: [1.0479227304458618, 0.609375]\n",
      "Epoch: 1630 , Loss: [1.3064624071121216, 0.359375]\n",
      "Epoch: 1631 , Loss: [1.2114689350128174, 0.421875]\n",
      "Epoch: 1632 , Loss: [1.165215253829956, 0.4375]\n",
      "Epoch: 1633 , Loss: [1.1201887130737305, 0.578125]\n",
      "Epoch: 1634 , Loss: [1.1082191467285156, 0.5625]\n",
      "Epoch: 1635 , Loss: [1.129164695739746, 0.46875]\n",
      "Epoch: 1636 , Loss: [1.1599392890930176, 0.421875]\n",
      "Epoch: 1637 , Loss: [1.1614476442337036, 0.46875]\n",
      "Epoch: 1638 , Loss: [1.1447882652282715, 0.46875]\n",
      "Epoch: 1639 , Loss: [1.1904027462005615, 0.421875]\n",
      "Epoch: 1640 , Loss: [1.156284213066101, 0.5]\n",
      "Epoch: 1641 , Loss: [1.0971407890319824, 0.515625]\n",
      "Epoch: 1642 , Loss: [1.0569753646850586, 0.5625]\n",
      "Epoch: 1643 , Loss: [1.0474436283111572, 0.59375]\n",
      "Epoch: 1644 , Loss: [1.0735454559326172, 0.578125]\n",
      "Epoch: 1645 , Loss: [1.0424084663391113, 0.5625]\n",
      "Epoch: 1646 , Loss: [1.0539599657058716, 0.578125]\n",
      "Epoch: 1647 , Loss: [1.081407904624939, 0.484375]\n",
      "Epoch: 1648 , Loss: [1.1191458702087402, 0.484375]\n",
      "Epoch: 1649 , Loss: [1.107322335243225, 0.5]\n",
      "Epoch: 1650 , Loss: [1.1205294132232666, 0.515625]\n",
      "Epoch: 1651 , Loss: [1.207844614982605, 0.453125]\n",
      "Epoch: 1652 , Loss: [1.2007757425308228, 0.484375]\n",
      "Epoch: 1653 , Loss: [1.2250816822052002, 0.359375]\n",
      "Epoch: 1654 , Loss: [1.0958986282348633, 0.53125]\n",
      "Epoch: 1655 , Loss: [1.2068824768066406, 0.390625]\n",
      "Epoch: 1656 , Loss: [1.188317894935608, 0.453125]\n",
      "Epoch: 1657 , Loss: [1.0717023611068726, 0.5]\n",
      "Epoch: 1658 , Loss: [1.1292445659637451, 0.578125]\n",
      "Epoch: 1659 , Loss: [1.1648190021514893, 0.359375]\n",
      "Epoch: 1660 , Loss: [1.1704120635986328, 0.40625]\n",
      "Epoch: 1661 , Loss: [1.0622038841247559, 0.53125]\n",
      "Epoch: 1662 , Loss: [1.0498467683792114, 0.59375]\n",
      "Epoch: 1663 , Loss: [1.123986840248108, 0.515625]\n",
      "Epoch: 1664 , Loss: [1.115856409072876, 0.5625]\n",
      "Epoch: 1665 , Loss: [1.0979243516921997, 0.484375]\n",
      "Epoch: 1666 , Loss: [1.100170373916626, 0.453125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1667 , Loss: [1.1730934381484985, 0.484375]\n",
      "Epoch: 1668 , Loss: [1.1443073749542236, 0.453125]\n",
      "Epoch: 1669 , Loss: [1.1165297031402588, 0.53125]\n",
      "Epoch: 1670 , Loss: [1.1128883361816406, 0.578125]\n",
      "Epoch: 1671 , Loss: [1.100333571434021, 0.5]\n",
      "Epoch: 1672 , Loss: [1.1155436038970947, 0.5]\n",
      "Epoch: 1673 , Loss: [1.121132493019104, 0.46875]\n",
      "Epoch: 1674 , Loss: [1.110191822052002, 0.515625]\n",
      "Epoch: 1675 , Loss: [1.0460516214370728, 0.671875]\n",
      "Epoch: 1676 , Loss: [1.113602638244629, 0.546875]\n",
      "Epoch: 1677 , Loss: [1.0700805187225342, 0.5625]\n",
      "Epoch: 1678 , Loss: [1.145999789237976, 0.484375]\n",
      "Epoch: 1679 , Loss: [1.072063684463501, 0.578125]\n",
      "Epoch: 1680 , Loss: [1.1278406381607056, 0.53125]\n",
      "Epoch: 1681 , Loss: [1.1011961698532104, 0.4375]\n",
      "Epoch: 1682 , Loss: [1.0744684934616089, 0.546875]\n",
      "Epoch: 1683 , Loss: [1.0518863201141357, 0.546875]\n",
      "Epoch: 1684 , Loss: [1.1633970737457275, 0.421875]\n",
      "Epoch: 1685 , Loss: [1.067049264907837, 0.53125]\n",
      "Epoch: 1686 , Loss: [1.1547112464904785, 0.40625]\n",
      "Epoch: 1687 , Loss: [1.1488969326019287, 0.5]\n",
      "Epoch: 1688 , Loss: [1.138503074645996, 0.484375]\n",
      "Epoch: 1689 , Loss: [1.1894936561584473, 0.46875]\n",
      "Epoch: 1690 , Loss: [1.1243274211883545, 0.453125]\n",
      "Epoch: 1691 , Loss: [1.1240124702453613, 0.40625]\n",
      "Epoch: 1692 , Loss: [1.0908020734786987, 0.53125]\n",
      "Epoch: 1693 , Loss: [1.1278523206710815, 0.5]\n",
      "Epoch: 1694 , Loss: [1.040745735168457, 0.609375]\n",
      "Epoch: 1695 , Loss: [1.1146554946899414, 0.546875]\n",
      "Epoch: 1696 , Loss: [1.0861032009124756, 0.421875]\n",
      "Epoch: 1697 , Loss: [1.1229323148727417, 0.546875]\n",
      "Epoch: 1698 , Loss: [1.149376630783081, 0.390625]\n",
      "Epoch: 1699 , Loss: [1.1139878034591675, 0.53125]\n",
      "Epoch: 1700 , Loss: [1.106642484664917, 0.4375]\n",
      "Epoch: 1701 , Loss: [1.0727070569992065, 0.53125]\n",
      "Epoch: 1702 , Loss: [1.160130500793457, 0.4375]\n",
      "Epoch: 1703 , Loss: [1.133420705795288, 0.53125]\n",
      "Epoch: 1704 , Loss: [1.0891916751861572, 0.5]\n",
      "Epoch: 1705 , Loss: [1.1325623989105225, 0.46875]\n",
      "Epoch: 1706 , Loss: [1.1212763786315918, 0.46875]\n",
      "Epoch: 1707 , Loss: [1.1393699645996094, 0.53125]\n",
      "Epoch: 1708 , Loss: [1.0236304998397827, 0.5625]\n",
      "Epoch: 1709 , Loss: [1.2503058910369873, 0.390625]\n",
      "Epoch: 1710 , Loss: [1.1039077043533325, 0.515625]\n",
      "Epoch: 1711 , Loss: [1.1163780689239502, 0.515625]\n",
      "Epoch: 1712 , Loss: [1.1229909658432007, 0.5]\n",
      "Epoch: 1713 , Loss: [1.1316404342651367, 0.484375]\n",
      "Epoch: 1714 , Loss: [1.1076364517211914, 0.515625]\n",
      "Epoch: 1715 , Loss: [1.0927947759628296, 0.609375]\n",
      "Epoch: 1716 , Loss: [1.11862051486969, 0.4375]\n",
      "Epoch: 1717 , Loss: [1.0364904403686523, 0.625]\n",
      "Epoch: 1718 , Loss: [1.11698579788208, 0.484375]\n",
      "Epoch: 1719 , Loss: [1.1091769933700562, 0.484375]\n",
      "Epoch: 1720 , Loss: [1.1537582874298096, 0.4375]\n",
      "Epoch: 1721 , Loss: [1.0390145778656006, 0.578125]\n",
      "Epoch: 1722 , Loss: [1.1380188465118408, 0.4375]\n",
      "Epoch: 1723 , Loss: [1.1371533870697021, 0.484375]\n",
      "Epoch: 1724 , Loss: [1.1452652215957642, 0.375]\n",
      "Epoch: 1725 , Loss: [1.2098753452301025, 0.359375]\n",
      "Epoch: 1726 , Loss: [1.0320851802825928, 0.546875]\n",
      "Epoch: 1727 , Loss: [1.0845654010772705, 0.46875]\n",
      "Epoch: 1728 , Loss: [1.1366063356399536, 0.46875]\n",
      "Epoch: 1729 , Loss: [1.0678515434265137, 0.53125]\n",
      "Epoch: 1730 , Loss: [1.12369704246521, 0.453125]\n",
      "Epoch: 1731 , Loss: [1.0927644968032837, 0.515625]\n",
      "Epoch: 1732 , Loss: [1.102874994277954, 0.5]\n",
      "Epoch: 1733 , Loss: [1.0600299835205078, 0.46875]\n",
      "Epoch: 1734 , Loss: [1.082404613494873, 0.5]\n",
      "Epoch: 1735 , Loss: [1.0818796157836914, 0.484375]\n",
      "Epoch: 1736 , Loss: [1.080552101135254, 0.546875]\n",
      "Epoch: 1737 , Loss: [1.0618748664855957, 0.59375]\n",
      "Epoch: 1738 , Loss: [1.0641354322433472, 0.578125]\n",
      "Epoch: 1739 , Loss: [1.0186891555786133, 0.53125]\n",
      "Epoch: 1740 , Loss: [1.0898802280426025, 0.53125]\n",
      "Epoch: 1741 , Loss: [1.0755772590637207, 0.546875]\n",
      "Epoch: 1742 , Loss: [1.018134593963623, 0.484375]\n",
      "Epoch: 1743 , Loss: [1.1137897968292236, 0.46875]\n",
      "Epoch: 1744 , Loss: [1.0496875047683716, 0.53125]\n",
      "Epoch: 1745 , Loss: [1.0730431079864502, 0.5625]\n",
      "Epoch: 1746 , Loss: [1.079057216644287, 0.5625]\n",
      "Epoch: 1747 , Loss: [1.0932817459106445, 0.4375]\n",
      "Epoch: 1748 , Loss: [1.091801643371582, 0.46875]\n",
      "Epoch: 1749 , Loss: [1.077554702758789, 0.53125]\n",
      "Epoch: 1750 , Loss: [1.1153414249420166, 0.515625]\n",
      "=============================================\n",
      "1 correctly classified among 64\n",
      "Accuracy as of 1750 epochs: 1.5625\n",
      "=============================================\n",
      "Epoch: 1751 , Loss: [1.205926775932312, 0.328125]\n",
      "Epoch: 1752 , Loss: [1.0941859483718872, 0.390625]\n",
      "Epoch: 1753 , Loss: [1.1045606136322021, 0.421875]\n",
      "Epoch: 1754 , Loss: [1.09697425365448, 0.53125]\n",
      "Epoch: 1755 , Loss: [1.0867843627929688, 0.390625]\n",
      "Epoch: 1756 , Loss: [1.0364112854003906, 0.625]\n",
      "Epoch: 1757 , Loss: [1.0800584554672241, 0.484375]\n",
      "Epoch: 1758 , Loss: [1.139660120010376, 0.359375]\n",
      "Epoch: 1759 , Loss: [1.0956132411956787, 0.484375]\n",
      "Epoch: 1760 , Loss: [1.076995611190796, 0.46875]\n",
      "Epoch: 1761 , Loss: [1.094341516494751, 0.515625]\n",
      "Epoch: 1762 , Loss: [1.0084997415542603, 0.5625]\n",
      "Epoch: 1763 , Loss: [1.1282302141189575, 0.46875]\n",
      "Epoch: 1764 , Loss: [1.0202577114105225, 0.640625]\n",
      "Epoch: 1765 , Loss: [1.1453275680541992, 0.484375]\n",
      "Epoch: 1766 , Loss: [1.1028528213500977, 0.453125]\n",
      "Epoch: 1767 , Loss: [1.1206836700439453, 0.484375]\n",
      "Epoch: 1768 , Loss: [1.0734751224517822, 0.453125]\n",
      "Epoch: 1769 , Loss: [1.183839201927185, 0.515625]\n",
      "Epoch: 1770 , Loss: [1.0950968265533447, 0.546875]\n",
      "Epoch: 1771 , Loss: [1.0736390352249146, 0.546875]\n",
      "Epoch: 1772 , Loss: [1.0592591762542725, 0.59375]\n",
      "Epoch: 1773 , Loss: [1.0467512607574463, 0.5]\n",
      "Epoch: 1774 , Loss: [1.0514663457870483, 0.5]\n",
      "Epoch: 1775 , Loss: [1.064024806022644, 0.5]\n",
      "Epoch: 1776 , Loss: [1.0241211652755737, 0.578125]\n",
      "Epoch: 1777 , Loss: [1.1574883460998535, 0.453125]\n",
      "Epoch: 1778 , Loss: [1.097814917564392, 0.4375]\n",
      "Epoch: 1779 , Loss: [1.0405571460723877, 0.5]\n",
      "Epoch: 1780 , Loss: [1.0825709104537964, 0.484375]\n",
      "Epoch: 1781 , Loss: [1.0749272108078003, 0.453125]\n",
      "Epoch: 1782 , Loss: [1.0443228483200073, 0.515625]\n",
      "Epoch: 1783 , Loss: [1.0641658306121826, 0.515625]\n",
      "Epoch: 1784 , Loss: [1.1021249294281006, 0.5]\n",
      "Epoch: 1785 , Loss: [1.0368256568908691, 0.515625]\n",
      "Epoch: 1786 , Loss: [1.077174425125122, 0.5625]\n",
      "Epoch: 1787 , Loss: [1.0869011878967285, 0.4375]\n",
      "Epoch: 1788 , Loss: [1.1202797889709473, 0.40625]\n",
      "Epoch: 1789 , Loss: [1.1157824993133545, 0.515625]\n",
      "Epoch: 1790 , Loss: [1.0980571508407593, 0.484375]\n",
      "Epoch: 1791 , Loss: [1.1897481679916382, 0.390625]\n",
      "Epoch: 1792 , Loss: [1.135237455368042, 0.40625]\n",
      "Epoch: 1793 , Loss: [1.071293592453003, 0.53125]\n",
      "Epoch: 1794 , Loss: [1.1415934562683105, 0.453125]\n",
      "Epoch: 1795 , Loss: [1.1172938346862793, 0.421875]\n",
      "Epoch: 1796 , Loss: [1.0700148344039917, 0.5]\n",
      "Epoch: 1797 , Loss: [1.032558798789978, 0.484375]\n",
      "Epoch: 1798 , Loss: [1.1730297803878784, 0.375]\n",
      "Epoch: 1799 , Loss: [1.0260908603668213, 0.578125]\n",
      "Epoch: 1800 , Loss: [1.0286587476730347, 0.515625]\n",
      "Epoch: 1801 , Loss: [1.1124835014343262, 0.4375]\n",
      "Epoch: 1802 , Loss: [1.087010383605957, 0.484375]\n",
      "Epoch: 1803 , Loss: [1.1101638078689575, 0.4375]\n",
      "Epoch: 1804 , Loss: [1.0402679443359375, 0.59375]\n",
      "Epoch: 1805 , Loss: [1.095919132232666, 0.4375]\n",
      "Epoch: 1806 , Loss: [1.0485107898712158, 0.484375]\n",
      "Epoch: 1807 , Loss: [1.143294095993042, 0.375]\n",
      "Epoch: 1808 , Loss: [1.0074247121810913, 0.515625]\n",
      "Epoch: 1809 , Loss: [1.0432676076889038, 0.515625]\n",
      "Epoch: 1810 , Loss: [1.0969868898391724, 0.484375]\n",
      "Epoch: 1811 , Loss: [1.0874106884002686, 0.5625]\n",
      "Epoch: 1812 , Loss: [1.089919090270996, 0.40625]\n",
      "Epoch: 1813 , Loss: [1.0856921672821045, 0.453125]\n",
      "Epoch: 1814 , Loss: [1.0442938804626465, 0.484375]\n",
      "Epoch: 1815 , Loss: [1.0742899179458618, 0.5]\n",
      "Epoch: 1816 , Loss: [1.0129947662353516, 0.625]\n",
      "Epoch: 1817 , Loss: [1.093498945236206, 0.46875]\n",
      "Epoch: 1818 , Loss: [0.9892309904098511, 0.609375]\n",
      "Epoch: 1819 , Loss: [1.0181607007980347, 0.59375]\n",
      "Epoch: 1820 , Loss: [1.0812482833862305, 0.546875]\n",
      "Epoch: 1821 , Loss: [1.0371644496917725, 0.53125]\n",
      "Epoch: 1822 , Loss: [1.088876724243164, 0.421875]\n",
      "Epoch: 1823 , Loss: [1.0904005765914917, 0.453125]\n",
      "Epoch: 1824 , Loss: [1.051783561706543, 0.453125]\n",
      "Epoch: 1825 , Loss: [1.0668578147888184, 0.4375]\n",
      "Epoch: 1826 , Loss: [1.0653775930404663, 0.515625]\n",
      "Epoch: 1827 , Loss: [1.0586426258087158, 0.453125]\n",
      "Epoch: 1828 , Loss: [1.0563116073608398, 0.40625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1829 , Loss: [1.100024700164795, 0.4375]\n",
      "Epoch: 1830 , Loss: [1.0413703918457031, 0.59375]\n",
      "Epoch: 1831 , Loss: [1.0956897735595703, 0.5]\n",
      "Epoch: 1832 , Loss: [1.1073451042175293, 0.5]\n",
      "Epoch: 1833 , Loss: [1.0627527236938477, 0.4375]\n",
      "Epoch: 1834 , Loss: [0.9743421077728271, 0.59375]\n",
      "Epoch: 1835 , Loss: [1.0415278673171997, 0.5625]\n",
      "Epoch: 1836 , Loss: [1.0998618602752686, 0.40625]\n",
      "Epoch: 1837 , Loss: [1.0458414554595947, 0.546875]\n",
      "Epoch: 1838 , Loss: [1.054070234298706, 0.484375]\n",
      "Epoch: 1839 , Loss: [1.0883429050445557, 0.53125]\n",
      "Epoch: 1840 , Loss: [1.0853440761566162, 0.4375]\n",
      "Epoch: 1841 , Loss: [1.0709729194641113, 0.40625]\n",
      "Epoch: 1842 , Loss: [1.081120252609253, 0.5]\n",
      "Epoch: 1843 , Loss: [1.0968314409255981, 0.453125]\n",
      "Epoch: 1844 , Loss: [1.0918469429016113, 0.453125]\n",
      "Epoch: 1845 , Loss: [1.10795259475708, 0.40625]\n",
      "Epoch: 1846 , Loss: [1.02116858959198, 0.5]\n",
      "Epoch: 1847 , Loss: [1.0408172607421875, 0.515625]\n",
      "Epoch: 1848 , Loss: [0.996289849281311, 0.609375]\n",
      "Epoch: 1849 , Loss: [1.1021267175674438, 0.40625]\n",
      "Epoch: 1850 , Loss: [1.089699387550354, 0.421875]\n",
      "Epoch: 1851 , Loss: [1.0908482074737549, 0.375]\n",
      "Epoch: 1852 , Loss: [1.1091041564941406, 0.34375]\n",
      "Epoch: 1853 , Loss: [0.9945744276046753, 0.578125]\n",
      "Epoch: 1854 , Loss: [1.1032044887542725, 0.4375]\n",
      "Epoch: 1855 , Loss: [1.0220807790756226, 0.4375]\n",
      "Epoch: 1856 , Loss: [1.00469970703125, 0.5625]\n",
      "Epoch: 1857 , Loss: [1.014103889465332, 0.609375]\n",
      "Epoch: 1858 , Loss: [1.028020977973938, 0.46875]\n",
      "Epoch: 1859 , Loss: [1.0345782041549683, 0.453125]\n",
      "Epoch: 1860 , Loss: [0.953762412071228, 0.59375]\n",
      "Epoch: 1861 , Loss: [1.0159200429916382, 0.5]\n",
      "Epoch: 1862 , Loss: [1.1347541809082031, 0.359375]\n",
      "Epoch: 1863 , Loss: [1.0910927057266235, 0.40625]\n",
      "Epoch: 1864 , Loss: [1.1057347059249878, 0.4375]\n",
      "Epoch: 1865 , Loss: [1.0078996419906616, 0.5]\n",
      "Epoch: 1866 , Loss: [1.0471229553222656, 0.46875]\n",
      "Epoch: 1867 , Loss: [1.074864387512207, 0.5]\n",
      "Epoch: 1868 , Loss: [1.044236183166504, 0.5625]\n",
      "Epoch: 1869 , Loss: [1.0419750213623047, 0.421875]\n",
      "Epoch: 1870 , Loss: [0.9628595113754272, 0.578125]\n",
      "Epoch: 1871 , Loss: [1.0739554166793823, 0.421875]\n",
      "Epoch: 1872 , Loss: [0.9787346124649048, 0.546875]\n",
      "Epoch: 1873 , Loss: [1.0135453939437866, 0.515625]\n",
      "Epoch: 1874 , Loss: [0.9643383026123047, 0.59375]\n",
      "Epoch: 1875 , Loss: [1.0221097469329834, 0.46875]\n",
      "Epoch: 1876 , Loss: [1.0569813251495361, 0.515625]\n",
      "Epoch: 1877 , Loss: [1.0196418762207031, 0.5]\n",
      "Epoch: 1878 , Loss: [0.9691627025604248, 0.578125]\n",
      "Epoch: 1879 , Loss: [1.0189976692199707, 0.484375]\n",
      "Epoch: 1880 , Loss: [0.9427019357681274, 0.609375]\n",
      "Epoch: 1881 , Loss: [1.089842438697815, 0.46875]\n",
      "Epoch: 1882 , Loss: [1.0393261909484863, 0.5]\n",
      "Epoch: 1883 , Loss: [0.9974144101142883, 0.515625]\n",
      "Epoch: 1884 , Loss: [1.0012187957763672, 0.546875]\n",
      "Epoch: 1885 , Loss: [1.004267692565918, 0.546875]\n",
      "Epoch: 1886 , Loss: [0.9930589199066162, 0.578125]\n",
      "Epoch: 1887 , Loss: [1.0211974382400513, 0.5]\n",
      "Epoch: 1888 , Loss: [1.0658910274505615, 0.453125]\n",
      "Epoch: 1889 , Loss: [1.0420727729797363, 0.5625]\n",
      "Epoch: 1890 , Loss: [1.0670416355133057, 0.375]\n",
      "Epoch: 1891 , Loss: [1.0123257637023926, 0.453125]\n",
      "Epoch: 1892 , Loss: [1.0554168224334717, 0.46875]\n",
      "Epoch: 1893 , Loss: [1.131032109260559, 0.4375]\n",
      "Epoch: 1894 , Loss: [0.9976034760475159, 0.546875]\n",
      "Epoch: 1895 , Loss: [1.0047305822372437, 0.59375]\n",
      "Epoch: 1896 , Loss: [1.05824875831604, 0.515625]\n",
      "Epoch: 1897 , Loss: [0.9877543449401855, 0.53125]\n",
      "Epoch: 1898 , Loss: [1.0361615419387817, 0.484375]\n",
      "Epoch: 1899 , Loss: [0.9971736073493958, 0.515625]\n",
      "Epoch: 1900 , Loss: [1.0050910711288452, 0.484375]\n",
      "Epoch: 1901 , Loss: [1.073378324508667, 0.484375]\n",
      "Epoch: 1902 , Loss: [1.0647071599960327, 0.453125]\n",
      "Epoch: 1903 , Loss: [1.0439765453338623, 0.46875]\n",
      "Epoch: 1904 , Loss: [1.0548255443572998, 0.40625]\n",
      "Epoch: 1905 , Loss: [0.9936419129371643, 0.59375]\n",
      "Epoch: 1906 , Loss: [1.0266330242156982, 0.5625]\n",
      "Epoch: 1907 , Loss: [1.0216519832611084, 0.578125]\n",
      "Epoch: 1908 , Loss: [1.0376371145248413, 0.4375]\n",
      "Epoch: 1909 , Loss: [1.0229671001434326, 0.5625]\n",
      "Epoch: 1910 , Loss: [1.076263666152954, 0.515625]\n",
      "Epoch: 1911 , Loss: [0.9677090644836426, 0.625]\n",
      "Epoch: 1912 , Loss: [1.0222386121749878, 0.546875]\n",
      "Epoch: 1913 , Loss: [1.0328974723815918, 0.484375]\n",
      "Epoch: 1914 , Loss: [1.0838327407836914, 0.390625]\n",
      "Epoch: 1915 , Loss: [1.0697463750839233, 0.46875]\n",
      "Epoch: 1916 , Loss: [1.012888789176941, 0.421875]\n",
      "Epoch: 1917 , Loss: [0.9899656772613525, 0.5625]\n",
      "Epoch: 1918 , Loss: [0.9556959867477417, 0.640625]\n",
      "Epoch: 1919 , Loss: [1.0236865282058716, 0.546875]\n",
      "Epoch: 1920 , Loss: [1.0798699855804443, 0.421875]\n",
      "Epoch: 1921 , Loss: [1.0679576396942139, 0.46875]\n",
      "Epoch: 1922 , Loss: [1.0898958444595337, 0.484375]\n",
      "Epoch: 1923 , Loss: [1.0016217231750488, 0.578125]\n",
      "Epoch: 1924 , Loss: [1.0149502754211426, 0.5625]\n",
      "Epoch: 1925 , Loss: [1.0137354135513306, 0.5]\n",
      "Epoch: 1926 , Loss: [1.0285921096801758, 0.5]\n",
      "Epoch: 1927 , Loss: [1.0058447122573853, 0.53125]\n",
      "Epoch: 1928 , Loss: [1.1051983833312988, 0.390625]\n",
      "Epoch: 1929 , Loss: [0.9991415739059448, 0.5625]\n",
      "Epoch: 1930 , Loss: [1.0319799184799194, 0.5]\n",
      "Epoch: 1931 , Loss: [0.9721072316169739, 0.5625]\n",
      "Epoch: 1932 , Loss: [1.007765531539917, 0.5625]\n",
      "Epoch: 1933 , Loss: [0.9653857946395874, 0.578125]\n",
      "Epoch: 1934 , Loss: [0.9295816421508789, 0.625]\n",
      "Epoch: 1935 , Loss: [1.0339105129241943, 0.46875]\n",
      "Epoch: 1936 , Loss: [0.9887335300445557, 0.546875]\n",
      "Epoch: 1937 , Loss: [1.0427523851394653, 0.484375]\n",
      "Epoch: 1938 , Loss: [0.9951524138450623, 0.578125]\n",
      "Epoch: 1939 , Loss: [0.9488057494163513, 0.625]\n",
      "Epoch: 1940 , Loss: [1.0262342691421509, 0.546875]\n",
      "Epoch: 1941 , Loss: [1.0501294136047363, 0.515625]\n",
      "Epoch: 1942 , Loss: [0.9591515064239502, 0.6875]\n",
      "Epoch: 1943 , Loss: [1.066880702972412, 0.46875]\n",
      "Epoch: 1944 , Loss: [0.9454569220542908, 0.59375]\n",
      "Epoch: 1945 , Loss: [0.9979051947593689, 0.484375]\n",
      "Epoch: 1946 , Loss: [1.0347609519958496, 0.53125]\n",
      "Epoch: 1947 , Loss: [1.0021581649780273, 0.53125]\n",
      "Epoch: 1948 , Loss: [0.9617708325386047, 0.5]\n",
      "Epoch: 1949 , Loss: [0.9892076849937439, 0.53125]\n",
      "Epoch: 1950 , Loss: [1.0180068016052246, 0.4375]\n",
      "Epoch: 1951 , Loss: [1.0283875465393066, 0.484375]\n",
      "Epoch: 1952 , Loss: [1.043795108795166, 0.40625]\n",
      "Epoch: 1953 , Loss: [1.0540235042572021, 0.5]\n",
      "Epoch: 1954 , Loss: [1.0160030126571655, 0.484375]\n",
      "Epoch: 1955 , Loss: [1.0120463371276855, 0.453125]\n",
      "Epoch: 1956 , Loss: [1.0498236417770386, 0.515625]\n",
      "Epoch: 1957 , Loss: [1.0022337436676025, 0.53125]\n",
      "Epoch: 1958 , Loss: [1.0017802715301514, 0.53125]\n",
      "Epoch: 1959 , Loss: [1.0278772115707397, 0.5]\n",
      "Epoch: 1960 , Loss: [1.003397822380066, 0.46875]\n",
      "Epoch: 1961 , Loss: [1.0645558834075928, 0.40625]\n",
      "Epoch: 1962 , Loss: [0.9638157486915588, 0.578125]\n",
      "Epoch: 1963 , Loss: [1.0077533721923828, 0.515625]\n",
      "Epoch: 1964 , Loss: [1.0201565027236938, 0.53125]\n",
      "Epoch: 1965 , Loss: [1.0303093194961548, 0.484375]\n",
      "Epoch: 1966 , Loss: [1.0042885541915894, 0.53125]\n",
      "Epoch: 1967 , Loss: [1.0136674642562866, 0.484375]\n",
      "Epoch: 1968 , Loss: [1.0010781288146973, 0.453125]\n",
      "Epoch: 1969 , Loss: [0.9818480014801025, 0.578125]\n",
      "Epoch: 1970 , Loss: [1.0061087608337402, 0.46875]\n",
      "Epoch: 1971 , Loss: [1.1234999895095825, 0.34375]\n",
      "Epoch: 1972 , Loss: [1.001237154006958, 0.546875]\n",
      "Epoch: 1973 , Loss: [1.0713460445404053, 0.390625]\n",
      "Epoch: 1974 , Loss: [1.0299928188323975, 0.453125]\n",
      "Epoch: 1975 , Loss: [0.9887480139732361, 0.53125]\n",
      "Epoch: 1976 , Loss: [1.0183569192886353, 0.421875]\n",
      "Epoch: 1977 , Loss: [1.0344202518463135, 0.5]\n",
      "Epoch: 1978 , Loss: [1.0025620460510254, 0.5]\n",
      "Epoch: 1979 , Loss: [0.9816625714302063, 0.5]\n",
      "Epoch: 1980 , Loss: [1.079473614692688, 0.390625]\n",
      "Epoch: 1981 , Loss: [1.055109977722168, 0.5]\n",
      "Epoch: 1982 , Loss: [0.9677658081054688, 0.546875]\n",
      "Epoch: 1983 , Loss: [1.004730463027954, 0.578125]\n",
      "Epoch: 1984 , Loss: [0.9574741721153259, 0.546875]\n",
      "Epoch: 1985 , Loss: [1.0131902694702148, 0.5]\n",
      "Epoch: 1986 , Loss: [1.0588080883026123, 0.421875]\n",
      "Epoch: 1987 , Loss: [0.9972535371780396, 0.546875]\n",
      "Epoch: 1988 , Loss: [1.0110106468200684, 0.40625]\n",
      "Epoch: 1989 , Loss: [1.0289523601531982, 0.453125]\n",
      "Epoch: 1990 , Loss: [0.974345862865448, 0.59375]\n",
      "Epoch: 1991 , Loss: [1.0088555812835693, 0.515625]\n",
      "Epoch: 1992 , Loss: [0.9920668601989746, 0.5]\n",
      "Epoch: 1993 , Loss: [1.0129332542419434, 0.484375]\n",
      "Epoch: 1994 , Loss: [0.9997051954269409, 0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1995 , Loss: [1.0268888473510742, 0.375]\n",
      "Epoch: 1996 , Loss: [1.042414903640747, 0.484375]\n",
      "Epoch: 1997 , Loss: [1.0004746913909912, 0.515625]\n",
      "Epoch: 1998 , Loss: [1.0026593208312988, 0.515625]\n",
      "Epoch: 1999 , Loss: [0.9854266047477722, 0.515625]\n",
      "Epoch: 2000 , Loss: [0.9443768858909607, 0.546875]\n",
      "=============================================\n",
      "2 correctly classified among 64\n",
      "Accuracy as of 2000 epochs: 3.125\n",
      "=============================================\n",
      "Epoch: 2001 , Loss: [1.089223027229309, 0.375]\n",
      "Epoch: 2002 , Loss: [1.0374994277954102, 0.4375]\n",
      "Epoch: 2003 , Loss: [0.9686663150787354, 0.453125]\n",
      "Epoch: 2004 , Loss: [1.0056146383285522, 0.53125]\n",
      "Epoch: 2005 , Loss: [0.9767570495605469, 0.53125]\n",
      "Epoch: 2006 , Loss: [0.9409369230270386, 0.5625]\n",
      "Epoch: 2007 , Loss: [0.9904909133911133, 0.5]\n",
      "Epoch: 2008 , Loss: [1.0907008647918701, 0.375]\n",
      "Epoch: 2009 , Loss: [1.0515109300613403, 0.34375]\n",
      "Epoch: 2010 , Loss: [1.0089290142059326, 0.515625]\n",
      "Epoch: 2011 , Loss: [1.0217779874801636, 0.5]\n",
      "Epoch: 2012 , Loss: [0.9381551146507263, 0.5625]\n",
      "Epoch: 2013 , Loss: [0.9833866357803345, 0.515625]\n",
      "Epoch: 2014 , Loss: [1.0151679515838623, 0.34375]\n",
      "Epoch: 2015 , Loss: [1.0260722637176514, 0.46875]\n",
      "Epoch: 2016 , Loss: [0.9871476888656616, 0.453125]\n",
      "Epoch: 2017 , Loss: [0.9594830870628357, 0.515625]\n",
      "Epoch: 2018 , Loss: [1.0165797472000122, 0.46875]\n",
      "Epoch: 2019 , Loss: [0.9844245910644531, 0.5]\n",
      "Epoch: 2020 , Loss: [1.0150474309921265, 0.4375]\n",
      "Epoch: 2021 , Loss: [1.0519030094146729, 0.46875]\n",
      "Epoch: 2022 , Loss: [1.0160272121429443, 0.453125]\n",
      "Epoch: 2023 , Loss: [1.0047662258148193, 0.4375]\n",
      "Epoch: 2024 , Loss: [0.9992027282714844, 0.484375]\n",
      "Epoch: 2025 , Loss: [0.9147434830665588, 0.6875]\n",
      "Epoch: 2026 , Loss: [0.9478587508201599, 0.53125]\n",
      "Epoch: 2027 , Loss: [1.0164226293563843, 0.453125]\n",
      "Epoch: 2028 , Loss: [0.9436138868331909, 0.546875]\n",
      "Epoch: 2029 , Loss: [0.9679673910140991, 0.5625]\n",
      "Epoch: 2030 , Loss: [1.0208439826965332, 0.4375]\n",
      "Epoch: 2031 , Loss: [0.9793156385421753, 0.484375]\n",
      "Epoch: 2032 , Loss: [0.967595100402832, 0.515625]\n",
      "Epoch: 2033 , Loss: [0.9717319011688232, 0.453125]\n",
      "Epoch: 2034 , Loss: [0.9009719491004944, 0.609375]\n",
      "Epoch: 2035 , Loss: [0.9929486513137817, 0.515625]\n",
      "Epoch: 2036 , Loss: [0.9801250100135803, 0.453125]\n",
      "Epoch: 2037 , Loss: [0.9487943649291992, 0.53125]\n",
      "Epoch: 2038 , Loss: [1.0355104207992554, 0.5]\n",
      "Epoch: 2039 , Loss: [0.9694045782089233, 0.515625]\n",
      "Epoch: 2040 , Loss: [0.9146313071250916, 0.609375]\n",
      "Epoch: 2041 , Loss: [0.9740142822265625, 0.546875]\n",
      "Epoch: 2042 , Loss: [1.0047533512115479, 0.5]\n",
      "Epoch: 2043 , Loss: [1.0272271633148193, 0.421875]\n",
      "Epoch: 2044 , Loss: [1.0531277656555176, 0.390625]\n",
      "Epoch: 2045 , Loss: [0.9796196222305298, 0.53125]\n",
      "Epoch: 2046 , Loss: [0.9464007019996643, 0.5]\n",
      "Epoch: 2047 , Loss: [0.9340918660163879, 0.5625]\n",
      "Epoch: 2048 , Loss: [0.9840177297592163, 0.53125]\n",
      "Epoch: 2049 , Loss: [0.9357465505599976, 0.546875]\n",
      "Epoch: 2050 , Loss: [0.9650664329528809, 0.484375]\n",
      "Epoch: 2051 , Loss: [0.9435718059539795, 0.515625]\n",
      "Epoch: 2052 , Loss: [0.9804269075393677, 0.453125]\n",
      "Epoch: 2053 , Loss: [0.9096295833587646, 0.65625]\n",
      "Epoch: 2054 , Loss: [0.9935035109519958, 0.421875]\n",
      "Epoch: 2055 , Loss: [0.9937398433685303, 0.5]\n",
      "Epoch: 2056 , Loss: [0.9761089086532593, 0.5]\n",
      "Epoch: 2057 , Loss: [0.980193555355072, 0.5]\n",
      "Epoch: 2058 , Loss: [0.9400566220283508, 0.5625]\n",
      "Epoch: 2059 , Loss: [0.9580352902412415, 0.53125]\n",
      "Epoch: 2060 , Loss: [0.955028235912323, 0.484375]\n",
      "Epoch: 2061 , Loss: [0.8918024301528931, 0.59375]\n",
      "Epoch: 2062 , Loss: [0.950849175453186, 0.53125]\n",
      "Epoch: 2063 , Loss: [0.9377289414405823, 0.53125]\n",
      "Epoch: 2064 , Loss: [0.9170375466346741, 0.640625]\n",
      "Epoch: 2065 , Loss: [0.9583008289337158, 0.5]\n",
      "Epoch: 2066 , Loss: [0.9232153296470642, 0.578125]\n",
      "Epoch: 2067 , Loss: [0.9520461559295654, 0.546875]\n",
      "Epoch: 2068 , Loss: [0.9739792346954346, 0.4375]\n",
      "Epoch: 2069 , Loss: [0.9736389517784119, 0.515625]\n",
      "Epoch: 2070 , Loss: [0.8861535787582397, 0.609375]\n",
      "Epoch: 2071 , Loss: [0.955988883972168, 0.5625]\n",
      "Epoch: 2072 , Loss: [1.0454983711242676, 0.46875]\n",
      "Epoch: 2073 , Loss: [0.921540379524231, 0.640625]\n",
      "Epoch: 2074 , Loss: [1.0725234746932983, 0.421875]\n",
      "Epoch: 2075 , Loss: [1.024231195449829, 0.515625]\n",
      "Epoch: 2076 , Loss: [0.9984518885612488, 0.46875]\n",
      "Epoch: 2077 , Loss: [1.0250604152679443, 0.34375]\n",
      "Epoch: 2078 , Loss: [0.9674109220504761, 0.546875]\n",
      "Epoch: 2079 , Loss: [1.0229055881500244, 0.4375]\n",
      "Epoch: 2080 , Loss: [1.0156750679016113, 0.53125]\n",
      "Epoch: 2081 , Loss: [1.0439485311508179, 0.375]\n",
      "Epoch: 2082 , Loss: [1.0005066394805908, 0.421875]\n",
      "Epoch: 2083 , Loss: [0.9542775750160217, 0.5]\n",
      "Epoch: 2084 , Loss: [0.9439324140548706, 0.515625]\n",
      "Epoch: 2085 , Loss: [0.9362886548042297, 0.578125]\n",
      "Epoch: 2086 , Loss: [0.9916097521781921, 0.4375]\n",
      "Epoch: 2087 , Loss: [0.9644055962562561, 0.53125]\n",
      "Epoch: 2088 , Loss: [0.9415899515151978, 0.546875]\n",
      "Epoch: 2089 , Loss: [0.8891568183898926, 0.640625]\n",
      "Epoch: 2090 , Loss: [0.8936681747436523, 0.640625]\n",
      "Epoch: 2091 , Loss: [0.9655168056488037, 0.4375]\n",
      "Epoch: 2092 , Loss: [0.9418076276779175, 0.546875]\n",
      "Epoch: 2093 , Loss: [0.9691669940948486, 0.515625]\n",
      "Epoch: 2094 , Loss: [0.9942740201950073, 0.453125]\n",
      "Epoch: 2095 , Loss: [1.021440029144287, 0.515625]\n",
      "Epoch: 2096 , Loss: [0.9480831623077393, 0.4375]\n",
      "Epoch: 2097 , Loss: [0.9555220603942871, 0.546875]\n",
      "Epoch: 2098 , Loss: [0.9666833877563477, 0.515625]\n",
      "Epoch: 2099 , Loss: [0.9115850925445557, 0.625]\n",
      "Epoch: 2100 , Loss: [0.9508817791938782, 0.515625]\n",
      "Epoch: 2101 , Loss: [0.9393669962882996, 0.53125]\n",
      "Epoch: 2102 , Loss: [0.9316881895065308, 0.59375]\n",
      "Epoch: 2103 , Loss: [0.971833348274231, 0.5]\n",
      "Epoch: 2104 , Loss: [0.9799134731292725, 0.59375]\n",
      "Epoch: 2105 , Loss: [0.9726732969284058, 0.578125]\n",
      "Epoch: 2106 , Loss: [0.9813032150268555, 0.515625]\n",
      "Epoch: 2107 , Loss: [1.012317180633545, 0.421875]\n",
      "Epoch: 2108 , Loss: [0.9798577427864075, 0.5]\n",
      "Epoch: 2109 , Loss: [1.0008840560913086, 0.375]\n",
      "Epoch: 2110 , Loss: [0.9968447089195251, 0.546875]\n",
      "Epoch: 2111 , Loss: [0.9766245484352112, 0.453125]\n",
      "Epoch: 2112 , Loss: [0.997991144657135, 0.390625]\n",
      "Epoch: 2113 , Loss: [0.9899976849555969, 0.515625]\n",
      "Epoch: 2114 , Loss: [0.9552637338638306, 0.515625]\n",
      "Epoch: 2115 , Loss: [0.9970120191574097, 0.515625]\n",
      "Epoch: 2116 , Loss: [1.019860029220581, 0.484375]\n",
      "Epoch: 2117 , Loss: [0.9711983799934387, 0.484375]\n",
      "Epoch: 2118 , Loss: [0.9599313735961914, 0.515625]\n",
      "Epoch: 2119 , Loss: [0.9530980587005615, 0.515625]\n",
      "Epoch: 2120 , Loss: [0.9712105989456177, 0.546875]\n",
      "Epoch: 2121 , Loss: [0.9726600050926208, 0.546875]\n",
      "Epoch: 2122 , Loss: [0.9438422918319702, 0.546875]\n",
      "Epoch: 2123 , Loss: [1.0189512968063354, 0.421875]\n",
      "Epoch: 2124 , Loss: [0.9719582796096802, 0.484375]\n",
      "Epoch: 2125 , Loss: [0.9845829606056213, 0.546875]\n",
      "Epoch: 2126 , Loss: [0.9629814624786377, 0.515625]\n",
      "Epoch: 2127 , Loss: [1.0451327562332153, 0.515625]\n",
      "Epoch: 2128 , Loss: [0.9399656057357788, 0.59375]\n",
      "Epoch: 2129 , Loss: [0.9340392351150513, 0.609375]\n",
      "Epoch: 2130 , Loss: [0.9901578426361084, 0.53125]\n",
      "Epoch: 2131 , Loss: [0.9417197704315186, 0.640625]\n",
      "Epoch: 2132 , Loss: [1.009056806564331, 0.484375]\n",
      "Epoch: 2133 , Loss: [0.9953293204307556, 0.359375]\n",
      "Epoch: 2134 , Loss: [0.9058603644371033, 0.5625]\n",
      "Epoch: 2135 , Loss: [0.9572923183441162, 0.578125]\n",
      "Epoch: 2136 , Loss: [0.9903459548950195, 0.484375]\n",
      "Epoch: 2137 , Loss: [0.948135495185852, 0.53125]\n",
      "Epoch: 2138 , Loss: [1.055845022201538, 0.390625]\n",
      "Epoch: 2139 , Loss: [0.980487585067749, 0.5]\n",
      "Epoch: 2140 , Loss: [0.9693255424499512, 0.53125]\n",
      "Epoch: 2141 , Loss: [0.962959885597229, 0.59375]\n",
      "Epoch: 2142 , Loss: [0.9948724508285522, 0.484375]\n",
      "Epoch: 2143 , Loss: [1.0152602195739746, 0.515625]\n",
      "Epoch: 2144 , Loss: [0.9707373380661011, 0.484375]\n",
      "Epoch: 2145 , Loss: [0.9497272968292236, 0.53125]\n",
      "Epoch: 2146 , Loss: [0.9556650519371033, 0.5]\n",
      "Epoch: 2147 , Loss: [0.9544687867164612, 0.65625]\n",
      "Epoch: 2148 , Loss: [1.0251435041427612, 0.453125]\n",
      "Epoch: 2149 , Loss: [0.9673667550086975, 0.53125]\n",
      "Epoch: 2150 , Loss: [0.9596354961395264, 0.53125]\n",
      "Epoch: 2151 , Loss: [0.9419514536857605, 0.5]\n",
      "Epoch: 2152 , Loss: [1.0609570741653442, 0.34375]\n",
      "Epoch: 2153 , Loss: [1.0142948627471924, 0.46875]\n",
      "Epoch: 2154 , Loss: [0.9422836303710938, 0.515625]\n",
      "Epoch: 2155 , Loss: [0.9942041039466858, 0.5]\n",
      "Epoch: 2156 , Loss: [0.9374743103981018, 0.421875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2157 , Loss: [1.0289047956466675, 0.390625]\n",
      "Epoch: 2158 , Loss: [0.9343730211257935, 0.484375]\n",
      "Epoch: 2159 , Loss: [0.9534450173377991, 0.515625]\n",
      "Epoch: 2160 , Loss: [0.897173285484314, 0.484375]\n",
      "Epoch: 2161 , Loss: [1.0103468894958496, 0.453125]\n",
      "Epoch: 2162 , Loss: [0.9708115458488464, 0.515625]\n",
      "Epoch: 2163 , Loss: [0.965408444404602, 0.4375]\n",
      "Epoch: 2164 , Loss: [1.0375455617904663, 0.4375]\n",
      "Epoch: 2165 , Loss: [0.9753469228744507, 0.4375]\n",
      "Epoch: 2166 , Loss: [0.9143958687782288, 0.546875]\n",
      "Epoch: 2167 , Loss: [1.0065100193023682, 0.46875]\n",
      "Epoch: 2168 , Loss: [0.9857486486434937, 0.4375]\n",
      "Epoch: 2169 , Loss: [0.9795373678207397, 0.53125]\n",
      "Epoch: 2170 , Loss: [0.9857946634292603, 0.453125]\n",
      "Epoch: 2171 , Loss: [0.9861873388290405, 0.484375]\n",
      "Epoch: 2172 , Loss: [0.9027059674263, 0.546875]\n",
      "Epoch: 2173 , Loss: [1.0232596397399902, 0.4375]\n",
      "Epoch: 2174 , Loss: [1.0110664367675781, 0.4375]\n",
      "Epoch: 2175 , Loss: [0.917251706123352, 0.59375]\n",
      "Epoch: 2176 , Loss: [0.9762202501296997, 0.5]\n",
      "Epoch: 2177 , Loss: [0.9235787987709045, 0.515625]\n",
      "Epoch: 2178 , Loss: [1.0285696983337402, 0.5]\n",
      "Epoch: 2179 , Loss: [1.0088831186294556, 0.484375]\n",
      "Epoch: 2180 , Loss: [0.9967995882034302, 0.421875]\n",
      "Epoch: 2181 , Loss: [0.9272289276123047, 0.484375]\n",
      "Epoch: 2182 , Loss: [0.979741632938385, 0.4375]\n",
      "Epoch: 2183 , Loss: [0.9966568946838379, 0.453125]\n",
      "Epoch: 2184 , Loss: [0.9797725677490234, 0.578125]\n",
      "Epoch: 2185 , Loss: [0.9267026782035828, 0.59375]\n",
      "Epoch: 2186 , Loss: [0.9546259045600891, 0.5]\n",
      "Epoch: 2187 , Loss: [0.9221243262290955, 0.5]\n",
      "Epoch: 2188 , Loss: [0.9315160512924194, 0.59375]\n",
      "Epoch: 2189 , Loss: [0.9280224442481995, 0.53125]\n",
      "Epoch: 2190 , Loss: [0.92438805103302, 0.515625]\n",
      "Epoch: 2191 , Loss: [0.9742656946182251, 0.484375]\n",
      "Epoch: 2192 , Loss: [0.9278708100318909, 0.5]\n",
      "Epoch: 2193 , Loss: [1.0170258283615112, 0.4375]\n",
      "Epoch: 2194 , Loss: [0.9764032959938049, 0.515625]\n",
      "Epoch: 2195 , Loss: [0.9412195086479187, 0.515625]\n",
      "Epoch: 2196 , Loss: [0.9825154542922974, 0.53125]\n",
      "Epoch: 2197 , Loss: [0.9352654218673706, 0.5]\n",
      "Epoch: 2198 , Loss: [0.9629628658294678, 0.53125]\n",
      "Epoch: 2199 , Loss: [1.0024224519729614, 0.4375]\n",
      "Epoch: 2200 , Loss: [0.9253796935081482, 0.546875]\n",
      "Epoch: 2201 , Loss: [0.9526511430740356, 0.53125]\n",
      "Epoch: 2202 , Loss: [0.961509108543396, 0.4375]\n",
      "Epoch: 2203 , Loss: [1.0325950384140015, 0.390625]\n",
      "Epoch: 2204 , Loss: [0.9481872320175171, 0.546875]\n",
      "Epoch: 2205 , Loss: [0.9240671396255493, 0.5]\n",
      "Epoch: 2206 , Loss: [0.9646868705749512, 0.515625]\n",
      "Epoch: 2207 , Loss: [0.9168999195098877, 0.546875]\n",
      "Epoch: 2208 , Loss: [0.9741668701171875, 0.609375]\n",
      "Epoch: 2209 , Loss: [0.9726688265800476, 0.515625]\n",
      "Epoch: 2210 , Loss: [0.9700394868850708, 0.484375]\n",
      "Epoch: 2211 , Loss: [0.9427937269210815, 0.46875]\n",
      "Epoch: 2212 , Loss: [0.9864311814308167, 0.46875]\n",
      "Epoch: 2213 , Loss: [0.9724136590957642, 0.484375]\n",
      "Epoch: 2214 , Loss: [0.9510403871536255, 0.578125]\n",
      "Epoch: 2215 , Loss: [0.9644507169723511, 0.390625]\n",
      "Epoch: 2216 , Loss: [0.995915412902832, 0.375]\n",
      "Epoch: 2217 , Loss: [0.9700412154197693, 0.46875]\n",
      "Epoch: 2218 , Loss: [0.9614534378051758, 0.390625]\n",
      "Epoch: 2219 , Loss: [0.9461202025413513, 0.484375]\n",
      "Epoch: 2220 , Loss: [0.9153377413749695, 0.625]\n",
      "Epoch: 2221 , Loss: [0.9806222915649414, 0.375]\n",
      "Epoch: 2222 , Loss: [0.9912474751472473, 0.40625]\n",
      "Epoch: 2223 , Loss: [0.976826548576355, 0.4375]\n",
      "Epoch: 2224 , Loss: [0.9769449830055237, 0.5]\n",
      "Epoch: 2225 , Loss: [0.9572649002075195, 0.515625]\n",
      "Epoch: 2226 , Loss: [0.9627857208251953, 0.453125]\n",
      "Epoch: 2227 , Loss: [0.9635218381881714, 0.484375]\n",
      "Epoch: 2228 , Loss: [0.9973704814910889, 0.453125]\n",
      "Epoch: 2229 , Loss: [0.8992959856987, 0.578125]\n",
      "Epoch: 2230 , Loss: [0.9832260012626648, 0.375]\n",
      "Epoch: 2231 , Loss: [0.9433668851852417, 0.484375]\n",
      "Epoch: 2232 , Loss: [0.9353018999099731, 0.53125]\n",
      "Epoch: 2233 , Loss: [0.9256175756454468, 0.609375]\n",
      "Epoch: 2234 , Loss: [0.9478734731674194, 0.5625]\n",
      "Epoch: 2235 , Loss: [0.9487254619598389, 0.40625]\n",
      "Epoch: 2236 , Loss: [0.9320359230041504, 0.5625]\n",
      "Epoch: 2237 , Loss: [0.9383906126022339, 0.46875]\n",
      "Epoch: 2238 , Loss: [0.8773984909057617, 0.625]\n",
      "Epoch: 2239 , Loss: [0.9914872646331787, 0.515625]\n",
      "Epoch: 2240 , Loss: [0.8903661966323853, 0.578125]\n",
      "Epoch: 2241 , Loss: [0.9511132836341858, 0.46875]\n",
      "Epoch: 2242 , Loss: [0.9647189974784851, 0.484375]\n",
      "Epoch: 2243 , Loss: [1.0162444114685059, 0.4375]\n",
      "Epoch: 2244 , Loss: [0.9167662858963013, 0.5]\n",
      "Epoch: 2245 , Loss: [1.0061187744140625, 0.40625]\n",
      "Epoch: 2246 , Loss: [0.9142944812774658, 0.53125]\n",
      "Epoch: 2247 , Loss: [1.008976697921753, 0.390625]\n",
      "Epoch: 2248 , Loss: [0.8955603837966919, 0.546875]\n",
      "Epoch: 2249 , Loss: [0.9510892033576965, 0.453125]\n",
      "Epoch: 2250 , Loss: [0.9747292399406433, 0.453125]\n",
      "=============================================\n",
      "3 correctly classified among 64\n",
      "Accuracy as of 2250 epochs: 4.6875\n",
      "=============================================\n",
      "Epoch: 2251 , Loss: [0.9470847845077515, 0.640625]\n",
      "Epoch: 2252 , Loss: [1.0619179010391235, 0.359375]\n",
      "Epoch: 2253 , Loss: [1.0208313465118408, 0.453125]\n",
      "Epoch: 2254 , Loss: [0.9993171691894531, 0.421875]\n",
      "Epoch: 2255 , Loss: [0.9375560283660889, 0.421875]\n",
      "Epoch: 2256 , Loss: [0.9692142605781555, 0.453125]\n",
      "Epoch: 2257 , Loss: [0.9300872087478638, 0.546875]\n",
      "Epoch: 2258 , Loss: [1.0028973817825317, 0.40625]\n",
      "Epoch: 2259 , Loss: [0.9418234825134277, 0.59375]\n",
      "Epoch: 2260 , Loss: [0.9187183380126953, 0.59375]\n",
      "Epoch: 2261 , Loss: [0.9522784948348999, 0.484375]\n",
      "Epoch: 2262 , Loss: [0.9620347023010254, 0.484375]\n",
      "Epoch: 2263 , Loss: [0.9737749695777893, 0.484375]\n",
      "Epoch: 2264 , Loss: [0.9408454298973083, 0.515625]\n",
      "Epoch: 2265 , Loss: [0.9644908905029297, 0.5]\n",
      "Epoch: 2266 , Loss: [0.9952377080917358, 0.359375]\n",
      "Epoch: 2267 , Loss: [0.9214597940444946, 0.546875]\n",
      "Epoch: 2268 , Loss: [0.9080848097801208, 0.453125]\n",
      "Epoch: 2269 , Loss: [0.9050459861755371, 0.578125]\n",
      "Epoch: 2270 , Loss: [0.9110718965530396, 0.53125]\n",
      "Epoch: 2271 , Loss: [0.9452953338623047, 0.421875]\n",
      "Epoch: 2272 , Loss: [0.9178815484046936, 0.515625]\n",
      "Epoch: 2273 , Loss: [0.9353597164154053, 0.421875]\n",
      "Epoch: 2274 , Loss: [0.9318253397941589, 0.53125]\n",
      "Epoch: 2275 , Loss: [0.9152517318725586, 0.546875]\n",
      "Epoch: 2276 , Loss: [0.9193482995033264, 0.53125]\n",
      "Epoch: 2277 , Loss: [1.0239152908325195, 0.34375]\n",
      "Epoch: 2278 , Loss: [0.9162644743919373, 0.546875]\n",
      "Epoch: 2279 , Loss: [0.9527753591537476, 0.484375]\n",
      "Epoch: 2280 , Loss: [0.9128208160400391, 0.515625]\n",
      "Epoch: 2281 , Loss: [0.9696030020713806, 0.4375]\n",
      "Epoch: 2282 , Loss: [0.933411717414856, 0.40625]\n",
      "Epoch: 2283 , Loss: [0.8959081172943115, 0.546875]\n",
      "Epoch: 2284 , Loss: [0.9020158052444458, 0.53125]\n",
      "Epoch: 2285 , Loss: [0.8621547222137451, 0.609375]\n",
      "Epoch: 2286 , Loss: [1.0018689632415771, 0.4375]\n",
      "Epoch: 2287 , Loss: [0.9437716007232666, 0.484375]\n",
      "Epoch: 2288 , Loss: [0.9715954661369324, 0.5]\n",
      "Epoch: 2289 , Loss: [1.0003795623779297, 0.359375]\n",
      "Epoch: 2290 , Loss: [0.9609133005142212, 0.4375]\n",
      "Epoch: 2291 , Loss: [0.9858049750328064, 0.546875]\n",
      "Epoch: 2292 , Loss: [0.924299955368042, 0.453125]\n",
      "Epoch: 2293 , Loss: [0.9586291909217834, 0.453125]\n",
      "Epoch: 2294 , Loss: [0.9543168544769287, 0.5]\n",
      "Epoch: 2295 , Loss: [0.9113672375679016, 0.546875]\n",
      "Epoch: 2296 , Loss: [0.8939549922943115, 0.59375]\n",
      "Epoch: 2297 , Loss: [0.9433658123016357, 0.5]\n",
      "Epoch: 2298 , Loss: [1.0605707168579102, 0.359375]\n",
      "Epoch: 2299 , Loss: [0.9212620854377747, 0.546875]\n",
      "Epoch: 2300 , Loss: [0.9380228519439697, 0.484375]\n",
      "Epoch: 2301 , Loss: [0.9314860105514526, 0.515625]\n",
      "Epoch: 2302 , Loss: [0.96576327085495, 0.46875]\n",
      "Epoch: 2303 , Loss: [0.9457435607910156, 0.46875]\n",
      "Epoch: 2304 , Loss: [0.874302089214325, 0.59375]\n",
      "Epoch: 2305 , Loss: [0.9205783009529114, 0.5]\n",
      "Epoch: 2306 , Loss: [0.9060974717140198, 0.5625]\n",
      "Epoch: 2307 , Loss: [0.9345018863677979, 0.53125]\n",
      "Epoch: 2308 , Loss: [0.9397352337837219, 0.484375]\n",
      "Epoch: 2309 , Loss: [0.9311531186103821, 0.4375]\n",
      "Epoch: 2310 , Loss: [0.9792495965957642, 0.484375]\n",
      "Epoch: 2311 , Loss: [0.8994412422180176, 0.53125]\n",
      "Epoch: 2312 , Loss: [0.9246928691864014, 0.453125]\n",
      "Epoch: 2313 , Loss: [0.9547368288040161, 0.4375]\n",
      "Epoch: 2314 , Loss: [0.8642610311508179, 0.546875]\n",
      "Epoch: 2315 , Loss: [0.8965767621994019, 0.609375]\n",
      "Epoch: 2316 , Loss: [0.9201820492744446, 0.5]\n",
      "Epoch: 2317 , Loss: [0.9550777673721313, 0.4375]\n",
      "Epoch: 2318 , Loss: [0.908638060092926, 0.515625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2319 , Loss: [0.9833595156669617, 0.390625]\n",
      "Epoch: 2320 , Loss: [0.8779541254043579, 0.625]\n",
      "Epoch: 2321 , Loss: [0.9458868503570557, 0.578125]\n",
      "Epoch: 2322 , Loss: [0.9439992308616638, 0.515625]\n",
      "Epoch: 2323 , Loss: [0.9205108880996704, 0.546875]\n",
      "Epoch: 2324 , Loss: [0.9221033453941345, 0.53125]\n",
      "Epoch: 2325 , Loss: [0.9410421848297119, 0.515625]\n",
      "Epoch: 2326 , Loss: [0.9285097122192383, 0.515625]\n",
      "Epoch: 2327 , Loss: [0.9952677488327026, 0.453125]\n",
      "Epoch: 2328 , Loss: [0.8839461803436279, 0.5625]\n",
      "Epoch: 2329 , Loss: [0.9230992794036865, 0.515625]\n",
      "Epoch: 2330 , Loss: [0.8763535022735596, 0.578125]\n",
      "Epoch: 2331 , Loss: [0.9264439344406128, 0.515625]\n",
      "Epoch: 2332 , Loss: [0.958367109298706, 0.453125]\n",
      "Epoch: 2333 , Loss: [0.9409526586532593, 0.453125]\n",
      "Epoch: 2334 , Loss: [0.9579318165779114, 0.421875]\n",
      "Epoch: 2335 , Loss: [0.8899752497673035, 0.578125]\n",
      "Epoch: 2336 , Loss: [0.8560569286346436, 0.640625]\n",
      "Epoch: 2337 , Loss: [0.9251296520233154, 0.453125]\n",
      "Epoch: 2338 , Loss: [0.9206556677818298, 0.5625]\n",
      "Epoch: 2339 , Loss: [0.8816304802894592, 0.5625]\n",
      "Epoch: 2340 , Loss: [0.9522638320922852, 0.390625]\n",
      "Epoch: 2341 , Loss: [0.9543072581291199, 0.46875]\n",
      "Epoch: 2342 , Loss: [0.9328129291534424, 0.484375]\n",
      "Epoch: 2343 , Loss: [0.8577635288238525, 0.609375]\n",
      "Epoch: 2344 , Loss: [0.9463604688644409, 0.453125]\n",
      "Epoch: 2345 , Loss: [0.9249274730682373, 0.515625]\n",
      "Epoch: 2346 , Loss: [0.9963100552558899, 0.46875]\n",
      "Epoch: 2347 , Loss: [0.9049567580223083, 0.609375]\n",
      "Epoch: 2348 , Loss: [0.8658918142318726, 0.5625]\n",
      "Epoch: 2349 , Loss: [0.9202050566673279, 0.546875]\n",
      "Epoch: 2350 , Loss: [0.9447104930877686, 0.46875]\n",
      "Epoch: 2351 , Loss: [0.953467607498169, 0.46875]\n",
      "Epoch: 2352 , Loss: [0.9383009076118469, 0.484375]\n",
      "Epoch: 2353 , Loss: [0.9769651889801025, 0.46875]\n",
      "Epoch: 2354 , Loss: [0.9533873796463013, 0.484375]\n",
      "Epoch: 2355 , Loss: [0.9436830878257751, 0.53125]\n",
      "Epoch: 2356 , Loss: [0.9212044477462769, 0.5625]\n",
      "Epoch: 2357 , Loss: [0.9801591634750366, 0.4375]\n",
      "Epoch: 2358 , Loss: [0.9339421391487122, 0.453125]\n",
      "Epoch: 2359 , Loss: [0.9478775262832642, 0.4375]\n",
      "Epoch: 2360 , Loss: [0.9887766242027283, 0.421875]\n",
      "Epoch: 2361 , Loss: [0.946251630783081, 0.46875]\n",
      "Epoch: 2362 , Loss: [0.9007060527801514, 0.546875]\n",
      "Epoch: 2363 , Loss: [0.8891865611076355, 0.5625]\n",
      "Epoch: 2364 , Loss: [0.9296362996101379, 0.484375]\n",
      "Epoch: 2365 , Loss: [0.9381409883499146, 0.453125]\n",
      "Epoch: 2366 , Loss: [0.9439568519592285, 0.421875]\n",
      "Epoch: 2367 , Loss: [0.891642689704895, 0.53125]\n",
      "Epoch: 2368 , Loss: [0.9344702959060669, 0.484375]\n",
      "Epoch: 2369 , Loss: [0.9242835640907288, 0.5]\n",
      "Epoch: 2370 , Loss: [0.9730076789855957, 0.484375]\n",
      "Epoch: 2371 , Loss: [0.9224255084991455, 0.515625]\n",
      "Epoch: 2372 , Loss: [0.914783239364624, 0.453125]\n",
      "Epoch: 2373 , Loss: [0.9592126607894897, 0.421875]\n",
      "Epoch: 2374 , Loss: [0.9537343382835388, 0.5]\n",
      "Epoch: 2375 , Loss: [0.9220762252807617, 0.484375]\n",
      "Epoch: 2376 , Loss: [0.9938554763793945, 0.3125]\n",
      "Epoch: 2377 , Loss: [0.9398506879806519, 0.515625]\n",
      "Epoch: 2378 , Loss: [0.8825556635856628, 0.5625]\n",
      "Epoch: 2379 , Loss: [0.9306196570396423, 0.484375]\n",
      "Epoch: 2380 , Loss: [0.9335200190544128, 0.46875]\n",
      "Epoch: 2381 , Loss: [0.9091737270355225, 0.5625]\n",
      "Epoch: 2382 , Loss: [0.9368475675582886, 0.53125]\n",
      "Epoch: 2383 , Loss: [0.9504829049110413, 0.421875]\n",
      "Epoch: 2384 , Loss: [0.9907072186470032, 0.4375]\n",
      "Epoch: 2385 , Loss: [0.9324001669883728, 0.390625]\n",
      "Epoch: 2386 , Loss: [0.8977704644203186, 0.5]\n",
      "Epoch: 2387 , Loss: [0.9150350093841553, 0.5]\n",
      "Epoch: 2388 , Loss: [0.92512047290802, 0.546875]\n",
      "Epoch: 2389 , Loss: [0.8917281627655029, 0.53125]\n",
      "Epoch: 2390 , Loss: [0.9461200833320618, 0.359375]\n",
      "Epoch: 2391 , Loss: [0.920081615447998, 0.5]\n",
      "Epoch: 2392 , Loss: [0.9209864139556885, 0.46875]\n",
      "Epoch: 2393 , Loss: [0.9437831044197083, 0.40625]\n",
      "Epoch: 2394 , Loss: [0.9497262835502625, 0.46875]\n",
      "Epoch: 2395 , Loss: [0.8721357583999634, 0.546875]\n",
      "Epoch: 2396 , Loss: [0.9033366441726685, 0.46875]\n",
      "Epoch: 2397 , Loss: [0.8925806283950806, 0.546875]\n",
      "Epoch: 2398 , Loss: [1.0294314622879028, 0.390625]\n",
      "Epoch: 2399 , Loss: [0.9090943336486816, 0.4375]\n",
      "Epoch: 2400 , Loss: [0.8820109367370605, 0.59375]\n",
      "Epoch: 2401 , Loss: [0.9608632326126099, 0.40625]\n",
      "Epoch: 2402 , Loss: [0.915371298789978, 0.484375]\n",
      "Epoch: 2403 , Loss: [0.9000171422958374, 0.453125]\n",
      "Epoch: 2404 , Loss: [0.8995094299316406, 0.546875]\n",
      "Epoch: 2405 , Loss: [0.9403533935546875, 0.5]\n",
      "Epoch: 2406 , Loss: [0.9365883469581604, 0.421875]\n",
      "Epoch: 2407 , Loss: [0.8907990455627441, 0.5625]\n",
      "Epoch: 2408 , Loss: [0.9004157781600952, 0.46875]\n",
      "Epoch: 2409 , Loss: [0.9024130702018738, 0.515625]\n",
      "Epoch: 2410 , Loss: [0.9241474270820618, 0.46875]\n",
      "Epoch: 2411 , Loss: [0.8977998495101929, 0.53125]\n",
      "Epoch: 2412 , Loss: [0.9146608114242554, 0.546875]\n",
      "Epoch: 2413 , Loss: [0.8940753936767578, 0.5625]\n",
      "Epoch: 2414 , Loss: [0.9303420782089233, 0.453125]\n",
      "Epoch: 2415 , Loss: [0.9322495460510254, 0.53125]\n",
      "Epoch: 2416 , Loss: [0.9377514123916626, 0.453125]\n",
      "Epoch: 2417 , Loss: [0.8963096737861633, 0.515625]\n",
      "Epoch: 2418 , Loss: [0.9226635694503784, 0.421875]\n",
      "Epoch: 2419 , Loss: [0.9075473546981812, 0.4375]\n",
      "Epoch: 2420 , Loss: [0.909879207611084, 0.53125]\n",
      "Epoch: 2421 , Loss: [0.9149089455604553, 0.484375]\n",
      "Epoch: 2422 , Loss: [0.8762236833572388, 0.46875]\n",
      "Epoch: 2423 , Loss: [0.9233497381210327, 0.375]\n",
      "Epoch: 2424 , Loss: [0.8807439804077148, 0.546875]\n",
      "Epoch: 2425 , Loss: [0.9194422960281372, 0.453125]\n",
      "Epoch: 2426 , Loss: [0.8313599228858948, 0.65625]\n",
      "Epoch: 2427 , Loss: [0.9136369824409485, 0.46875]\n",
      "Epoch: 2428 , Loss: [0.9028148055076599, 0.46875]\n",
      "Epoch: 2429 , Loss: [0.9837175607681274, 0.328125]\n",
      "Epoch: 2430 , Loss: [0.9094253182411194, 0.515625]\n",
      "Epoch: 2431 , Loss: [0.9454715251922607, 0.421875]\n",
      "Epoch: 2432 , Loss: [0.8673334121704102, 0.5625]\n",
      "Epoch: 2433 , Loss: [0.9510042667388916, 0.484375]\n",
      "Epoch: 2434 , Loss: [1.017532229423523, 0.328125]\n",
      "Epoch: 2435 , Loss: [0.8789366483688354, 0.578125]\n",
      "Epoch: 2436 , Loss: [0.8816916346549988, 0.5625]\n",
      "Epoch: 2437 , Loss: [0.9258610606193542, 0.4375]\n",
      "Epoch: 2438 , Loss: [0.9229114651679993, 0.453125]\n",
      "Epoch: 2439 , Loss: [0.9737684726715088, 0.390625]\n",
      "Epoch: 2440 , Loss: [0.9056278467178345, 0.515625]\n",
      "Epoch: 2441 , Loss: [0.8534785509109497, 0.65625]\n",
      "Epoch: 2442 , Loss: [0.9443253874778748, 0.46875]\n",
      "Epoch: 2443 , Loss: [0.956868052482605, 0.421875]\n",
      "Epoch: 2444 , Loss: [0.9567142724990845, 0.453125]\n",
      "Epoch: 2445 , Loss: [0.8853311538696289, 0.515625]\n",
      "Epoch: 2446 , Loss: [0.8996979594230652, 0.5]\n",
      "Epoch: 2447 , Loss: [0.9231340885162354, 0.46875]\n",
      "Epoch: 2448 , Loss: [0.9357039928436279, 0.46875]\n",
      "Epoch: 2449 , Loss: [0.914754331111908, 0.546875]\n",
      "Epoch: 2450 , Loss: [0.9375600814819336, 0.4375]\n",
      "Epoch: 2451 , Loss: [0.9042423963546753, 0.515625]\n",
      "Epoch: 2452 , Loss: [0.8918596506118774, 0.46875]\n",
      "Epoch: 2453 , Loss: [0.912314236164093, 0.421875]\n",
      "Epoch: 2454 , Loss: [0.8979312777519226, 0.484375]\n",
      "Epoch: 2455 , Loss: [0.9196160435676575, 0.5625]\n",
      "Epoch: 2456 , Loss: [0.8959215879440308, 0.578125]\n",
      "Epoch: 2457 , Loss: [0.884899377822876, 0.4375]\n",
      "Epoch: 2458 , Loss: [0.8895854353904724, 0.53125]\n",
      "Epoch: 2459 , Loss: [0.8836222887039185, 0.5625]\n",
      "Epoch: 2460 , Loss: [0.8835641145706177, 0.546875]\n",
      "Epoch: 2461 , Loss: [0.8756247758865356, 0.609375]\n",
      "Epoch: 2462 , Loss: [0.9355177283287048, 0.46875]\n",
      "Epoch: 2463 , Loss: [0.9097107648849487, 0.515625]\n",
      "Epoch: 2464 , Loss: [0.9039446711540222, 0.53125]\n",
      "Epoch: 2465 , Loss: [0.8698863983154297, 0.5625]\n",
      "Epoch: 2466 , Loss: [0.9123705625534058, 0.515625]\n",
      "Epoch: 2467 , Loss: [0.8549976348876953, 0.578125]\n",
      "Epoch: 2468 , Loss: [0.9071027636528015, 0.53125]\n",
      "Epoch: 2469 , Loss: [0.889891505241394, 0.546875]\n",
      "Epoch: 2470 , Loss: [0.9553245306015015, 0.4375]\n",
      "Epoch: 2471 , Loss: [0.9203084111213684, 0.46875]\n",
      "Epoch: 2472 , Loss: [0.9045854210853577, 0.515625]\n",
      "Epoch: 2473 , Loss: [0.9156527519226074, 0.453125]\n",
      "Epoch: 2474 , Loss: [0.9254899621009827, 0.453125]\n",
      "Epoch: 2475 , Loss: [0.9209499359130859, 0.390625]\n",
      "Epoch: 2476 , Loss: [0.8926544189453125, 0.59375]\n",
      "Epoch: 2477 , Loss: [0.9384459257125854, 0.484375]\n",
      "Epoch: 2478 , Loss: [0.924512505531311, 0.546875]\n",
      "Epoch: 2479 , Loss: [0.8936499953269958, 0.578125]\n",
      "Epoch: 2480 , Loss: [0.9090975522994995, 0.4375]\n",
      "Epoch: 2481 , Loss: [0.9374395608901978, 0.4375]\n",
      "Epoch: 2482 , Loss: [0.8311290740966797, 0.59375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2483 , Loss: [0.916923999786377, 0.515625]\n",
      "Epoch: 2484 , Loss: [0.9469661712646484, 0.375]\n",
      "Epoch: 2485 , Loss: [0.9342843294143677, 0.421875]\n",
      "Epoch: 2486 , Loss: [0.9056993722915649, 0.5]\n",
      "Epoch: 2487 , Loss: [0.9024534821510315, 0.5]\n",
      "Epoch: 2488 , Loss: [0.8726900815963745, 0.546875]\n",
      "Epoch: 2489 , Loss: [0.9121231436729431, 0.515625]\n",
      "Epoch: 2490 , Loss: [0.8974449634552002, 0.53125]\n",
      "Epoch: 2491 , Loss: [0.9184365272521973, 0.46875]\n",
      "Epoch: 2492 , Loss: [0.9296722412109375, 0.46875]\n",
      "Epoch: 2493 , Loss: [0.9022246599197388, 0.46875]\n",
      "Epoch: 2494 , Loss: [0.9212976694107056, 0.421875]\n",
      "Epoch: 2495 , Loss: [0.921650230884552, 0.390625]\n",
      "Epoch: 2496 , Loss: [0.9388603568077087, 0.484375]\n",
      "Epoch: 2497 , Loss: [0.906395435333252, 0.484375]\n",
      "Epoch: 2498 , Loss: [0.9186671376228333, 0.515625]\n",
      "Epoch: 2499 , Loss: [0.8644784688949585, 0.546875]\n",
      "Epoch: 2500 , Loss: [0.846688985824585, 0.5]\n",
      "=============================================\n",
      "2 correctly classified among 64\n",
      "Accuracy as of 2500 epochs: 3.125\n",
      "=============================================\n",
      "Epoch: 2501 , Loss: [0.8770424127578735, 0.609375]\n",
      "Epoch: 2502 , Loss: [0.8972558379173279, 0.515625]\n",
      "Epoch: 2503 , Loss: [0.93460613489151, 0.4375]\n",
      "Epoch: 2504 , Loss: [0.9474247097969055, 0.40625]\n",
      "Epoch: 2505 , Loss: [0.8758760690689087, 0.609375]\n",
      "Epoch: 2506 , Loss: [0.911892294883728, 0.515625]\n",
      "Epoch: 2507 , Loss: [0.8978877067565918, 0.453125]\n",
      "Epoch: 2508 , Loss: [0.9420901536941528, 0.375]\n",
      "Epoch: 2509 , Loss: [0.9368575215339661, 0.515625]\n",
      "Epoch: 2510 , Loss: [0.9480389356613159, 0.546875]\n",
      "Epoch: 2511 , Loss: [0.8692724704742432, 0.515625]\n",
      "Epoch: 2512 , Loss: [0.8514809608459473, 0.546875]\n",
      "Epoch: 2513 , Loss: [0.8995379209518433, 0.5]\n",
      "Epoch: 2514 , Loss: [0.914763867855072, 0.53125]\n",
      "Epoch: 2515 , Loss: [0.8842086791992188, 0.53125]\n",
      "Epoch: 2516 , Loss: [0.8861198425292969, 0.546875]\n",
      "Epoch: 2517 , Loss: [0.9313815832138062, 0.484375]\n",
      "Epoch: 2518 , Loss: [0.9405795931816101, 0.4375]\n",
      "Epoch: 2519 , Loss: [0.8892403244972229, 0.46875]\n",
      "Epoch: 2520 , Loss: [0.8822039365768433, 0.546875]\n",
      "Epoch: 2521 , Loss: [0.9629322290420532, 0.390625]\n",
      "Epoch: 2522 , Loss: [0.8910585045814514, 0.46875]\n",
      "Epoch: 2523 , Loss: [0.8715654611587524, 0.59375]\n",
      "Epoch: 2524 , Loss: [0.9482502341270447, 0.421875]\n",
      "Epoch: 2525 , Loss: [0.9121886491775513, 0.46875]\n",
      "Epoch: 2526 , Loss: [0.889153778553009, 0.515625]\n",
      "Epoch: 2527 , Loss: [0.917243480682373, 0.515625]\n",
      "Epoch: 2528 , Loss: [0.8856856822967529, 0.546875]\n",
      "Epoch: 2529 , Loss: [0.8930565714836121, 0.5]\n",
      "Epoch: 2530 , Loss: [0.9155189990997314, 0.515625]\n",
      "Epoch: 2531 , Loss: [0.9258948564529419, 0.4375]\n",
      "Epoch: 2532 , Loss: [0.9027687311172485, 0.546875]\n",
      "Epoch: 2533 , Loss: [0.9480075836181641, 0.46875]\n",
      "Epoch: 2534 , Loss: [0.8942747116088867, 0.5]\n",
      "Epoch: 2535 , Loss: [0.9259932637214661, 0.421875]\n",
      "Epoch: 2536 , Loss: [0.8895052075386047, 0.546875]\n",
      "Epoch: 2537 , Loss: [0.9026169180870056, 0.5]\n",
      "Epoch: 2538 , Loss: [0.9485599398612976, 0.40625]\n",
      "Epoch: 2539 , Loss: [0.8381940126419067, 0.578125]\n",
      "Epoch: 2540 , Loss: [0.9410591721534729, 0.5]\n",
      "Epoch: 2541 , Loss: [0.8585686683654785, 0.546875]\n",
      "Epoch: 2542 , Loss: [0.8896421194076538, 0.484375]\n",
      "Epoch: 2543 , Loss: [0.9518627524375916, 0.484375]\n",
      "Epoch: 2544 , Loss: [0.8303185701370239, 0.578125]\n",
      "Epoch: 2545 , Loss: [0.9071115255355835, 0.453125]\n",
      "Epoch: 2546 , Loss: [0.8739808797836304, 0.578125]\n",
      "Epoch: 2547 , Loss: [0.877382755279541, 0.59375]\n",
      "Epoch: 2548 , Loss: [0.9185636639595032, 0.4375]\n",
      "Epoch: 2549 , Loss: [0.8751083612442017, 0.546875]\n",
      "Epoch: 2550 , Loss: [0.9050071239471436, 0.453125]\n",
      "Epoch: 2551 , Loss: [0.9076678156852722, 0.53125]\n",
      "Epoch: 2552 , Loss: [0.9204296469688416, 0.421875]\n",
      "Epoch: 2553 , Loss: [0.9393235445022583, 0.453125]\n",
      "Epoch: 2554 , Loss: [0.9176395535469055, 0.4375]\n",
      "Epoch: 2555 , Loss: [0.890927255153656, 0.484375]\n",
      "Epoch: 2556 , Loss: [0.8561879992485046, 0.53125]\n",
      "Epoch: 2557 , Loss: [0.8983800411224365, 0.46875]\n",
      "Epoch: 2558 , Loss: [0.8885353803634644, 0.4375]\n",
      "Epoch: 2559 , Loss: [0.9089629650115967, 0.53125]\n",
      "Epoch: 2560 , Loss: [0.908747673034668, 0.4375]\n",
      "Epoch: 2561 , Loss: [0.8772292733192444, 0.546875]\n",
      "Epoch: 2562 , Loss: [0.976906418800354, 0.34375]\n",
      "Epoch: 2563 , Loss: [0.8985022306442261, 0.46875]\n",
      "Epoch: 2564 , Loss: [0.846869945526123, 0.5]\n",
      "Epoch: 2565 , Loss: [0.8514481782913208, 0.59375]\n",
      "Epoch: 2566 , Loss: [0.8813707232475281, 0.46875]\n",
      "Epoch: 2567 , Loss: [0.9039481282234192, 0.484375]\n",
      "Epoch: 2568 , Loss: [0.8856117129325867, 0.5]\n",
      "Epoch: 2569 , Loss: [0.9155526757240295, 0.421875]\n",
      "Epoch: 2570 , Loss: [0.8333462476730347, 0.609375]\n",
      "Epoch: 2571 , Loss: [0.8544871211051941, 0.46875]\n",
      "Epoch: 2572 , Loss: [0.8730978965759277, 0.5625]\n",
      "Epoch: 2573 , Loss: [0.8887063264846802, 0.5625]\n",
      "Epoch: 2574 , Loss: [0.8624095916748047, 0.515625]\n",
      "Epoch: 2575 , Loss: [0.9145110249519348, 0.453125]\n",
      "Epoch: 2576 , Loss: [0.8912094831466675, 0.53125]\n",
      "Epoch: 2577 , Loss: [0.880020260810852, 0.46875]\n",
      "Epoch: 2578 , Loss: [0.8530005216598511, 0.578125]\n",
      "Epoch: 2579 , Loss: [0.9274647235870361, 0.5]\n",
      "Epoch: 2580 , Loss: [0.9283851385116577, 0.390625]\n",
      "Epoch: 2581 , Loss: [0.9075972437858582, 0.4375]\n",
      "Epoch: 2582 , Loss: [0.862106204032898, 0.53125]\n",
      "Epoch: 2583 , Loss: [0.9549696445465088, 0.390625]\n",
      "Epoch: 2584 , Loss: [0.9041821360588074, 0.484375]\n",
      "Epoch: 2585 , Loss: [0.8627029657363892, 0.46875]\n",
      "Epoch: 2586 , Loss: [0.8804946541786194, 0.515625]\n",
      "Epoch: 2587 , Loss: [0.8676741719245911, 0.5]\n",
      "Epoch: 2588 , Loss: [0.896249532699585, 0.46875]\n",
      "Epoch: 2589 , Loss: [0.8782176971435547, 0.515625]\n",
      "Epoch: 2590 , Loss: [0.8896262049674988, 0.46875]\n",
      "Epoch: 2591 , Loss: [0.9275638461112976, 0.375]\n",
      "Epoch: 2592 , Loss: [0.9136645197868347, 0.453125]\n",
      "Epoch: 2593 , Loss: [0.9025256633758545, 0.5]\n",
      "Epoch: 2594 , Loss: [0.9513359069824219, 0.4375]\n",
      "Epoch: 2595 , Loss: [0.8887143135070801, 0.53125]\n",
      "Epoch: 2596 , Loss: [0.8711833953857422, 0.546875]\n",
      "Epoch: 2597 , Loss: [0.9129934906959534, 0.40625]\n",
      "Epoch: 2598 , Loss: [0.9140417575836182, 0.515625]\n",
      "Epoch: 2599 , Loss: [0.9137620329856873, 0.4375]\n",
      "Epoch: 2600 , Loss: [0.8904587030410767, 0.421875]\n",
      "Epoch: 2601 , Loss: [0.9025862216949463, 0.5]\n",
      "Epoch: 2602 , Loss: [0.8797075152397156, 0.46875]\n",
      "Epoch: 2603 , Loss: [0.8989885449409485, 0.453125]\n",
      "Epoch: 2604 , Loss: [0.9270747900009155, 0.421875]\n",
      "Epoch: 2605 , Loss: [0.9012877941131592, 0.453125]\n",
      "Epoch: 2606 , Loss: [0.8843156695365906, 0.515625]\n",
      "Epoch: 2607 , Loss: [0.899681806564331, 0.40625]\n",
      "Epoch: 2608 , Loss: [0.8646490573883057, 0.5625]\n",
      "Epoch: 2609 , Loss: [0.8834875226020813, 0.453125]\n",
      "Epoch: 2610 , Loss: [0.8880724906921387, 0.515625]\n",
      "Epoch: 2611 , Loss: [0.8546699285507202, 0.53125]\n",
      "Epoch: 2612 , Loss: [0.8998437523841858, 0.421875]\n",
      "Epoch: 2613 , Loss: [0.8969182968139648, 0.53125]\n",
      "Epoch: 2614 , Loss: [0.8982369899749756, 0.46875]\n",
      "Epoch: 2615 , Loss: [0.8658132553100586, 0.5625]\n",
      "Epoch: 2616 , Loss: [0.8898535966873169, 0.4375]\n",
      "Epoch: 2617 , Loss: [0.931377649307251, 0.453125]\n",
      "Epoch: 2618 , Loss: [0.9093684554100037, 0.40625]\n",
      "Epoch: 2619 , Loss: [0.8889386653900146, 0.453125]\n",
      "Epoch: 2620 , Loss: [0.8974011540412903, 0.46875]\n",
      "Epoch: 2621 , Loss: [0.9202677607536316, 0.4375]\n",
      "Epoch: 2622 , Loss: [0.8417627811431885, 0.578125]\n",
      "Epoch: 2623 , Loss: [0.862006425857544, 0.53125]\n",
      "Epoch: 2624 , Loss: [0.8839617371559143, 0.5]\n",
      "Epoch: 2625 , Loss: [0.8717390894889832, 0.53125]\n",
      "Epoch: 2626 , Loss: [0.8887842893600464, 0.5]\n",
      "Epoch: 2627 , Loss: [0.8683300018310547, 0.5625]\n",
      "Epoch: 2628 , Loss: [0.8795987367630005, 0.53125]\n",
      "Epoch: 2629 , Loss: [0.8644258975982666, 0.46875]\n",
      "Epoch: 2630 , Loss: [0.8586193323135376, 0.484375]\n",
      "Epoch: 2631 , Loss: [0.9116904735565186, 0.40625]\n",
      "Epoch: 2632 , Loss: [0.9198510646820068, 0.46875]\n",
      "Epoch: 2633 , Loss: [0.9265725612640381, 0.46875]\n",
      "Epoch: 2634 , Loss: [0.9305477142333984, 0.453125]\n",
      "Epoch: 2635 , Loss: [0.8888441324234009, 0.484375]\n",
      "Epoch: 2636 , Loss: [0.8858692049980164, 0.40625]\n",
      "Epoch: 2637 , Loss: [0.906943142414093, 0.46875]\n",
      "Epoch: 2638 , Loss: [0.8757954835891724, 0.546875]\n",
      "Epoch: 2639 , Loss: [0.8932837843894958, 0.4375]\n",
      "Epoch: 2640 , Loss: [0.9128819704055786, 0.453125]\n",
      "Epoch: 2641 , Loss: [0.8655447959899902, 0.5]\n",
      "Epoch: 2642 , Loss: [0.9093770980834961, 0.390625]\n",
      "Epoch: 2643 , Loss: [0.9026601314544678, 0.484375]\n",
      "Epoch: 2644 , Loss: [0.8716661930084229, 0.515625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2645 , Loss: [0.9009413719177246, 0.515625]\n",
      "Epoch: 2646 , Loss: [0.8467264771461487, 0.546875]\n",
      "Epoch: 2647 , Loss: [0.8623999953269958, 0.5625]\n",
      "Epoch: 2648 , Loss: [0.8633686304092407, 0.578125]\n",
      "Epoch: 2649 , Loss: [0.8968241214752197, 0.484375]\n",
      "Epoch: 2650 , Loss: [0.8655444383621216, 0.453125]\n",
      "Epoch: 2651 , Loss: [0.8621988892555237, 0.578125]\n",
      "Epoch: 2652 , Loss: [0.859153687953949, 0.5625]\n",
      "Epoch: 2653 , Loss: [0.9142959117889404, 0.359375]\n",
      "Epoch: 2654 , Loss: [0.8876513242721558, 0.46875]\n",
      "Epoch: 2655 , Loss: [0.8565853238105774, 0.578125]\n",
      "Epoch: 2656 , Loss: [0.8658933639526367, 0.515625]\n",
      "Epoch: 2657 , Loss: [0.9067975282669067, 0.515625]\n",
      "Epoch: 2658 , Loss: [0.8631432056427002, 0.53125]\n",
      "Epoch: 2659 , Loss: [0.8450934290885925, 0.5625]\n",
      "Epoch: 2660 , Loss: [0.8529312610626221, 0.5625]\n",
      "Epoch: 2661 , Loss: [0.8761429786682129, 0.46875]\n",
      "Epoch: 2662 , Loss: [0.8650774955749512, 0.53125]\n",
      "Epoch: 2663 , Loss: [0.8889327049255371, 0.5]\n",
      "Epoch: 2664 , Loss: [0.8622579574584961, 0.515625]\n",
      "Epoch: 2665 , Loss: [0.8834599256515503, 0.515625]\n",
      "Epoch: 2666 , Loss: [0.8847432136535645, 0.46875]\n",
      "Epoch: 2667 , Loss: [0.8686992526054382, 0.5]\n",
      "Epoch: 2668 , Loss: [0.8461872339248657, 0.546875]\n",
      "Epoch: 2669 , Loss: [0.8738152384757996, 0.484375]\n",
      "Epoch: 2670 , Loss: [0.8467583656311035, 0.5625]\n",
      "Epoch: 2671 , Loss: [0.8684306144714355, 0.515625]\n",
      "Epoch: 2672 , Loss: [0.8541992902755737, 0.515625]\n",
      "Epoch: 2673 , Loss: [0.8484436869621277, 0.515625]\n",
      "Epoch: 2674 , Loss: [0.8342198133468628, 0.578125]\n",
      "Epoch: 2675 , Loss: [0.8659945726394653, 0.5]\n",
      "Epoch: 2676 , Loss: [0.871951699256897, 0.4375]\n",
      "Epoch: 2677 , Loss: [0.8423066139221191, 0.59375]\n",
      "Epoch: 2678 , Loss: [0.8314024806022644, 0.546875]\n",
      "Epoch: 2679 , Loss: [0.8718505501747131, 0.453125]\n",
      "Epoch: 2680 , Loss: [0.9107377529144287, 0.453125]\n",
      "Epoch: 2681 , Loss: [0.8971308469772339, 0.453125]\n",
      "Epoch: 2682 , Loss: [0.8723407983779907, 0.5625]\n",
      "Epoch: 2683 , Loss: [0.8716132640838623, 0.546875]\n",
      "Epoch: 2684 , Loss: [0.8616902828216553, 0.53125]\n",
      "Epoch: 2685 , Loss: [0.8823454976081848, 0.5]\n",
      "Epoch: 2686 , Loss: [0.872351348400116, 0.5]\n",
      "Epoch: 2687 , Loss: [0.8538174629211426, 0.484375]\n",
      "Epoch: 2688 , Loss: [0.8763998746871948, 0.515625]\n",
      "Epoch: 2689 , Loss: [0.8811618685722351, 0.4375]\n",
      "Epoch: 2690 , Loss: [0.8682288527488708, 0.515625]\n",
      "Epoch: 2691 , Loss: [0.875993549823761, 0.46875]\n",
      "Epoch: 2692 , Loss: [0.8559384346008301, 0.515625]\n",
      "Epoch: 2693 , Loss: [0.8750123977661133, 0.53125]\n",
      "Epoch: 2694 , Loss: [0.9235740303993225, 0.4375]\n",
      "Epoch: 2695 , Loss: [0.8857811093330383, 0.421875]\n",
      "Epoch: 2696 , Loss: [0.8444218635559082, 0.515625]\n",
      "Epoch: 2697 , Loss: [0.8795392513275146, 0.515625]\n",
      "Epoch: 2698 , Loss: [0.8342783451080322, 0.5625]\n",
      "Epoch: 2699 , Loss: [0.8916316628456116, 0.484375]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-379f979404c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m', Loss:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Face-Detection/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Face-Detection/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Face-Detection/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Face-Detection/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Face-Detection/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Face-Detection/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Face-Detection/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Face-Detection/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "n_way = 20\n",
    "n_val = 64\n",
    "batch_size = 64\n",
    "\n",
    "loss_list=[]\n",
    "accuracy_list=[]\n",
    "for epoch in range(1,epochs):\n",
    "    batch_x, batch_y = get_batch(batch_size)\n",
    "    loss = model.train_on_batch(batch_x, batch_y)\n",
    "    loss_list.append((epoch,loss))\n",
    "    print('Epoch:', epoch, ', Loss:',loss)\n",
    "    if epoch%250 == 0:\n",
    "        print(\"=============================================\")\n",
    "        accuracy = one_shot_learning(model, n_way, n_val)\n",
    "        accuracy_list.append((epoch, accuracy))\n",
    "        print('Accuracy as of', epoch, 'epochs:', accuracy)\n",
    "        print(\"=============================================\")\n",
    "        if(accuracy>99):\n",
    "            print(\"Achieved more than 90% Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Face-Detection] *",
   "language": "python",
   "name": "conda-env-Face-Detection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
